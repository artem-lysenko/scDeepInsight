{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eee4b9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "import torch.optim.lr_scheduler as lr_scheduler \n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn import preprocessing\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "from timeit import default_timer as timer\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e429ed01",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainy = pd.read_csv(\"./pretrained/trainy_pre.csv\")\n",
    "valy = pd.read_csv(\"./pretrained/valy_pre.csv\")\n",
    "#labels to categorical matrix\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(trainy['celltype'])\n",
    "classes = len(np.unique(trainy['celltype']))\n",
    "with open(\"./pretrained/label_encoder_pre.obj\",\"wb\") as f:\n",
    "   pickle.dump(le, f)\n",
    "\n",
    "y_train = pd.DataFrame(le.transform(trainy['celltype']))\n",
    "y_val = pd.DataFrame(le.transform(valy['celltype']))\n",
    "np.save('./pretrained/train_pre_label.npy', y_train)\n",
    "np.save('./pretrained/val_pre_label.npy', y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47eefb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothingCrossEntropy(torch.nn.Module):\n",
    "    def __init__(self, eps=0.1, reduction='mean'):\n",
    "        super(LabelSmoothingCrossEntropy, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.reduction = reduction\n",
    "    def forward(self, output, target):\n",
    "        c = output.size()[-1]\n",
    "        log_preds = torch.nn.functional.log_softmax(output, dim=-1)\n",
    "        if self.reduction=='sum':\n",
    "            loss = -log_preds.sum()\n",
    "        else:\n",
    "            loss = -log_preds.sum(dim=-1)\n",
    "            if self.reduction=='mean':\n",
    "                loss = loss.mean()\n",
    "        return loss*self.eps/c + (1-self.eps) * torch.nn.functional.nll_loss(log_preds, target, reduction=self.reduction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eda3e106",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, verbose=False, path='./pretrained/checkpoint_model_pre.pth'):\n",
    "        self.patience = patience    \n",
    "        self.verbose = verbose      \n",
    "        self.counter = 0            \n",
    "        self.best_score = None      \n",
    "        self.early_stop = False     \n",
    "        self.val_acc_max = 0   \n",
    "        self.path = path             \n",
    "    def __call__(self, val_acc, model):\n",
    "        score = val_acc\n",
    "        if self.best_score is None: \n",
    "            self.best_score = score \n",
    "            self.checkpoint(val_acc, model)\n",
    "        elif score < self.best_score: \n",
    "            self.counter += 1 \n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience: \n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.checkpoint(val_acc, model)\n",
    "            self.counter = 0  \n",
    "    def checkpoint(self, val_acc, model):\n",
    "        if self.verbose:  \n",
    "            print(f'Validation accuracy increased ({self.val_acc_max:.6f} --> {val_acc:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)  \n",
    "        self.val_acc_max = val_acc  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "145fe140",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, img, label):\n",
    "        self.img = np.load(img)\n",
    "        self.label = torch.tensor(np.load(label))\n",
    "        self.transforms = transforms.Compose([transforms.ToTensor(), ])\n",
    "    def __getitem__(self, index):\n",
    "        img = self.img[index, :, :, :] \n",
    "        img = np.squeeze(img)\n",
    "        img = Image.fromarray(np.uint8(img))\n",
    "        img = self.transforms(img)\n",
    "        label = self.label[index]\n",
    "        label = np.squeeze(label)\n",
    "        return img,label\n",
    "    def __len__(self):\n",
    "        return self.img.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d89cf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(pre_epoch, EPOCH, early_patience, training_loader, validation_loader, net, optimizer, scheduler, criteria, device):\n",
    "    with open(\"./pretrained/acc.txt\", \"w\") as f:\n",
    "        with open(\"./pretrained/log.txt\", \"w\")as f2:\n",
    "            start = time.time()\n",
    "            earlystopping = EarlyStopping(patience=early_patience, verbose=True)\n",
    "            losses_train = []\n",
    "            accs_train = []\n",
    "            losses_val = []\n",
    "            accs_val = []\n",
    "            best_acc = 0\n",
    "            total_poches = 0\n",
    "            for epoch in range(pre_epoch, EPOCH):\n",
    "                print('\\nEpoch: %d' % (epoch + 1))\n",
    "                since = time.time()\n",
    "                net.train()\n",
    "                sum_loss = 0.0\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                for i, data in enumerate(training_loader):\n",
    "                    length = len(training_loader)\n",
    "                    input, target = data\n",
    "                    input, target = input.to(device), target.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    # forward + backward\n",
    "                    output = net(input)\n",
    "                    loss = criteria(output, target)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    sum_loss += loss.item()\n",
    "                    _, predicted = torch.max(output.data, 1)\n",
    "                    total += target.size(0)\n",
    "                    correct += predicted.eq(target.data).cpu().sum()\n",
    "                    loss_train = sum_loss / (i + 1)\n",
    "                    acc_train = 100. * float(correct) / float(total)\n",
    "                    print('[epoch:%d, iter:%d] Loss: %.03f | Accuracy: %.3f%% '\n",
    "                        % (epoch + 1, (i + 1 + epoch * length), loss_train, acc_train))\n",
    "                    f2.write('%03d  %05d |Loss: %.03f | Accuracy: %.3f%% '\n",
    "                        % (epoch + 1, (i + 1 + epoch * length), loss_train, acc_train))\n",
    "                    f2.write('\\n')\n",
    "                    f2.flush()\n",
    "                acc_train = 100. * float(correct) / float(total)\n",
    "                accs_train.append(acc_train)\n",
    "                losses_train.append(loss_train)\n",
    "                print(\"Waiting Test!\")\n",
    "                with torch.no_grad():\n",
    "                    sum_loss_val = 0\n",
    "                    correct = 0\n",
    "                    total = 0\n",
    "                    loss_val = 0\n",
    "                    for i, data in enumerate(validation_loader):\n",
    "                        net.eval()\n",
    "                        images, labels = data\n",
    "                        images, labels = images.to(device), labels.to(device)\n",
    "                        outputs = net(images)\n",
    "                        loss = criteria(outputs, labels)\n",
    "                        sum_loss_val += loss.item()\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total += labels.size(0)\n",
    "                        correct += predicted.eq(labels.data).cpu().sum()\n",
    "                        loss_val = sum_loss_val / (i + 1)\n",
    "                    acc_val = 100. * float(correct) / float(total)\n",
    "                    losses_val.append(loss_val)\n",
    "                    accs_val.append(acc_val)\n",
    "                    print(\"EPOCH=%03d, Loss: %.03f, Accuracy= %.3f%%\" % (epoch + 1, loss_val ,acc_val))\n",
    "                    scheduler.step(acc_val)\n",
    "                    if acc_val > best_acc:\n",
    "                        f3 = open(\"./pretrained/best_acc.txt\", \"w\")\n",
    "                        f3.write(\"EPOCH=%d,best_acc= %.3f%%\" % (epoch + 1, acc_val))\n",
    "                        f3.close()\n",
    "                        best_acc = acc_val\n",
    "                    time_elapsed = time.time() - since\n",
    "                    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "                    earlystopping(acc_val, net)\n",
    "                    if earlystopping.early_stop: \n",
    "                        print(\"Early Stopping!\")\n",
    "                        total_poches = epoch + 1\n",
    "                        break\n",
    "            print(\"Training Finished, TotalEPOCH=%d\" % total_poches)\n",
    "            time_total = time.time() - start\n",
    "            print('The whole training process complete in {:.0f}m {:.0f}s'.format(time_total // 60, time_total % 60))\n",
    "    return losses_train, accs_train, losses_val, accs_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "101b2a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Quadro RTX 8000'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "batch_size = 32\n",
    "net = EfficientNet.from_pretrained('efficientnet-b3', num_classes=classes)\n",
    "net._fc.out_features = classes\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    net = nn.DataParallel(net)\n",
    "\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.device_count()\n",
    "torch.cuda.current_device()\n",
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "489763c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.to(device)\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62716211",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = MyDataset(\"./pretrained/train_pre.npy\", \"./pretrained/train_pre_label.npy\")\n",
    "training_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "val = MyDataset(\"./pretrained/val_pre.npy\", \"./pretrained/val_pre_label.npy\")\n",
    "validation_loader = torch.utils.data.DataLoader(val, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7197f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 3e-4 \n",
    "# optimizer\n",
    "params_to_update = net.parameters()\n",
    "optimizer = optim.NAdam(params_to_update, lr=LR, betas=(0.9, 0.999), eps=1e-9)\n",
    "# scheduler\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.7, patience=3, verbose=True)\n",
    "criteria = LabelSmoothingCrossEntropy(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e317905",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8faca313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n",
      "[epoch:1, iter:1] Loss: 2.306 | Accuracy: 9.375% \n",
      "[epoch:1, iter:2] Loss: 2.267 | Accuracy: 20.312% \n",
      "[epoch:1, iter:3] Loss: 2.228 | Accuracy: 28.125% \n",
      "[epoch:1, iter:4] Loss: 2.194 | Accuracy: 29.688% \n",
      "[epoch:1, iter:5] Loss: 2.163 | Accuracy: 33.125% \n",
      "[epoch:1, iter:6] Loss: 2.125 | Accuracy: 37.500% \n",
      "[epoch:1, iter:7] Loss: 2.075 | Accuracy: 42.411% \n",
      "[epoch:1, iter:8] Loss: 2.022 | Accuracy: 45.703% \n",
      "[epoch:1, iter:9] Loss: 2.004 | Accuracy: 45.833% \n",
      "[epoch:1, iter:10] Loss: 1.948 | Accuracy: 49.375% \n",
      "[epoch:1, iter:11] Loss: 1.909 | Accuracy: 50.000% \n",
      "[epoch:1, iter:12] Loss: 1.880 | Accuracy: 51.042% \n",
      "[epoch:1, iter:13] Loss: 1.826 | Accuracy: 52.163% \n",
      "[epoch:1, iter:14] Loss: 1.777 | Accuracy: 54.464% \n",
      "[epoch:1, iter:15] Loss: 1.728 | Accuracy: 56.667% \n",
      "[epoch:1, iter:16] Loss: 1.683 | Accuracy: 58.008% \n",
      "[epoch:1, iter:17] Loss: 1.644 | Accuracy: 59.375% \n",
      "[epoch:1, iter:18] Loss: 1.620 | Accuracy: 60.069% \n",
      "[epoch:1, iter:19] Loss: 1.577 | Accuracy: 61.678% \n",
      "[epoch:1, iter:20] Loss: 1.543 | Accuracy: 62.812% \n",
      "[epoch:1, iter:21] Loss: 1.511 | Accuracy: 64.137% \n",
      "[epoch:1, iter:22] Loss: 1.488 | Accuracy: 64.489% \n",
      "[epoch:1, iter:23] Loss: 1.456 | Accuracy: 65.897% \n",
      "[epoch:1, iter:24] Loss: 1.431 | Accuracy: 66.797% \n",
      "[epoch:1, iter:25] Loss: 1.413 | Accuracy: 67.375% \n",
      "[epoch:1, iter:26] Loss: 1.395 | Accuracy: 68.149% \n",
      "[epoch:1, iter:27] Loss: 1.375 | Accuracy: 68.981% \n",
      "[epoch:1, iter:28] Loss: 1.351 | Accuracy: 69.754% \n",
      "[epoch:1, iter:29] Loss: 1.330 | Accuracy: 70.474% \n",
      "[epoch:1, iter:30] Loss: 1.308 | Accuracy: 71.354% \n",
      "[epoch:1, iter:31] Loss: 1.291 | Accuracy: 71.976% \n",
      "[epoch:1, iter:32] Loss: 1.272 | Accuracy: 72.559% \n",
      "[epoch:1, iter:33] Loss: 1.257 | Accuracy: 73.201% \n",
      "[epoch:1, iter:34] Loss: 1.239 | Accuracy: 73.805% \n",
      "[epoch:1, iter:35] Loss: 1.224 | Accuracy: 74.196% \n",
      "[epoch:1, iter:36] Loss: 1.206 | Accuracy: 74.913% \n",
      "[epoch:1, iter:37] Loss: 1.192 | Accuracy: 75.338% \n",
      "[epoch:1, iter:38] Loss: 1.177 | Accuracy: 75.822% \n",
      "[epoch:1, iter:39] Loss: 1.167 | Accuracy: 76.202% \n",
      "[epoch:1, iter:40] Loss: 1.157 | Accuracy: 76.484% \n",
      "[epoch:1, iter:41] Loss: 1.143 | Accuracy: 77.058% \n",
      "[epoch:1, iter:42] Loss: 1.132 | Accuracy: 77.381% \n",
      "[epoch:1, iter:43] Loss: 1.124 | Accuracy: 77.689% \n",
      "[epoch:1, iter:44] Loss: 1.113 | Accuracy: 78.125% \n",
      "[epoch:1, iter:45] Loss: 1.106 | Accuracy: 78.264% \n",
      "[epoch:1, iter:46] Loss: 1.098 | Accuracy: 78.601% \n",
      "[epoch:1, iter:47] Loss: 1.089 | Accuracy: 78.923% \n",
      "[epoch:1, iter:48] Loss: 1.082 | Accuracy: 79.232% \n",
      "[epoch:1, iter:49] Loss: 1.073 | Accuracy: 79.528% \n",
      "[epoch:1, iter:50] Loss: 1.068 | Accuracy: 79.750% \n",
      "[epoch:1, iter:51] Loss: 1.058 | Accuracy: 80.147% \n",
      "[epoch:1, iter:52] Loss: 1.049 | Accuracy: 80.469% \n",
      "[epoch:1, iter:53] Loss: 1.039 | Accuracy: 80.837% \n",
      "[epoch:1, iter:54] Loss: 1.037 | Accuracy: 80.903% \n",
      "[epoch:1, iter:55] Loss: 1.029 | Accuracy: 81.250% \n",
      "[epoch:1, iter:56] Loss: 1.021 | Accuracy: 81.473% \n",
      "[epoch:1, iter:57] Loss: 1.013 | Accuracy: 81.798% \n",
      "[epoch:1, iter:58] Loss: 1.005 | Accuracy: 82.112% \n",
      "[epoch:1, iter:59] Loss: 0.999 | Accuracy: 82.309% \n",
      "[epoch:1, iter:60] Loss: 0.996 | Accuracy: 82.488% \n",
      "Waiting Test!\n",
      "EPOCH=001, Loss: 1.975, Accuracy= 38.095%\n",
      "Training complete in 0m 14s\n",
      "Validation accuracy increased (0.000000 --> 38.095238).  Saving model ...\n",
      "\n",
      "Epoch: 2\n",
      "[epoch:2, iter:61] Loss: 0.595 | Accuracy: 96.875% \n",
      "[epoch:2, iter:62] Loss: 0.608 | Accuracy: 96.875% \n",
      "[epoch:2, iter:63] Loss: 0.645 | Accuracy: 96.875% \n",
      "[epoch:2, iter:64] Loss: 0.664 | Accuracy: 96.094% \n",
      "[epoch:2, iter:65] Loss: 0.641 | Accuracy: 96.875% \n",
      "[epoch:2, iter:66] Loss: 0.642 | Accuracy: 96.354% \n",
      "[epoch:2, iter:67] Loss: 0.628 | Accuracy: 96.875% \n",
      "[epoch:2, iter:68] Loss: 0.616 | Accuracy: 97.266% \n",
      "[epoch:2, iter:69] Loss: 0.625 | Accuracy: 96.875% \n",
      "[epoch:2, iter:70] Loss: 0.616 | Accuracy: 97.188% \n",
      "[epoch:2, iter:71] Loss: 0.623 | Accuracy: 97.159% \n",
      "[epoch:2, iter:72] Loss: 0.618 | Accuracy: 97.135% \n",
      "[epoch:2, iter:73] Loss: 0.614 | Accuracy: 97.356% \n",
      "[epoch:2, iter:74] Loss: 0.608 | Accuracy: 97.545% \n",
      "[epoch:2, iter:75] Loss: 0.618 | Accuracy: 97.292% \n",
      "[epoch:2, iter:76] Loss: 0.620 | Accuracy: 97.266% \n",
      "[epoch:2, iter:77] Loss: 0.627 | Accuracy: 97.059% \n",
      "[epoch:2, iter:78] Loss: 0.621 | Accuracy: 97.222% \n",
      "[epoch:2, iter:79] Loss: 0.621 | Accuracy: 97.039% \n",
      "[epoch:2, iter:80] Loss: 0.618 | Accuracy: 97.188% \n",
      "[epoch:2, iter:81] Loss: 0.616 | Accuracy: 97.173% \n",
      "[epoch:2, iter:82] Loss: 0.619 | Accuracy: 97.017% \n",
      "[epoch:2, iter:83] Loss: 0.619 | Accuracy: 97.011% \n",
      "[epoch:2, iter:84] Loss: 0.620 | Accuracy: 96.875% \n",
      "[epoch:2, iter:85] Loss: 0.617 | Accuracy: 97.000% \n",
      "[epoch:2, iter:86] Loss: 0.619 | Accuracy: 96.995% \n",
      "[epoch:2, iter:87] Loss: 0.620 | Accuracy: 96.991% \n",
      "[epoch:2, iter:88] Loss: 0.620 | Accuracy: 96.987% \n",
      "[epoch:2, iter:89] Loss: 0.617 | Accuracy: 97.091% \n",
      "[epoch:2, iter:90] Loss: 0.616 | Accuracy: 97.083% \n",
      "[epoch:2, iter:91] Loss: 0.617 | Accuracy: 96.976% \n",
      "[epoch:2, iter:92] Loss: 0.624 | Accuracy: 96.777% \n",
      "[epoch:2, iter:93] Loss: 0.622 | Accuracy: 96.875% \n",
      "[epoch:2, iter:94] Loss: 0.622 | Accuracy: 96.875% \n",
      "[epoch:2, iter:95] Loss: 0.623 | Accuracy: 96.875% \n",
      "[epoch:2, iter:96] Loss: 0.625 | Accuracy: 96.701% \n",
      "[epoch:2, iter:97] Loss: 0.623 | Accuracy: 96.791% \n",
      "[epoch:2, iter:98] Loss: 0.623 | Accuracy: 96.793% \n",
      "[epoch:2, iter:99] Loss: 0.621 | Accuracy: 96.715% \n",
      "[epoch:2, iter:100] Loss: 0.620 | Accuracy: 96.719% \n",
      "[epoch:2, iter:101] Loss: 0.619 | Accuracy: 96.799% \n",
      "[epoch:2, iter:102] Loss: 0.618 | Accuracy: 96.801% \n",
      "[epoch:2, iter:103] Loss: 0.619 | Accuracy: 96.802% \n",
      "[epoch:2, iter:104] Loss: 0.620 | Accuracy: 96.733% \n",
      "[epoch:2, iter:105] Loss: 0.619 | Accuracy: 96.736% \n",
      "[epoch:2, iter:106] Loss: 0.620 | Accuracy: 96.603% \n",
      "[epoch:2, iter:107] Loss: 0.622 | Accuracy: 96.609% \n",
      "[epoch:2, iter:108] Loss: 0.621 | Accuracy: 96.549% \n",
      "[epoch:2, iter:109] Loss: 0.622 | Accuracy: 96.429% \n",
      "[epoch:2, iter:110] Loss: 0.622 | Accuracy: 96.438% \n",
      "[epoch:2, iter:111] Loss: 0.623 | Accuracy: 96.385% \n",
      "[epoch:2, iter:112] Loss: 0.621 | Accuracy: 96.454% \n",
      "[epoch:2, iter:113] Loss: 0.621 | Accuracy: 96.462% \n",
      "[epoch:2, iter:114] Loss: 0.621 | Accuracy: 96.412% \n",
      "[epoch:2, iter:115] Loss: 0.624 | Accuracy: 96.250% \n",
      "[epoch:2, iter:116] Loss: 0.623 | Accuracy: 96.317% \n",
      "[epoch:2, iter:117] Loss: 0.626 | Accuracy: 96.217% \n",
      "[epoch:2, iter:118] Loss: 0.627 | Accuracy: 96.228% \n",
      "[epoch:2, iter:119] Loss: 0.629 | Accuracy: 96.186% \n",
      "[epoch:2, iter:120] Loss: 0.628 | Accuracy: 96.236% \n",
      "Waiting Test!\n",
      "EPOCH=002, Loss: 1.914, Accuracy= 40.952%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (38.095238 --> 40.952381).  Saving model ...\n",
      "\n",
      "Epoch: 3\n",
      "[epoch:3, iter:121] Loss: 0.531 | Accuracy: 100.000% \n",
      "[epoch:3, iter:122] Loss: 0.596 | Accuracy: 96.875% \n",
      "[epoch:3, iter:123] Loss: 0.603 | Accuracy: 96.875% \n",
      "[epoch:3, iter:124] Loss: 0.591 | Accuracy: 97.656% \n",
      "[epoch:3, iter:125] Loss: 0.592 | Accuracy: 97.500% \n",
      "[epoch:3, iter:126] Loss: 0.599 | Accuracy: 97.396% \n",
      "[epoch:3, iter:127] Loss: 0.588 | Accuracy: 97.768% \n",
      "[epoch:3, iter:128] Loss: 0.590 | Accuracy: 97.656% \n",
      "[epoch:3, iter:129] Loss: 0.596 | Accuracy: 97.222% \n",
      "[epoch:3, iter:130] Loss: 0.596 | Accuracy: 97.188% \n",
      "[epoch:3, iter:131] Loss: 0.592 | Accuracy: 97.159% \n",
      "[epoch:3, iter:132] Loss: 0.589 | Accuracy: 97.396% \n",
      "[epoch:3, iter:133] Loss: 0.584 | Accuracy: 97.596% \n",
      "[epoch:3, iter:134] Loss: 0.592 | Accuracy: 97.098% \n",
      "[epoch:3, iter:135] Loss: 0.588 | Accuracy: 97.292% \n",
      "[epoch:3, iter:136] Loss: 0.585 | Accuracy: 97.461% \n",
      "[epoch:3, iter:137] Loss: 0.582 | Accuracy: 97.610% \n",
      "[epoch:3, iter:138] Loss: 0.586 | Accuracy: 97.569% \n",
      "[epoch:3, iter:139] Loss: 0.590 | Accuracy: 97.533% \n",
      "[epoch:3, iter:140] Loss: 0.588 | Accuracy: 97.656% \n",
      "[epoch:3, iter:141] Loss: 0.589 | Accuracy: 97.619% \n",
      "[epoch:3, iter:142] Loss: 0.586 | Accuracy: 97.727% \n",
      "[epoch:3, iter:143] Loss: 0.584 | Accuracy: 97.826% \n",
      "[epoch:3, iter:144] Loss: 0.582 | Accuracy: 97.917% \n",
      "[epoch:3, iter:145] Loss: 0.580 | Accuracy: 98.000% \n",
      "[epoch:3, iter:146] Loss: 0.577 | Accuracy: 98.077% \n",
      "[epoch:3, iter:147] Loss: 0.576 | Accuracy: 98.148% \n",
      "[epoch:3, iter:148] Loss: 0.575 | Accuracy: 98.214% \n",
      "[epoch:3, iter:149] Loss: 0.573 | Accuracy: 98.276% \n",
      "[epoch:3, iter:150] Loss: 0.572 | Accuracy: 98.333% \n",
      "[epoch:3, iter:151] Loss: 0.570 | Accuracy: 98.387% \n",
      "[epoch:3, iter:152] Loss: 0.570 | Accuracy: 98.438% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:3, iter:153] Loss: 0.573 | Accuracy: 98.295% \n",
      "[epoch:3, iter:154] Loss: 0.572 | Accuracy: 98.346% \n",
      "[epoch:3, iter:155] Loss: 0.570 | Accuracy: 98.393% \n",
      "[epoch:3, iter:156] Loss: 0.570 | Accuracy: 98.351% \n",
      "[epoch:3, iter:157] Loss: 0.574 | Accuracy: 98.057% \n",
      "[epoch:3, iter:158] Loss: 0.574 | Accuracy: 98.109% \n",
      "[epoch:3, iter:159] Loss: 0.575 | Accuracy: 98.077% \n",
      "[epoch:3, iter:160] Loss: 0.574 | Accuracy: 98.125% \n",
      "[epoch:3, iter:161] Loss: 0.579 | Accuracy: 98.018% \n",
      "[epoch:3, iter:162] Loss: 0.581 | Accuracy: 97.991% \n",
      "[epoch:3, iter:163] Loss: 0.581 | Accuracy: 97.965% \n",
      "[epoch:3, iter:164] Loss: 0.584 | Accuracy: 97.727% \n",
      "[epoch:3, iter:165] Loss: 0.584 | Accuracy: 97.778% \n",
      "[epoch:3, iter:166] Loss: 0.583 | Accuracy: 97.826% \n",
      "[epoch:3, iter:167] Loss: 0.582 | Accuracy: 97.806% \n",
      "[epoch:3, iter:168] Loss: 0.585 | Accuracy: 97.721% \n",
      "[epoch:3, iter:169] Loss: 0.584 | Accuracy: 97.768% \n",
      "[epoch:3, iter:170] Loss: 0.585 | Accuracy: 97.688% \n",
      "[epoch:3, iter:171] Loss: 0.589 | Accuracy: 97.549% \n",
      "[epoch:3, iter:172] Loss: 0.588 | Accuracy: 97.596% \n",
      "[epoch:3, iter:173] Loss: 0.588 | Accuracy: 97.583% \n",
      "[epoch:3, iter:174] Loss: 0.587 | Accuracy: 97.627% \n",
      "[epoch:3, iter:175] Loss: 0.588 | Accuracy: 97.557% \n",
      "[epoch:3, iter:176] Loss: 0.588 | Accuracy: 97.545% \n",
      "[epoch:3, iter:177] Loss: 0.587 | Accuracy: 97.588% \n",
      "[epoch:3, iter:178] Loss: 0.587 | Accuracy: 97.575% \n",
      "[epoch:3, iter:179] Loss: 0.587 | Accuracy: 97.617% \n",
      "[epoch:3, iter:180] Loss: 0.587 | Accuracy: 97.595% \n",
      "Waiting Test!\n",
      "EPOCH=003, Loss: 1.999, Accuracy= 51.429%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (40.952381 --> 51.428571).  Saving model ...\n",
      "\n",
      "Epoch: 4\n",
      "[epoch:4, iter:181] Loss: 0.543 | Accuracy: 100.000% \n",
      "[epoch:4, iter:182] Loss: 0.531 | Accuracy: 100.000% \n",
      "[epoch:4, iter:183] Loss: 0.538 | Accuracy: 100.000% \n",
      "[epoch:4, iter:184] Loss: 0.536 | Accuracy: 100.000% \n",
      "[epoch:4, iter:185] Loss: 0.537 | Accuracy: 100.000% \n",
      "[epoch:4, iter:186] Loss: 0.536 | Accuracy: 100.000% \n",
      "[epoch:4, iter:187] Loss: 0.534 | Accuracy: 100.000% \n",
      "[epoch:4, iter:188] Loss: 0.537 | Accuracy: 100.000% \n",
      "[epoch:4, iter:189] Loss: 0.536 | Accuracy: 100.000% \n",
      "[epoch:4, iter:190] Loss: 0.537 | Accuracy: 100.000% \n",
      "[epoch:4, iter:191] Loss: 0.539 | Accuracy: 100.000% \n",
      "[epoch:4, iter:192] Loss: 0.537 | Accuracy: 100.000% \n",
      "[epoch:4, iter:193] Loss: 0.543 | Accuracy: 99.519% \n",
      "[epoch:4, iter:194] Loss: 0.544 | Accuracy: 99.554% \n",
      "[epoch:4, iter:195] Loss: 0.543 | Accuracy: 99.583% \n",
      "[epoch:4, iter:196] Loss: 0.545 | Accuracy: 99.414% \n",
      "[epoch:4, iter:197] Loss: 0.547 | Accuracy: 99.449% \n",
      "[epoch:4, iter:198] Loss: 0.553 | Accuracy: 99.132% \n",
      "[epoch:4, iter:199] Loss: 0.552 | Accuracy: 99.178% \n",
      "[epoch:4, iter:200] Loss: 0.554 | Accuracy: 98.906% \n",
      "[epoch:4, iter:201] Loss: 0.553 | Accuracy: 98.958% \n",
      "[epoch:4, iter:202] Loss: 0.552 | Accuracy: 99.006% \n",
      "[epoch:4, iter:203] Loss: 0.552 | Accuracy: 99.049% \n",
      "[epoch:4, iter:204] Loss: 0.551 | Accuracy: 99.089% \n",
      "[epoch:4, iter:205] Loss: 0.554 | Accuracy: 98.875% \n",
      "[epoch:4, iter:206] Loss: 0.558 | Accuracy: 98.798% \n",
      "[epoch:4, iter:207] Loss: 0.557 | Accuracy: 98.843% \n",
      "[epoch:4, iter:208] Loss: 0.556 | Accuracy: 98.884% \n",
      "[epoch:4, iter:209] Loss: 0.556 | Accuracy: 98.815% \n",
      "[epoch:4, iter:210] Loss: 0.558 | Accuracy: 98.750% \n",
      "[epoch:4, iter:211] Loss: 0.559 | Accuracy: 98.690% \n",
      "[epoch:4, iter:212] Loss: 0.558 | Accuracy: 98.730% \n",
      "[epoch:4, iter:213] Loss: 0.557 | Accuracy: 98.769% \n",
      "[epoch:4, iter:214] Loss: 0.559 | Accuracy: 98.713% \n",
      "[epoch:4, iter:215] Loss: 0.560 | Accuracy: 98.661% \n",
      "[epoch:4, iter:216] Loss: 0.559 | Accuracy: 98.611% \n",
      "[epoch:4, iter:217] Loss: 0.560 | Accuracy: 98.564% \n",
      "[epoch:4, iter:218] Loss: 0.558 | Accuracy: 98.602% \n",
      "[epoch:4, iter:219] Loss: 0.558 | Accuracy: 98.638% \n",
      "[epoch:4, iter:220] Loss: 0.558 | Accuracy: 98.594% \n",
      "[epoch:4, iter:221] Loss: 0.557 | Accuracy: 98.628% \n",
      "[epoch:4, iter:222] Loss: 0.556 | Accuracy: 98.661% \n",
      "[epoch:4, iter:223] Loss: 0.556 | Accuracy: 98.619% \n",
      "[epoch:4, iter:224] Loss: 0.555 | Accuracy: 98.651% \n",
      "[epoch:4, iter:225] Loss: 0.556 | Accuracy: 98.681% \n",
      "[epoch:4, iter:226] Loss: 0.555 | Accuracy: 98.709% \n",
      "[epoch:4, iter:227] Loss: 0.554 | Accuracy: 98.737% \n",
      "[epoch:4, iter:228] Loss: 0.554 | Accuracy: 98.763% \n",
      "[epoch:4, iter:229] Loss: 0.553 | Accuracy: 98.788% \n",
      "[epoch:4, iter:230] Loss: 0.555 | Accuracy: 98.688% \n",
      "[epoch:4, iter:231] Loss: 0.555 | Accuracy: 98.652% \n",
      "[epoch:4, iter:232] Loss: 0.556 | Accuracy: 98.618% \n",
      "[epoch:4, iter:233] Loss: 0.557 | Accuracy: 98.585% \n",
      "[epoch:4, iter:234] Loss: 0.556 | Accuracy: 98.611% \n",
      "[epoch:4, iter:235] Loss: 0.555 | Accuracy: 98.636% \n",
      "[epoch:4, iter:236] Loss: 0.555 | Accuracy: 98.661% \n",
      "[epoch:4, iter:237] Loss: 0.556 | Accuracy: 98.575% \n",
      "[epoch:4, iter:238] Loss: 0.555 | Accuracy: 98.599% \n",
      "[epoch:4, iter:239] Loss: 0.555 | Accuracy: 98.623% \n",
      "[epoch:4, iter:240] Loss: 0.554 | Accuracy: 98.641% \n",
      "Waiting Test!\n",
      "EPOCH=004, Loss: 2.138, Accuracy= 32.381%\n",
      "Training complete in 0m 11s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "\n",
      "Epoch: 5\n",
      "[epoch:5, iter:241] Loss: 0.529 | Accuracy: 100.000% \n",
      "[epoch:5, iter:242] Loss: 0.520 | Accuracy: 100.000% \n",
      "[epoch:5, iter:243] Loss: 0.538 | Accuracy: 97.917% \n",
      "[epoch:5, iter:244] Loss: 0.543 | Accuracy: 97.656% \n",
      "[epoch:5, iter:245] Loss: 0.538 | Accuracy: 98.125% \n",
      "[epoch:5, iter:246] Loss: 0.581 | Accuracy: 96.875% \n",
      "[epoch:5, iter:247] Loss: 0.574 | Accuracy: 97.321% \n",
      "[epoch:5, iter:248] Loss: 0.582 | Accuracy: 97.266% \n",
      "[epoch:5, iter:249] Loss: 0.575 | Accuracy: 97.569% \n",
      "[epoch:5, iter:250] Loss: 0.572 | Accuracy: 97.812% \n",
      "[epoch:5, iter:251] Loss: 0.568 | Accuracy: 98.011% \n",
      "[epoch:5, iter:252] Loss: 0.564 | Accuracy: 98.177% \n",
      "[epoch:5, iter:253] Loss: 0.564 | Accuracy: 98.077% \n",
      "[epoch:5, iter:254] Loss: 0.561 | Accuracy: 98.214% \n",
      "[epoch:5, iter:255] Loss: 0.559 | Accuracy: 98.333% \n",
      "[epoch:5, iter:256] Loss: 0.556 | Accuracy: 98.438% \n",
      "[epoch:5, iter:257] Loss: 0.557 | Accuracy: 98.529% \n",
      "[epoch:5, iter:258] Loss: 0.556 | Accuracy: 98.611% \n",
      "[epoch:5, iter:259] Loss: 0.555 | Accuracy: 98.684% \n",
      "[epoch:5, iter:260] Loss: 0.555 | Accuracy: 98.594% \n",
      "[epoch:5, iter:261] Loss: 0.553 | Accuracy: 98.661% \n",
      "[epoch:5, iter:262] Loss: 0.560 | Accuracy: 98.438% \n",
      "[epoch:5, iter:263] Loss: 0.558 | Accuracy: 98.505% \n",
      "[epoch:5, iter:264] Loss: 0.557 | Accuracy: 98.568% \n",
      "[epoch:5, iter:265] Loss: 0.559 | Accuracy: 98.500% \n",
      "[epoch:5, iter:266] Loss: 0.557 | Accuracy: 98.558% \n",
      "[epoch:5, iter:267] Loss: 0.558 | Accuracy: 98.495% \n",
      "[epoch:5, iter:268] Loss: 0.558 | Accuracy: 98.438% \n",
      "[epoch:5, iter:269] Loss: 0.559 | Accuracy: 98.276% \n",
      "[epoch:5, iter:270] Loss: 0.560 | Accuracy: 98.229% \n",
      "[epoch:5, iter:271] Loss: 0.561 | Accuracy: 98.185% \n",
      "[epoch:5, iter:272] Loss: 0.560 | Accuracy: 98.242% \n",
      "[epoch:5, iter:273] Loss: 0.560 | Accuracy: 98.201% \n",
      "[epoch:5, iter:274] Loss: 0.559 | Accuracy: 98.254% \n",
      "[epoch:5, iter:275] Loss: 0.559 | Accuracy: 98.214% \n",
      "[epoch:5, iter:276] Loss: 0.558 | Accuracy: 98.264% \n",
      "[epoch:5, iter:277] Loss: 0.558 | Accuracy: 98.311% \n",
      "[epoch:5, iter:278] Loss: 0.557 | Accuracy: 98.355% \n",
      "[epoch:5, iter:279] Loss: 0.556 | Accuracy: 98.397% \n",
      "[epoch:5, iter:280] Loss: 0.558 | Accuracy: 98.281% \n",
      "[epoch:5, iter:281] Loss: 0.557 | Accuracy: 98.323% \n",
      "[epoch:5, iter:282] Loss: 0.556 | Accuracy: 98.363% \n",
      "[epoch:5, iter:283] Loss: 0.556 | Accuracy: 98.401% \n",
      "[epoch:5, iter:284] Loss: 0.556 | Accuracy: 98.366% \n",
      "[epoch:5, iter:285] Loss: 0.556 | Accuracy: 98.333% \n",
      "[epoch:5, iter:286] Loss: 0.555 | Accuracy: 98.370% \n",
      "[epoch:5, iter:287] Loss: 0.555 | Accuracy: 98.404% \n",
      "[epoch:5, iter:288] Loss: 0.555 | Accuracy: 98.372% \n",
      "[epoch:5, iter:289] Loss: 0.556 | Accuracy: 98.342% \n",
      "[epoch:5, iter:290] Loss: 0.557 | Accuracy: 98.312% \n",
      "[epoch:5, iter:291] Loss: 0.556 | Accuracy: 98.346% \n",
      "[epoch:5, iter:292] Loss: 0.556 | Accuracy: 98.317% \n",
      "[epoch:5, iter:293] Loss: 0.556 | Accuracy: 98.349% \n",
      "[epoch:5, iter:294] Loss: 0.555 | Accuracy: 98.380% \n",
      "[epoch:5, iter:295] Loss: 0.555 | Accuracy: 98.409% \n",
      "[epoch:5, iter:296] Loss: 0.555 | Accuracy: 98.382% \n",
      "[epoch:5, iter:297] Loss: 0.554 | Accuracy: 98.410% \n",
      "[epoch:5, iter:298] Loss: 0.554 | Accuracy: 98.438% \n",
      "[epoch:5, iter:299] Loss: 0.553 | Accuracy: 98.464% \n",
      "[epoch:5, iter:300] Loss: 0.552 | Accuracy: 98.484% \n",
      "Waiting Test!\n",
      "EPOCH=005, Loss: 1.784, Accuracy= 52.381%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (51.428571 --> 52.380952).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 6\n",
      "[epoch:6, iter:301] Loss: 0.524 | Accuracy: 100.000% \n",
      "[epoch:6, iter:302] Loss: 0.520 | Accuracy: 100.000% \n",
      "[epoch:6, iter:303] Loss: 0.517 | Accuracy: 100.000% \n",
      "[epoch:6, iter:304] Loss: 0.526 | Accuracy: 99.219% \n",
      "[epoch:6, iter:305] Loss: 0.522 | Accuracy: 99.375% \n",
      "[epoch:6, iter:306] Loss: 0.524 | Accuracy: 99.479% \n",
      "[epoch:6, iter:307] Loss: 0.534 | Accuracy: 99.107% \n",
      "[epoch:6, iter:308] Loss: 0.538 | Accuracy: 98.828% \n",
      "[epoch:6, iter:309] Loss: 0.549 | Accuracy: 98.611% \n",
      "[epoch:6, iter:310] Loss: 0.547 | Accuracy: 98.750% \n",
      "[epoch:6, iter:311] Loss: 0.547 | Accuracy: 98.580% \n",
      "[epoch:6, iter:312] Loss: 0.545 | Accuracy: 98.698% \n",
      "[epoch:6, iter:313] Loss: 0.546 | Accuracy: 98.558% \n",
      "[epoch:6, iter:314] Loss: 0.544 | Accuracy: 98.661% \n",
      "[epoch:6, iter:315] Loss: 0.548 | Accuracy: 98.333% \n",
      "[epoch:6, iter:316] Loss: 0.546 | Accuracy: 98.438% \n",
      "[epoch:6, iter:317] Loss: 0.544 | Accuracy: 98.529% \n",
      "[epoch:6, iter:318] Loss: 0.544 | Accuracy: 98.438% \n",
      "[epoch:6, iter:319] Loss: 0.542 | Accuracy: 98.520% \n",
      "[epoch:6, iter:320] Loss: 0.545 | Accuracy: 98.281% \n",
      "[epoch:6, iter:321] Loss: 0.544 | Accuracy: 98.363% \n",
      "[epoch:6, iter:322] Loss: 0.543 | Accuracy: 98.438% \n",
      "[epoch:6, iter:323] Loss: 0.543 | Accuracy: 98.370% \n",
      "[epoch:6, iter:324] Loss: 0.542 | Accuracy: 98.438% \n",
      "[epoch:6, iter:325] Loss: 0.542 | Accuracy: 98.500% \n",
      "[epoch:6, iter:326] Loss: 0.541 | Accuracy: 98.558% \n",
      "[epoch:6, iter:327] Loss: 0.540 | Accuracy: 98.611% \n",
      "[epoch:6, iter:328] Loss: 0.539 | Accuracy: 98.661% \n",
      "[epoch:6, iter:329] Loss: 0.538 | Accuracy: 98.707% \n",
      "[epoch:6, iter:330] Loss: 0.538 | Accuracy: 98.750% \n",
      "[epoch:6, iter:331] Loss: 0.538 | Accuracy: 98.790% \n",
      "[epoch:6, iter:332] Loss: 0.537 | Accuracy: 98.828% \n",
      "[epoch:6, iter:333] Loss: 0.536 | Accuracy: 98.864% \n",
      "[epoch:6, iter:334] Loss: 0.536 | Accuracy: 98.897% \n",
      "[epoch:6, iter:335] Loss: 0.535 | Accuracy: 98.929% \n",
      "[epoch:6, iter:336] Loss: 0.535 | Accuracy: 98.958% \n",
      "[epoch:6, iter:337] Loss: 0.535 | Accuracy: 98.902% \n",
      "[epoch:6, iter:338] Loss: 0.535 | Accuracy: 98.931% \n",
      "[epoch:6, iter:339] Loss: 0.535 | Accuracy: 98.958% \n",
      "[epoch:6, iter:340] Loss: 0.536 | Accuracy: 98.906% \n",
      "[epoch:6, iter:341] Loss: 0.535 | Accuracy: 98.933% \n",
      "[epoch:6, iter:342] Loss: 0.535 | Accuracy: 98.958% \n",
      "[epoch:6, iter:343] Loss: 0.534 | Accuracy: 98.983% \n",
      "[epoch:6, iter:344] Loss: 0.534 | Accuracy: 99.006% \n",
      "[epoch:6, iter:345] Loss: 0.534 | Accuracy: 98.958% \n",
      "[epoch:6, iter:346] Loss: 0.534 | Accuracy: 98.981% \n",
      "[epoch:6, iter:347] Loss: 0.533 | Accuracy: 99.003% \n",
      "[epoch:6, iter:348] Loss: 0.533 | Accuracy: 99.023% \n",
      "[epoch:6, iter:349] Loss: 0.533 | Accuracy: 99.043% \n",
      "[epoch:6, iter:350] Loss: 0.533 | Accuracy: 99.062% \n",
      "[epoch:6, iter:351] Loss: 0.532 | Accuracy: 99.081% \n",
      "[epoch:6, iter:352] Loss: 0.532 | Accuracy: 99.099% \n",
      "[epoch:6, iter:353] Loss: 0.532 | Accuracy: 99.116% \n",
      "[epoch:6, iter:354] Loss: 0.531 | Accuracy: 99.132% \n",
      "[epoch:6, iter:355] Loss: 0.531 | Accuracy: 99.148% \n",
      "[epoch:6, iter:356] Loss: 0.531 | Accuracy: 99.163% \n",
      "[epoch:6, iter:357] Loss: 0.532 | Accuracy: 99.123% \n",
      "[epoch:6, iter:358] Loss: 0.532 | Accuracy: 99.138% \n",
      "[epoch:6, iter:359] Loss: 0.532 | Accuracy: 99.100% \n",
      "[epoch:6, iter:360] Loss: 0.532 | Accuracy: 99.111% \n",
      "Waiting Test!\n",
      "EPOCH=006, Loss: 1.829, Accuracy= 58.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (52.380952 --> 58.095238).  Saving model ...\n",
      "\n",
      "Epoch: 7\n",
      "[epoch:7, iter:361] Loss: 0.513 | Accuracy: 100.000% \n",
      "[epoch:7, iter:362] Loss: 0.511 | Accuracy: 100.000% \n",
      "[epoch:7, iter:363] Loss: 0.511 | Accuracy: 100.000% \n",
      "[epoch:7, iter:364] Loss: 0.510 | Accuracy: 100.000% \n",
      "[epoch:7, iter:365] Loss: 0.513 | Accuracy: 100.000% \n",
      "[epoch:7, iter:366] Loss: 0.516 | Accuracy: 100.000% \n",
      "[epoch:7, iter:367] Loss: 0.515 | Accuracy: 100.000% \n",
      "[epoch:7, iter:368] Loss: 0.515 | Accuracy: 100.000% \n",
      "[epoch:7, iter:369] Loss: 0.515 | Accuracy: 100.000% \n",
      "[epoch:7, iter:370] Loss: 0.514 | Accuracy: 100.000% \n",
      "[epoch:7, iter:371] Loss: 0.514 | Accuracy: 100.000% \n",
      "[epoch:7, iter:372] Loss: 0.513 | Accuracy: 100.000% \n",
      "[epoch:7, iter:373] Loss: 0.513 | Accuracy: 100.000% \n",
      "[epoch:7, iter:374] Loss: 0.514 | Accuracy: 100.000% \n",
      "[epoch:7, iter:375] Loss: 0.515 | Accuracy: 100.000% \n",
      "[epoch:7, iter:376] Loss: 0.515 | Accuracy: 100.000% \n",
      "[epoch:7, iter:377] Loss: 0.515 | Accuracy: 100.000% \n",
      "[epoch:7, iter:378] Loss: 0.515 | Accuracy: 100.000% \n",
      "[epoch:7, iter:379] Loss: 0.514 | Accuracy: 100.000% \n",
      "[epoch:7, iter:380] Loss: 0.514 | Accuracy: 100.000% \n",
      "[epoch:7, iter:381] Loss: 0.514 | Accuracy: 100.000% \n",
      "[epoch:7, iter:382] Loss: 0.517 | Accuracy: 99.858% \n",
      "[epoch:7, iter:383] Loss: 0.520 | Accuracy: 99.728% \n",
      "[epoch:7, iter:384] Loss: 0.520 | Accuracy: 99.740% \n",
      "[epoch:7, iter:385] Loss: 0.520 | Accuracy: 99.750% \n",
      "[epoch:7, iter:386] Loss: 0.520 | Accuracy: 99.760% \n",
      "[epoch:7, iter:387] Loss: 0.519 | Accuracy: 99.769% \n",
      "[epoch:7, iter:388] Loss: 0.519 | Accuracy: 99.777% \n",
      "[epoch:7, iter:389] Loss: 0.519 | Accuracy: 99.784% \n",
      "[epoch:7, iter:390] Loss: 0.519 | Accuracy: 99.792% \n",
      "[epoch:7, iter:391] Loss: 0.519 | Accuracy: 99.798% \n",
      "[epoch:7, iter:392] Loss: 0.519 | Accuracy: 99.805% \n",
      "[epoch:7, iter:393] Loss: 0.519 | Accuracy: 99.811% \n",
      "[epoch:7, iter:394] Loss: 0.520 | Accuracy: 99.724% \n",
      "[epoch:7, iter:395] Loss: 0.520 | Accuracy: 99.732% \n",
      "[epoch:7, iter:396] Loss: 0.521 | Accuracy: 99.653% \n",
      "[epoch:7, iter:397] Loss: 0.522 | Accuracy: 99.578% \n",
      "[epoch:7, iter:398] Loss: 0.522 | Accuracy: 99.589% \n",
      "[epoch:7, iter:399] Loss: 0.522 | Accuracy: 99.599% \n",
      "[epoch:7, iter:400] Loss: 0.522 | Accuracy: 99.609% \n",
      "[epoch:7, iter:401] Loss: 0.521 | Accuracy: 99.619% \n",
      "[epoch:7, iter:402] Loss: 0.521 | Accuracy: 99.628% \n",
      "[epoch:7, iter:403] Loss: 0.521 | Accuracy: 99.637% \n",
      "[epoch:7, iter:404] Loss: 0.521 | Accuracy: 99.645% \n",
      "[epoch:7, iter:405] Loss: 0.521 | Accuracy: 99.583% \n",
      "[epoch:7, iter:406] Loss: 0.521 | Accuracy: 99.592% \n",
      "[epoch:7, iter:407] Loss: 0.521 | Accuracy: 99.601% \n",
      "[epoch:7, iter:408] Loss: 0.523 | Accuracy: 99.414% \n",
      "[epoch:7, iter:409] Loss: 0.524 | Accuracy: 99.362% \n",
      "[epoch:7, iter:410] Loss: 0.524 | Accuracy: 99.375% \n",
      "[epoch:7, iter:411] Loss: 0.524 | Accuracy: 99.387% \n",
      "[epoch:7, iter:412] Loss: 0.524 | Accuracy: 99.399% \n",
      "[epoch:7, iter:413] Loss: 0.524 | Accuracy: 99.410% \n",
      "[epoch:7, iter:414] Loss: 0.524 | Accuracy: 99.421% \n",
      "[epoch:7, iter:415] Loss: 0.524 | Accuracy: 99.432% \n",
      "[epoch:7, iter:416] Loss: 0.524 | Accuracy: 99.442% \n",
      "[epoch:7, iter:417] Loss: 0.524 | Accuracy: 99.452% \n",
      "[epoch:7, iter:418] Loss: 0.523 | Accuracy: 99.461% \n",
      "[epoch:7, iter:419] Loss: 0.523 | Accuracy: 99.470% \n",
      "[epoch:7, iter:420] Loss: 0.523 | Accuracy: 99.477% \n",
      "Waiting Test!\n",
      "EPOCH=007, Loss: 1.612, Accuracy= 46.667%\n",
      "Training complete in 0m 11s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "\n",
      "Epoch: 8\n",
      "[epoch:8, iter:421] Loss: 0.510 | Accuracy: 100.000% \n",
      "[epoch:8, iter:422] Loss: 0.516 | Accuracy: 100.000% \n",
      "[epoch:8, iter:423] Loss: 0.516 | Accuracy: 100.000% \n",
      "[epoch:8, iter:424] Loss: 0.515 | Accuracy: 100.000% \n",
      "[epoch:8, iter:425] Loss: 0.514 | Accuracy: 100.000% \n",
      "[epoch:8, iter:426] Loss: 0.513 | Accuracy: 100.000% \n",
      "[epoch:8, iter:427] Loss: 0.513 | Accuracy: 100.000% \n",
      "[epoch:8, iter:428] Loss: 0.513 | Accuracy: 100.000% \n",
      "[epoch:8, iter:429] Loss: 0.512 | Accuracy: 100.000% \n",
      "[epoch:8, iter:430] Loss: 0.512 | Accuracy: 100.000% \n",
      "[epoch:8, iter:431] Loss: 0.512 | Accuracy: 100.000% \n",
      "[epoch:8, iter:432] Loss: 0.511 | Accuracy: 100.000% \n",
      "[epoch:8, iter:433] Loss: 0.511 | Accuracy: 100.000% \n",
      "[epoch:8, iter:434] Loss: 0.512 | Accuracy: 100.000% \n",
      "[epoch:8, iter:435] Loss: 0.513 | Accuracy: 100.000% \n",
      "[epoch:8, iter:436] Loss: 0.517 | Accuracy: 99.805% \n",
      "[epoch:8, iter:437] Loss: 0.516 | Accuracy: 99.816% \n",
      "[epoch:8, iter:438] Loss: 0.516 | Accuracy: 99.826% \n",
      "[epoch:8, iter:439] Loss: 0.516 | Accuracy: 99.836% \n",
      "[epoch:8, iter:440] Loss: 0.516 | Accuracy: 99.844% \n",
      "[epoch:8, iter:441] Loss: 0.516 | Accuracy: 99.851% \n",
      "[epoch:8, iter:442] Loss: 0.515 | Accuracy: 99.858% \n",
      "[epoch:8, iter:443] Loss: 0.515 | Accuracy: 99.864% \n",
      "[epoch:8, iter:444] Loss: 0.515 | Accuracy: 99.870% \n",
      "[epoch:8, iter:445] Loss: 0.515 | Accuracy: 99.875% \n",
      "[epoch:8, iter:446] Loss: 0.518 | Accuracy: 99.760% \n",
      "[epoch:8, iter:447] Loss: 0.520 | Accuracy: 99.653% \n",
      "[epoch:8, iter:448] Loss: 0.520 | Accuracy: 99.665% \n",
      "[epoch:8, iter:449] Loss: 0.520 | Accuracy: 99.677% \n",
      "[epoch:8, iter:450] Loss: 0.520 | Accuracy: 99.688% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:8, iter:451] Loss: 0.519 | Accuracy: 99.698% \n",
      "[epoch:8, iter:452] Loss: 0.519 | Accuracy: 99.707% \n",
      "[epoch:8, iter:453] Loss: 0.519 | Accuracy: 99.716% \n",
      "[epoch:8, iter:454] Loss: 0.519 | Accuracy: 99.724% \n",
      "[epoch:8, iter:455] Loss: 0.519 | Accuracy: 99.732% \n",
      "[epoch:8, iter:456] Loss: 0.520 | Accuracy: 99.653% \n",
      "[epoch:8, iter:457] Loss: 0.520 | Accuracy: 99.662% \n",
      "[epoch:8, iter:458] Loss: 0.519 | Accuracy: 99.671% \n",
      "[epoch:8, iter:459] Loss: 0.519 | Accuracy: 99.679% \n",
      "[epoch:8, iter:460] Loss: 0.519 | Accuracy: 99.688% \n",
      "[epoch:8, iter:461] Loss: 0.521 | Accuracy: 99.619% \n",
      "[epoch:8, iter:462] Loss: 0.522 | Accuracy: 99.628% \n",
      "[epoch:8, iter:463] Loss: 0.521 | Accuracy: 99.637% \n",
      "[epoch:8, iter:464] Loss: 0.521 | Accuracy: 99.645% \n",
      "[epoch:8, iter:465] Loss: 0.521 | Accuracy: 99.653% \n",
      "[epoch:8, iter:466] Loss: 0.521 | Accuracy: 99.660% \n",
      "[epoch:8, iter:467] Loss: 0.520 | Accuracy: 99.668% \n",
      "[epoch:8, iter:468] Loss: 0.520 | Accuracy: 99.674% \n",
      "[epoch:8, iter:469] Loss: 0.520 | Accuracy: 99.681% \n",
      "[epoch:8, iter:470] Loss: 0.520 | Accuracy: 99.688% \n",
      "[epoch:8, iter:471] Loss: 0.520 | Accuracy: 99.632% \n",
      "[epoch:8, iter:472] Loss: 0.521 | Accuracy: 99.579% \n",
      "[epoch:8, iter:473] Loss: 0.521 | Accuracy: 99.587% \n",
      "[epoch:8, iter:474] Loss: 0.521 | Accuracy: 99.595% \n",
      "[epoch:8, iter:475] Loss: 0.522 | Accuracy: 99.545% \n",
      "[epoch:8, iter:476] Loss: 0.522 | Accuracy: 99.554% \n",
      "[epoch:8, iter:477] Loss: 0.522 | Accuracy: 99.561% \n",
      "[epoch:8, iter:478] Loss: 0.522 | Accuracy: 99.569% \n",
      "[epoch:8, iter:479] Loss: 0.522 | Accuracy: 99.576% \n",
      "[epoch:8, iter:480] Loss: 0.521 | Accuracy: 99.582% \n",
      "Waiting Test!\n",
      "EPOCH=008, Loss: 1.091, Accuracy= 80.000%\n",
      "Training complete in 0m 10s\n",
      "Validation accuracy increased (58.095238 --> 80.000000).  Saving model ...\n",
      "\n",
      "Epoch: 9\n",
      "[epoch:9, iter:481] Loss: 0.526 | Accuracy: 100.000% \n",
      "[epoch:9, iter:482] Loss: 0.520 | Accuracy: 100.000% \n",
      "[epoch:9, iter:483] Loss: 0.521 | Accuracy: 100.000% \n",
      "[epoch:9, iter:484] Loss: 0.518 | Accuracy: 100.000% \n",
      "[epoch:9, iter:485] Loss: 0.516 | Accuracy: 100.000% \n",
      "[epoch:9, iter:486] Loss: 0.516 | Accuracy: 100.000% \n",
      "[epoch:9, iter:487] Loss: 0.515 | Accuracy: 100.000% \n",
      "[epoch:9, iter:488] Loss: 0.514 | Accuracy: 100.000% \n",
      "[epoch:9, iter:489] Loss: 0.515 | Accuracy: 100.000% \n",
      "[epoch:9, iter:490] Loss: 0.515 | Accuracy: 100.000% \n",
      "[epoch:9, iter:491] Loss: 0.514 | Accuracy: 100.000% \n",
      "[epoch:9, iter:492] Loss: 0.514 | Accuracy: 100.000% \n",
      "[epoch:9, iter:493] Loss: 0.513 | Accuracy: 100.000% \n",
      "[epoch:9, iter:494] Loss: 0.513 | Accuracy: 100.000% \n",
      "[epoch:9, iter:495] Loss: 0.513 | Accuracy: 100.000% \n",
      "[epoch:9, iter:496] Loss: 0.514 | Accuracy: 100.000% \n",
      "[epoch:9, iter:497] Loss: 0.514 | Accuracy: 100.000% \n",
      "[epoch:9, iter:498] Loss: 0.514 | Accuracy: 100.000% \n",
      "[epoch:9, iter:499] Loss: 0.515 | Accuracy: 99.836% \n",
      "[epoch:9, iter:500] Loss: 0.516 | Accuracy: 99.844% \n",
      "[epoch:9, iter:501] Loss: 0.516 | Accuracy: 99.851% \n",
      "[epoch:9, iter:502] Loss: 0.515 | Accuracy: 99.858% \n",
      "[epoch:9, iter:503] Loss: 0.515 | Accuracy: 99.864% \n",
      "[epoch:9, iter:504] Loss: 0.515 | Accuracy: 99.870% \n",
      "[epoch:9, iter:505] Loss: 0.515 | Accuracy: 99.875% \n",
      "[epoch:9, iter:506] Loss: 0.515 | Accuracy: 99.880% \n",
      "[epoch:9, iter:507] Loss: 0.515 | Accuracy: 99.884% \n",
      "[epoch:9, iter:508] Loss: 0.515 | Accuracy: 99.888% \n",
      "[epoch:9, iter:509] Loss: 0.515 | Accuracy: 99.892% \n",
      "[epoch:9, iter:510] Loss: 0.515 | Accuracy: 99.896% \n",
      "[epoch:9, iter:511] Loss: 0.515 | Accuracy: 99.899% \n",
      "[epoch:9, iter:512] Loss: 0.515 | Accuracy: 99.902% \n",
      "[epoch:9, iter:513] Loss: 0.515 | Accuracy: 99.905% \n",
      "[epoch:9, iter:514] Loss: 0.515 | Accuracy: 99.908% \n",
      "[epoch:9, iter:515] Loss: 0.515 | Accuracy: 99.911% \n",
      "[epoch:9, iter:516] Loss: 0.515 | Accuracy: 99.913% \n",
      "[epoch:9, iter:517] Loss: 0.515 | Accuracy: 99.916% \n",
      "[epoch:9, iter:518] Loss: 0.515 | Accuracy: 99.918% \n",
      "[epoch:9, iter:519] Loss: 0.515 | Accuracy: 99.920% \n",
      "[epoch:9, iter:520] Loss: 0.515 | Accuracy: 99.922% \n",
      "[epoch:9, iter:521] Loss: 0.515 | Accuracy: 99.924% \n",
      "[epoch:9, iter:522] Loss: 0.515 | Accuracy: 99.926% \n",
      "[epoch:9, iter:523] Loss: 0.515 | Accuracy: 99.927% \n",
      "[epoch:9, iter:524] Loss: 0.515 | Accuracy: 99.929% \n",
      "[epoch:9, iter:525] Loss: 0.515 | Accuracy: 99.931% \n",
      "[epoch:9, iter:526] Loss: 0.515 | Accuracy: 99.932% \n",
      "[epoch:9, iter:527] Loss: 0.515 | Accuracy: 99.934% \n",
      "[epoch:9, iter:528] Loss: 0.515 | Accuracy: 99.935% \n",
      "[epoch:9, iter:529] Loss: 0.515 | Accuracy: 99.936% \n",
      "[epoch:9, iter:530] Loss: 0.515 | Accuracy: 99.938% \n",
      "[epoch:9, iter:531] Loss: 0.514 | Accuracy: 99.939% \n",
      "[epoch:9, iter:532] Loss: 0.514 | Accuracy: 99.940% \n",
      "[epoch:9, iter:533] Loss: 0.514 | Accuracy: 99.941% \n",
      "[epoch:9, iter:534] Loss: 0.514 | Accuracy: 99.942% \n",
      "[epoch:9, iter:535] Loss: 0.514 | Accuracy: 99.943% \n",
      "[epoch:9, iter:536] Loss: 0.514 | Accuracy: 99.944% \n",
      "[epoch:9, iter:537] Loss: 0.514 | Accuracy: 99.945% \n",
      "[epoch:9, iter:538] Loss: 0.514 | Accuracy: 99.946% \n",
      "[epoch:9, iter:539] Loss: 0.514 | Accuracy: 99.947% \n",
      "[epoch:9, iter:540] Loss: 0.514 | Accuracy: 99.948% \n",
      "Waiting Test!\n",
      "EPOCH=009, Loss: 1.060, Accuracy= 76.190%\n",
      "Training complete in 0m 10s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "\n",
      "Epoch: 10\n",
      "[epoch:10, iter:541] Loss: 0.514 | Accuracy: 100.000% \n",
      "[epoch:10, iter:542] Loss: 0.513 | Accuracy: 100.000% \n",
      "[epoch:10, iter:543] Loss: 0.511 | Accuracy: 100.000% \n",
      "[epoch:10, iter:544] Loss: 0.509 | Accuracy: 100.000% \n",
      "[epoch:10, iter:545] Loss: 0.509 | Accuracy: 100.000% \n",
      "[epoch:10, iter:546] Loss: 0.510 | Accuracy: 100.000% \n",
      "[epoch:10, iter:547] Loss: 0.510 | Accuracy: 100.000% \n",
      "[epoch:10, iter:548] Loss: 0.515 | Accuracy: 100.000% \n",
      "[epoch:10, iter:549] Loss: 0.514 | Accuracy: 100.000% \n",
      "[epoch:10, iter:550] Loss: 0.513 | Accuracy: 100.000% \n",
      "[epoch:10, iter:551] Loss: 0.513 | Accuracy: 100.000% \n",
      "[epoch:10, iter:552] Loss: 0.512 | Accuracy: 100.000% \n",
      "[epoch:10, iter:553] Loss: 0.512 | Accuracy: 100.000% \n",
      "[epoch:10, iter:554] Loss: 0.511 | Accuracy: 100.000% \n",
      "[epoch:10, iter:555] Loss: 0.511 | Accuracy: 100.000% \n",
      "[epoch:10, iter:556] Loss: 0.511 | Accuracy: 100.000% \n",
      "[epoch:10, iter:557] Loss: 0.511 | Accuracy: 100.000% \n",
      "[epoch:10, iter:558] Loss: 0.511 | Accuracy: 100.000% \n",
      "[epoch:10, iter:559] Loss: 0.511 | Accuracy: 100.000% \n",
      "[epoch:10, iter:560] Loss: 0.511 | Accuracy: 100.000% \n",
      "[epoch:10, iter:561] Loss: 0.511 | Accuracy: 100.000% \n",
      "[epoch:10, iter:562] Loss: 0.510 | Accuracy: 100.000% \n",
      "[epoch:10, iter:563] Loss: 0.513 | Accuracy: 99.864% \n",
      "[epoch:10, iter:564] Loss: 0.513 | Accuracy: 99.870% \n",
      "[epoch:10, iter:565] Loss: 0.513 | Accuracy: 99.875% \n",
      "[epoch:10, iter:566] Loss: 0.513 | Accuracy: 99.880% \n",
      "[epoch:10, iter:567] Loss: 0.515 | Accuracy: 99.769% \n",
      "[epoch:10, iter:568] Loss: 0.515 | Accuracy: 99.777% \n",
      "[epoch:10, iter:569] Loss: 0.515 | Accuracy: 99.784% \n",
      "[epoch:10, iter:570] Loss: 0.515 | Accuracy: 99.792% \n",
      "[epoch:10, iter:571] Loss: 0.515 | Accuracy: 99.798% \n",
      "[epoch:10, iter:572] Loss: 0.515 | Accuracy: 99.805% \n",
      "[epoch:10, iter:573] Loss: 0.515 | Accuracy: 99.811% \n",
      "[epoch:10, iter:574] Loss: 0.515 | Accuracy: 99.816% \n",
      "[epoch:10, iter:575] Loss: 0.514 | Accuracy: 99.821% \n",
      "[epoch:10, iter:576] Loss: 0.515 | Accuracy: 99.826% \n",
      "[epoch:10, iter:577] Loss: 0.514 | Accuracy: 99.831% \n",
      "[epoch:10, iter:578] Loss: 0.514 | Accuracy: 99.836% \n",
      "[epoch:10, iter:579] Loss: 0.514 | Accuracy: 99.840% \n",
      "[epoch:10, iter:580] Loss: 0.514 | Accuracy: 99.844% \n",
      "[epoch:10, iter:581] Loss: 0.514 | Accuracy: 99.848% \n",
      "[epoch:10, iter:582] Loss: 0.514 | Accuracy: 99.851% \n",
      "[epoch:10, iter:583] Loss: 0.513 | Accuracy: 99.855% \n",
      "[epoch:10, iter:584] Loss: 0.513 | Accuracy: 99.858% \n",
      "[epoch:10, iter:585] Loss: 0.513 | Accuracy: 99.861% \n",
      "[epoch:10, iter:586] Loss: 0.514 | Accuracy: 99.796% \n",
      "[epoch:10, iter:587] Loss: 0.516 | Accuracy: 99.668% \n",
      "[epoch:10, iter:588] Loss: 0.516 | Accuracy: 99.674% \n",
      "[epoch:10, iter:589] Loss: 0.516 | Accuracy: 99.681% \n",
      "[epoch:10, iter:590] Loss: 0.518 | Accuracy: 99.625% \n",
      "[epoch:10, iter:591] Loss: 0.518 | Accuracy: 99.632% \n",
      "[epoch:10, iter:592] Loss: 0.518 | Accuracy: 99.639% \n",
      "[epoch:10, iter:593] Loss: 0.518 | Accuracy: 99.646% \n",
      "[epoch:10, iter:594] Loss: 0.517 | Accuracy: 99.653% \n",
      "[epoch:10, iter:595] Loss: 0.518 | Accuracy: 99.659% \n",
      "[epoch:10, iter:596] Loss: 0.518 | Accuracy: 99.665% \n",
      "[epoch:10, iter:597] Loss: 0.517 | Accuracy: 99.671% \n",
      "[epoch:10, iter:598] Loss: 0.517 | Accuracy: 99.677% \n",
      "[epoch:10, iter:599] Loss: 0.517 | Accuracy: 99.682% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:10, iter:600] Loss: 0.517 | Accuracy: 99.686% \n",
      "Waiting Test!\n",
      "EPOCH=010, Loss: 0.670, Accuracy= 93.333%\n",
      "Training complete in 0m 10s\n",
      "Validation accuracy increased (80.000000 --> 93.333333).  Saving model ...\n",
      "\n",
      "Epoch: 11\n",
      "[epoch:11, iter:601] Loss: 0.509 | Accuracy: 100.000% \n",
      "[epoch:11, iter:602] Loss: 0.507 | Accuracy: 100.000% \n",
      "[epoch:11, iter:603] Loss: 0.509 | Accuracy: 100.000% \n",
      "[epoch:11, iter:604] Loss: 0.508 | Accuracy: 100.000% \n",
      "[epoch:11, iter:605] Loss: 0.508 | Accuracy: 100.000% \n",
      "[epoch:11, iter:606] Loss: 0.508 | Accuracy: 100.000% \n",
      "[epoch:11, iter:607] Loss: 0.508 | Accuracy: 100.000% \n",
      "[epoch:11, iter:608] Loss: 0.508 | Accuracy: 100.000% \n",
      "[epoch:11, iter:609] Loss: 0.508 | Accuracy: 100.000% \n",
      "[epoch:11, iter:610] Loss: 0.507 | Accuracy: 100.000% \n",
      "[epoch:11, iter:611] Loss: 0.507 | Accuracy: 100.000% \n",
      "[epoch:11, iter:612] Loss: 0.507 | Accuracy: 100.000% \n",
      "[epoch:11, iter:613] Loss: 0.508 | Accuracy: 100.000% \n",
      "[epoch:11, iter:614] Loss: 0.513 | Accuracy: 99.777% \n",
      "[epoch:11, iter:615] Loss: 0.513 | Accuracy: 99.792% \n",
      "[epoch:11, iter:616] Loss: 0.513 | Accuracy: 99.805% \n",
      "[epoch:11, iter:617] Loss: 0.513 | Accuracy: 99.816% \n",
      "[epoch:11, iter:618] Loss: 0.513 | Accuracy: 99.826% \n",
      "[epoch:11, iter:619] Loss: 0.513 | Accuracy: 99.836% \n",
      "[epoch:11, iter:620] Loss: 0.512 | Accuracy: 99.844% \n",
      "[epoch:11, iter:621] Loss: 0.512 | Accuracy: 99.851% \n",
      "[epoch:11, iter:622] Loss: 0.512 | Accuracy: 99.858% \n",
      "[epoch:11, iter:623] Loss: 0.512 | Accuracy: 99.864% \n",
      "[epoch:11, iter:624] Loss: 0.512 | Accuracy: 99.870% \n",
      "[epoch:11, iter:625] Loss: 0.514 | Accuracy: 99.750% \n",
      "[epoch:11, iter:626] Loss: 0.514 | Accuracy: 99.760% \n",
      "[epoch:11, iter:627] Loss: 0.514 | Accuracy: 99.769% \n",
      "[epoch:11, iter:628] Loss: 0.515 | Accuracy: 99.665% \n",
      "[epoch:11, iter:629] Loss: 0.515 | Accuracy: 99.677% \n",
      "[epoch:11, iter:630] Loss: 0.514 | Accuracy: 99.688% \n",
      "[epoch:11, iter:631] Loss: 0.518 | Accuracy: 99.597% \n",
      "[epoch:11, iter:632] Loss: 0.518 | Accuracy: 99.609% \n",
      "[epoch:11, iter:633] Loss: 0.517 | Accuracy: 99.621% \n",
      "[epoch:11, iter:634] Loss: 0.517 | Accuracy: 99.632% \n",
      "[epoch:11, iter:635] Loss: 0.517 | Accuracy: 99.643% \n",
      "[epoch:11, iter:636] Loss: 0.520 | Accuracy: 99.566% \n",
      "[epoch:11, iter:637] Loss: 0.520 | Accuracy: 99.578% \n",
      "[epoch:11, iter:638] Loss: 0.520 | Accuracy: 99.589% \n",
      "[epoch:11, iter:639] Loss: 0.520 | Accuracy: 99.599% \n",
      "[epoch:11, iter:640] Loss: 0.520 | Accuracy: 99.609% \n",
      "[epoch:11, iter:641] Loss: 0.520 | Accuracy: 99.619% \n",
      "[epoch:11, iter:642] Loss: 0.519 | Accuracy: 99.628% \n",
      "[epoch:11, iter:643] Loss: 0.519 | Accuracy: 99.637% \n",
      "[epoch:11, iter:644] Loss: 0.519 | Accuracy: 99.645% \n",
      "[epoch:11, iter:645] Loss: 0.519 | Accuracy: 99.653% \n",
      "[epoch:11, iter:646] Loss: 0.519 | Accuracy: 99.592% \n",
      "[epoch:11, iter:647] Loss: 0.520 | Accuracy: 99.535% \n",
      "[epoch:11, iter:648] Loss: 0.520 | Accuracy: 99.544% \n",
      "[epoch:11, iter:649] Loss: 0.520 | Accuracy: 99.554% \n",
      "[epoch:11, iter:650] Loss: 0.519 | Accuracy: 99.562% \n",
      "[epoch:11, iter:651] Loss: 0.519 | Accuracy: 99.571% \n",
      "[epoch:11, iter:652] Loss: 0.519 | Accuracy: 99.579% \n",
      "[epoch:11, iter:653] Loss: 0.519 | Accuracy: 99.587% \n",
      "[epoch:11, iter:654] Loss: 0.519 | Accuracy: 99.595% \n",
      "[epoch:11, iter:655] Loss: 0.519 | Accuracy: 99.602% \n",
      "[epoch:11, iter:656] Loss: 0.519 | Accuracy: 99.609% \n",
      "[epoch:11, iter:657] Loss: 0.518 | Accuracy: 99.616% \n",
      "[epoch:11, iter:658] Loss: 0.518 | Accuracy: 99.623% \n",
      "[epoch:11, iter:659] Loss: 0.519 | Accuracy: 99.629% \n",
      "[epoch:11, iter:660] Loss: 0.518 | Accuracy: 99.634% \n",
      "Waiting Test!\n",
      "EPOCH=011, Loss: 0.822, Accuracy= 91.429%\n",
      "Training complete in 0m 11s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "\n",
      "Epoch: 12\n",
      "[epoch:12, iter:661] Loss: 0.616 | Accuracy: 96.875% \n",
      "[epoch:12, iter:662] Loss: 0.571 | Accuracy: 98.438% \n",
      "[epoch:12, iter:663] Loss: 0.550 | Accuracy: 98.958% \n",
      "[epoch:12, iter:664] Loss: 0.540 | Accuracy: 99.219% \n",
      "[epoch:12, iter:665] Loss: 0.534 | Accuracy: 99.375% \n",
      "[epoch:12, iter:666] Loss: 0.530 | Accuracy: 99.479% \n",
      "[epoch:12, iter:667] Loss: 0.526 | Accuracy: 99.554% \n",
      "[epoch:12, iter:668] Loss: 0.524 | Accuracy: 99.609% \n",
      "[epoch:12, iter:669] Loss: 0.523 | Accuracy: 99.653% \n",
      "[epoch:12, iter:670] Loss: 0.523 | Accuracy: 99.688% \n",
      "[epoch:12, iter:671] Loss: 0.521 | Accuracy: 99.716% \n",
      "[epoch:12, iter:672] Loss: 0.520 | Accuracy: 99.740% \n",
      "[epoch:12, iter:673] Loss: 0.527 | Accuracy: 99.519% \n",
      "[epoch:12, iter:674] Loss: 0.526 | Accuracy: 99.554% \n",
      "[epoch:12, iter:675] Loss: 0.526 | Accuracy: 99.583% \n",
      "[epoch:12, iter:676] Loss: 0.524 | Accuracy: 99.609% \n",
      "[epoch:12, iter:677] Loss: 0.523 | Accuracy: 99.632% \n",
      "[epoch:12, iter:678] Loss: 0.523 | Accuracy: 99.653% \n",
      "[epoch:12, iter:679] Loss: 0.523 | Accuracy: 99.507% \n",
      "[epoch:12, iter:680] Loss: 0.523 | Accuracy: 99.531% \n",
      "[epoch:12, iter:681] Loss: 0.522 | Accuracy: 99.554% \n",
      "[epoch:12, iter:682] Loss: 0.521 | Accuracy: 99.574% \n",
      "[epoch:12, iter:683] Loss: 0.521 | Accuracy: 99.592% \n",
      "[epoch:12, iter:684] Loss: 0.520 | Accuracy: 99.609% \n",
      "[epoch:12, iter:685] Loss: 0.520 | Accuracy: 99.625% \n",
      "[epoch:12, iter:686] Loss: 0.519 | Accuracy: 99.639% \n",
      "[epoch:12, iter:687] Loss: 0.519 | Accuracy: 99.653% \n",
      "[epoch:12, iter:688] Loss: 0.519 | Accuracy: 99.665% \n",
      "[epoch:12, iter:689] Loss: 0.518 | Accuracy: 99.677% \n",
      "[epoch:12, iter:690] Loss: 0.519 | Accuracy: 99.583% \n",
      "[epoch:12, iter:691] Loss: 0.519 | Accuracy: 99.597% \n",
      "[epoch:12, iter:692] Loss: 0.519 | Accuracy: 99.609% \n",
      "[epoch:12, iter:693] Loss: 0.522 | Accuracy: 99.527% \n",
      "[epoch:12, iter:694] Loss: 0.522 | Accuracy: 99.540% \n",
      "[epoch:12, iter:695] Loss: 0.523 | Accuracy: 99.464% \n",
      "[epoch:12, iter:696] Loss: 0.523 | Accuracy: 99.479% \n",
      "[epoch:12, iter:697] Loss: 0.523 | Accuracy: 99.493% \n",
      "[epoch:12, iter:698] Loss: 0.523 | Accuracy: 99.507% \n",
      "[epoch:12, iter:699] Loss: 0.523 | Accuracy: 99.519% \n",
      "[epoch:12, iter:700] Loss: 0.522 | Accuracy: 99.531% \n",
      "[epoch:12, iter:701] Loss: 0.522 | Accuracy: 99.543% \n",
      "[epoch:12, iter:702] Loss: 0.522 | Accuracy: 99.554% \n",
      "[epoch:12, iter:703] Loss: 0.521 | Accuracy: 99.564% \n",
      "[epoch:12, iter:704] Loss: 0.521 | Accuracy: 99.574% \n",
      "[epoch:12, iter:705] Loss: 0.521 | Accuracy: 99.583% \n",
      "[epoch:12, iter:706] Loss: 0.521 | Accuracy: 99.592% \n",
      "[epoch:12, iter:707] Loss: 0.521 | Accuracy: 99.601% \n",
      "[epoch:12, iter:708] Loss: 0.520 | Accuracy: 99.609% \n",
      "[epoch:12, iter:709] Loss: 0.520 | Accuracy: 99.617% \n",
      "[epoch:12, iter:710] Loss: 0.520 | Accuracy: 99.625% \n",
      "[epoch:12, iter:711] Loss: 0.520 | Accuracy: 99.632% \n",
      "[epoch:12, iter:712] Loss: 0.519 | Accuracy: 99.639% \n",
      "[epoch:12, iter:713] Loss: 0.519 | Accuracy: 99.646% \n",
      "[epoch:12, iter:714] Loss: 0.519 | Accuracy: 99.653% \n",
      "[epoch:12, iter:715] Loss: 0.519 | Accuracy: 99.659% \n",
      "[epoch:12, iter:716] Loss: 0.519 | Accuracy: 99.665% \n",
      "[epoch:12, iter:717] Loss: 0.519 | Accuracy: 99.671% \n",
      "[epoch:12, iter:718] Loss: 0.518 | Accuracy: 99.677% \n",
      "[epoch:12, iter:719] Loss: 0.518 | Accuracy: 99.682% \n",
      "[epoch:12, iter:720] Loss: 0.518 | Accuracy: 99.686% \n",
      "Waiting Test!\n",
      "EPOCH=012, Loss: 0.710, Accuracy= 93.333%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (93.333333 --> 93.333333).  Saving model ...\n",
      "\n",
      "Epoch: 13\n",
      "[epoch:13, iter:721] Loss: 0.511 | Accuracy: 100.000% \n",
      "[epoch:13, iter:722] Loss: 0.511 | Accuracy: 100.000% \n",
      "[epoch:13, iter:723] Loss: 0.509 | Accuracy: 100.000% \n",
      "[epoch:13, iter:724] Loss: 0.522 | Accuracy: 99.219% \n",
      "[epoch:13, iter:725] Loss: 0.519 | Accuracy: 99.375% \n",
      "[epoch:13, iter:726] Loss: 0.517 | Accuracy: 99.479% \n",
      "[epoch:13, iter:727] Loss: 0.520 | Accuracy: 99.107% \n",
      "[epoch:13, iter:728] Loss: 0.523 | Accuracy: 98.828% \n",
      "[epoch:13, iter:729] Loss: 0.522 | Accuracy: 98.958% \n",
      "[epoch:13, iter:730] Loss: 0.521 | Accuracy: 99.062% \n",
      "[epoch:13, iter:731] Loss: 0.521 | Accuracy: 99.148% \n",
      "[epoch:13, iter:732] Loss: 0.520 | Accuracy: 99.219% \n",
      "[epoch:13, iter:733] Loss: 0.519 | Accuracy: 99.279% \n",
      "[epoch:13, iter:734] Loss: 0.518 | Accuracy: 99.330% \n",
      "[epoch:13, iter:735] Loss: 0.517 | Accuracy: 99.375% \n",
      "[epoch:13, iter:736] Loss: 0.517 | Accuracy: 99.414% \n",
      "[epoch:13, iter:737] Loss: 0.517 | Accuracy: 99.449% \n",
      "[epoch:13, iter:738] Loss: 0.516 | Accuracy: 99.479% \n",
      "[epoch:13, iter:739] Loss: 0.516 | Accuracy: 99.507% \n",
      "[epoch:13, iter:740] Loss: 0.523 | Accuracy: 99.375% \n",
      "[epoch:13, iter:741] Loss: 0.525 | Accuracy: 99.256% \n",
      "[epoch:13, iter:742] Loss: 0.525 | Accuracy: 99.290% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:13, iter:743] Loss: 0.525 | Accuracy: 99.321% \n",
      "[epoch:13, iter:744] Loss: 0.525 | Accuracy: 99.219% \n",
      "[epoch:13, iter:745] Loss: 0.525 | Accuracy: 99.250% \n",
      "[epoch:13, iter:746] Loss: 0.525 | Accuracy: 99.279% \n",
      "[epoch:13, iter:747] Loss: 0.525 | Accuracy: 99.306% \n",
      "[epoch:13, iter:748] Loss: 0.524 | Accuracy: 99.330% \n",
      "[epoch:13, iter:749] Loss: 0.524 | Accuracy: 99.353% \n",
      "[epoch:13, iter:750] Loss: 0.523 | Accuracy: 99.375% \n",
      "[epoch:13, iter:751] Loss: 0.523 | Accuracy: 99.395% \n",
      "[epoch:13, iter:752] Loss: 0.523 | Accuracy: 99.414% \n",
      "[epoch:13, iter:753] Loss: 0.522 | Accuracy: 99.432% \n",
      "[epoch:13, iter:754] Loss: 0.526 | Accuracy: 99.265% \n",
      "[epoch:13, iter:755] Loss: 0.526 | Accuracy: 99.286% \n",
      "[epoch:13, iter:756] Loss: 0.526 | Accuracy: 99.306% \n",
      "[epoch:13, iter:757] Loss: 0.525 | Accuracy: 99.324% \n",
      "[epoch:13, iter:758] Loss: 0.525 | Accuracy: 99.342% \n",
      "[epoch:13, iter:759] Loss: 0.525 | Accuracy: 99.359% \n",
      "[epoch:13, iter:760] Loss: 0.524 | Accuracy: 99.375% \n",
      "[epoch:13, iter:761] Loss: 0.524 | Accuracy: 99.390% \n",
      "[epoch:13, iter:762] Loss: 0.523 | Accuracy: 99.405% \n",
      "[epoch:13, iter:763] Loss: 0.523 | Accuracy: 99.419% \n",
      "[epoch:13, iter:764] Loss: 0.523 | Accuracy: 99.432% \n",
      "[epoch:13, iter:765] Loss: 0.523 | Accuracy: 99.444% \n",
      "[epoch:13, iter:766] Loss: 0.522 | Accuracy: 99.457% \n",
      "[epoch:13, iter:767] Loss: 0.522 | Accuracy: 99.468% \n",
      "[epoch:13, iter:768] Loss: 0.522 | Accuracy: 99.479% \n",
      "[epoch:13, iter:769] Loss: 0.521 | Accuracy: 99.490% \n",
      "[epoch:13, iter:770] Loss: 0.521 | Accuracy: 99.500% \n",
      "[epoch:13, iter:771] Loss: 0.521 | Accuracy: 99.510% \n",
      "[epoch:13, iter:772] Loss: 0.521 | Accuracy: 99.519% \n",
      "[epoch:13, iter:773] Loss: 0.520 | Accuracy: 99.528% \n",
      "[epoch:13, iter:774] Loss: 0.520 | Accuracy: 99.537% \n",
      "[epoch:13, iter:775] Loss: 0.521 | Accuracy: 99.489% \n",
      "[epoch:13, iter:776] Loss: 0.521 | Accuracy: 99.498% \n",
      "[epoch:13, iter:777] Loss: 0.521 | Accuracy: 99.507% \n",
      "[epoch:13, iter:778] Loss: 0.521 | Accuracy: 99.515% \n",
      "[epoch:13, iter:779] Loss: 0.521 | Accuracy: 99.523% \n",
      "[epoch:13, iter:780] Loss: 0.520 | Accuracy: 99.530% \n",
      "Waiting Test!\n",
      "EPOCH=013, Loss: 0.667, Accuracy= 94.286%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (93.333333 --> 94.285714).  Saving model ...\n",
      "\n",
      "Epoch: 14\n",
      "[epoch:14, iter:781] Loss: 0.561 | Accuracy: 96.875% \n",
      "[epoch:14, iter:782] Loss: 0.536 | Accuracy: 98.438% \n",
      "[epoch:14, iter:783] Loss: 0.527 | Accuracy: 98.958% \n",
      "[epoch:14, iter:784] Loss: 0.523 | Accuracy: 99.219% \n",
      "[epoch:14, iter:785] Loss: 0.520 | Accuracy: 99.375% \n",
      "[epoch:14, iter:786] Loss: 0.518 | Accuracy: 99.479% \n",
      "[epoch:14, iter:787] Loss: 0.516 | Accuracy: 99.554% \n",
      "[epoch:14, iter:788] Loss: 0.515 | Accuracy: 99.609% \n",
      "[epoch:14, iter:789] Loss: 0.514 | Accuracy: 99.653% \n",
      "[epoch:14, iter:790] Loss: 0.513 | Accuracy: 99.688% \n",
      "[epoch:14, iter:791] Loss: 0.512 | Accuracy: 99.716% \n",
      "[epoch:14, iter:792] Loss: 0.512 | Accuracy: 99.740% \n",
      "[epoch:14, iter:793] Loss: 0.512 | Accuracy: 99.760% \n",
      "[epoch:14, iter:794] Loss: 0.512 | Accuracy: 99.777% \n",
      "[epoch:14, iter:795] Loss: 0.512 | Accuracy: 99.792% \n",
      "[epoch:14, iter:796] Loss: 0.511 | Accuracy: 99.805% \n",
      "[epoch:14, iter:797] Loss: 0.511 | Accuracy: 99.816% \n",
      "[epoch:14, iter:798] Loss: 0.511 | Accuracy: 99.826% \n",
      "[epoch:14, iter:799] Loss: 0.511 | Accuracy: 99.836% \n",
      "[epoch:14, iter:800] Loss: 0.511 | Accuracy: 99.844% \n",
      "[epoch:14, iter:801] Loss: 0.510 | Accuracy: 99.851% \n",
      "[epoch:14, iter:802] Loss: 0.510 | Accuracy: 99.858% \n",
      "[epoch:14, iter:803] Loss: 0.510 | Accuracy: 99.864% \n",
      "[epoch:14, iter:804] Loss: 0.510 | Accuracy: 99.870% \n",
      "[epoch:14, iter:805] Loss: 0.510 | Accuracy: 99.875% \n",
      "[epoch:14, iter:806] Loss: 0.510 | Accuracy: 99.880% \n",
      "[epoch:14, iter:807] Loss: 0.510 | Accuracy: 99.884% \n",
      "[epoch:14, iter:808] Loss: 0.510 | Accuracy: 99.888% \n",
      "[epoch:14, iter:809] Loss: 0.510 | Accuracy: 99.892% \n",
      "[epoch:14, iter:810] Loss: 0.510 | Accuracy: 99.896% \n",
      "[epoch:14, iter:811] Loss: 0.511 | Accuracy: 99.798% \n",
      "[epoch:14, iter:812] Loss: 0.511 | Accuracy: 99.805% \n",
      "[epoch:14, iter:813] Loss: 0.510 | Accuracy: 99.811% \n",
      "[epoch:14, iter:814] Loss: 0.510 | Accuracy: 99.816% \n",
      "[epoch:14, iter:815] Loss: 0.510 | Accuracy: 99.821% \n",
      "[epoch:14, iter:816] Loss: 0.510 | Accuracy: 99.826% \n",
      "[epoch:14, iter:817] Loss: 0.511 | Accuracy: 99.831% \n",
      "[epoch:14, iter:818] Loss: 0.510 | Accuracy: 99.836% \n",
      "[epoch:14, iter:819] Loss: 0.510 | Accuracy: 99.840% \n",
      "[epoch:14, iter:820] Loss: 0.510 | Accuracy: 99.844% \n",
      "[epoch:14, iter:821] Loss: 0.510 | Accuracy: 99.848% \n",
      "[epoch:14, iter:822] Loss: 0.510 | Accuracy: 99.851% \n",
      "[epoch:14, iter:823] Loss: 0.510 | Accuracy: 99.855% \n",
      "[epoch:14, iter:824] Loss: 0.510 | Accuracy: 99.858% \n",
      "[epoch:14, iter:825] Loss: 0.510 | Accuracy: 99.861% \n",
      "[epoch:14, iter:826] Loss: 0.510 | Accuracy: 99.864% \n",
      "[epoch:14, iter:827] Loss: 0.510 | Accuracy: 99.867% \n",
      "[epoch:14, iter:828] Loss: 0.510 | Accuracy: 99.870% \n",
      "[epoch:14, iter:829] Loss: 0.510 | Accuracy: 99.872% \n",
      "[epoch:14, iter:830] Loss: 0.510 | Accuracy: 99.875% \n",
      "[epoch:14, iter:831] Loss: 0.510 | Accuracy: 99.877% \n",
      "[epoch:14, iter:832] Loss: 0.510 | Accuracy: 99.880% \n",
      "[epoch:14, iter:833] Loss: 0.510 | Accuracy: 99.882% \n",
      "[epoch:14, iter:834] Loss: 0.510 | Accuracy: 99.884% \n",
      "[epoch:14, iter:835] Loss: 0.510 | Accuracy: 99.886% \n",
      "[epoch:14, iter:836] Loss: 0.509 | Accuracy: 99.888% \n",
      "[epoch:14, iter:837] Loss: 0.509 | Accuracy: 99.890% \n",
      "[epoch:14, iter:838] Loss: 0.509 | Accuracy: 99.892% \n",
      "[epoch:14, iter:839] Loss: 0.509 | Accuracy: 99.894% \n",
      "[epoch:14, iter:840] Loss: 0.509 | Accuracy: 99.895% \n",
      "Waiting Test!\n",
      "EPOCH=014, Loss: 0.593, Accuracy= 97.143%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (94.285714 --> 97.142857).  Saving model ...\n",
      "\n",
      "Epoch: 15\n",
      "[epoch:15, iter:841] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:15, iter:842] Loss: 0.515 | Accuracy: 100.000% \n",
      "[epoch:15, iter:843] Loss: 0.512 | Accuracy: 100.000% \n",
      "[epoch:15, iter:844] Loss: 0.510 | Accuracy: 100.000% \n",
      "[epoch:15, iter:845] Loss: 0.509 | Accuracy: 100.000% \n",
      "[epoch:15, iter:846] Loss: 0.509 | Accuracy: 100.000% \n",
      "[epoch:15, iter:847] Loss: 0.508 | Accuracy: 100.000% \n",
      "[epoch:15, iter:848] Loss: 0.508 | Accuracy: 100.000% \n",
      "[epoch:15, iter:849] Loss: 0.508 | Accuracy: 100.000% \n",
      "[epoch:15, iter:850] Loss: 0.522 | Accuracy: 99.688% \n",
      "[epoch:15, iter:851] Loss: 0.521 | Accuracy: 99.716% \n",
      "[epoch:15, iter:852] Loss: 0.520 | Accuracy: 99.740% \n",
      "[epoch:15, iter:853] Loss: 0.518 | Accuracy: 99.760% \n",
      "[epoch:15, iter:854] Loss: 0.518 | Accuracy: 99.777% \n",
      "[epoch:15, iter:855] Loss: 0.517 | Accuracy: 99.792% \n",
      "[epoch:15, iter:856] Loss: 0.516 | Accuracy: 99.805% \n",
      "[epoch:15, iter:857] Loss: 0.516 | Accuracy: 99.816% \n",
      "[epoch:15, iter:858] Loss: 0.515 | Accuracy: 99.826% \n",
      "[epoch:15, iter:859] Loss: 0.515 | Accuracy: 99.836% \n",
      "[epoch:15, iter:860] Loss: 0.514 | Accuracy: 99.844% \n",
      "[epoch:15, iter:861] Loss: 0.514 | Accuracy: 99.851% \n",
      "[epoch:15, iter:862] Loss: 0.514 | Accuracy: 99.858% \n",
      "[epoch:15, iter:863] Loss: 0.513 | Accuracy: 99.864% \n",
      "[epoch:15, iter:864] Loss: 0.513 | Accuracy: 99.870% \n",
      "[epoch:15, iter:865] Loss: 0.513 | Accuracy: 99.875% \n",
      "[epoch:15, iter:866] Loss: 0.512 | Accuracy: 99.880% \n",
      "[epoch:15, iter:867] Loss: 0.512 | Accuracy: 99.884% \n",
      "[epoch:15, iter:868] Loss: 0.512 | Accuracy: 99.888% \n",
      "[epoch:15, iter:869] Loss: 0.512 | Accuracy: 99.892% \n",
      "[epoch:15, iter:870] Loss: 0.512 | Accuracy: 99.896% \n",
      "[epoch:15, iter:871] Loss: 0.512 | Accuracy: 99.899% \n",
      "[epoch:15, iter:872] Loss: 0.511 | Accuracy: 99.902% \n",
      "[epoch:15, iter:873] Loss: 0.511 | Accuracy: 99.905% \n",
      "[epoch:15, iter:874] Loss: 0.511 | Accuracy: 99.908% \n",
      "[epoch:15, iter:875] Loss: 0.511 | Accuracy: 99.911% \n",
      "[epoch:15, iter:876] Loss: 0.511 | Accuracy: 99.913% \n",
      "[epoch:15, iter:877] Loss: 0.510 | Accuracy: 99.916% \n",
      "[epoch:15, iter:878] Loss: 0.510 | Accuracy: 99.918% \n",
      "[epoch:15, iter:879] Loss: 0.510 | Accuracy: 99.920% \n",
      "[epoch:15, iter:880] Loss: 0.510 | Accuracy: 99.922% \n",
      "[epoch:15, iter:881] Loss: 0.510 | Accuracy: 99.924% \n",
      "[epoch:15, iter:882] Loss: 0.510 | Accuracy: 99.926% \n",
      "[epoch:15, iter:883] Loss: 0.510 | Accuracy: 99.927% \n",
      "[epoch:15, iter:884] Loss: 0.510 | Accuracy: 99.929% \n",
      "[epoch:15, iter:885] Loss: 0.510 | Accuracy: 99.931% \n",
      "[epoch:15, iter:886] Loss: 0.510 | Accuracy: 99.932% \n",
      "[epoch:15, iter:887] Loss: 0.510 | Accuracy: 99.934% \n",
      "[epoch:15, iter:888] Loss: 0.509 | Accuracy: 99.935% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:15, iter:889] Loss: 0.509 | Accuracy: 99.936% \n",
      "[epoch:15, iter:890] Loss: 0.509 | Accuracy: 99.938% \n",
      "[epoch:15, iter:891] Loss: 0.509 | Accuracy: 99.939% \n",
      "[epoch:15, iter:892] Loss: 0.509 | Accuracy: 99.940% \n",
      "[epoch:15, iter:893] Loss: 0.509 | Accuracy: 99.941% \n",
      "[epoch:15, iter:894] Loss: 0.509 | Accuracy: 99.942% \n",
      "[epoch:15, iter:895] Loss: 0.509 | Accuracy: 99.943% \n",
      "[epoch:15, iter:896] Loss: 0.509 | Accuracy: 99.944% \n",
      "[epoch:15, iter:897] Loss: 0.509 | Accuracy: 99.945% \n",
      "[epoch:15, iter:898] Loss: 0.509 | Accuracy: 99.946% \n",
      "[epoch:15, iter:899] Loss: 0.509 | Accuracy: 99.947% \n",
      "[epoch:15, iter:900] Loss: 0.510 | Accuracy: 99.948% \n",
      "Waiting Test!\n",
      "EPOCH=015, Loss: 0.571, Accuracy= 97.143%\n",
      "Training complete in 0m 10s\n",
      "Validation accuracy increased (97.142857 --> 97.142857).  Saving model ...\n",
      "\n",
      "Epoch: 16\n",
      "[epoch:16, iter:901] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:16, iter:902] Loss: 0.507 | Accuracy: 100.000% \n",
      "[epoch:16, iter:903] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:16, iter:904] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:16, iter:905] Loss: 0.511 | Accuracy: 99.375% \n",
      "[epoch:16, iter:906] Loss: 0.510 | Accuracy: 99.479% \n",
      "[epoch:16, iter:907] Loss: 0.510 | Accuracy: 99.554% \n",
      "[epoch:16, iter:908] Loss: 0.510 | Accuracy: 99.609% \n",
      "[epoch:16, iter:909] Loss: 0.509 | Accuracy: 99.653% \n",
      "[epoch:16, iter:910] Loss: 0.509 | Accuracy: 99.688% \n",
      "[epoch:16, iter:911] Loss: 0.508 | Accuracy: 99.716% \n",
      "[epoch:16, iter:912] Loss: 0.508 | Accuracy: 99.740% \n",
      "[epoch:16, iter:913] Loss: 0.508 | Accuracy: 99.760% \n",
      "[epoch:16, iter:914] Loss: 0.508 | Accuracy: 99.777% \n",
      "[epoch:16, iter:915] Loss: 0.508 | Accuracy: 99.792% \n",
      "[epoch:16, iter:916] Loss: 0.508 | Accuracy: 99.805% \n",
      "[epoch:16, iter:917] Loss: 0.508 | Accuracy: 99.816% \n",
      "[epoch:16, iter:918] Loss: 0.508 | Accuracy: 99.826% \n",
      "[epoch:16, iter:919] Loss: 0.508 | Accuracy: 99.836% \n",
      "[epoch:16, iter:920] Loss: 0.508 | Accuracy: 99.844% \n",
      "[epoch:16, iter:921] Loss: 0.508 | Accuracy: 99.851% \n",
      "[epoch:16, iter:922] Loss: 0.507 | Accuracy: 99.858% \n",
      "[epoch:16, iter:923] Loss: 0.507 | Accuracy: 99.864% \n",
      "[epoch:16, iter:924] Loss: 0.507 | Accuracy: 99.870% \n",
      "[epoch:16, iter:925] Loss: 0.507 | Accuracy: 99.875% \n",
      "[epoch:16, iter:926] Loss: 0.511 | Accuracy: 99.760% \n",
      "[epoch:16, iter:927] Loss: 0.511 | Accuracy: 99.769% \n",
      "[epoch:16, iter:928] Loss: 0.511 | Accuracy: 99.777% \n",
      "[epoch:16, iter:929] Loss: 0.511 | Accuracy: 99.784% \n",
      "[epoch:16, iter:930] Loss: 0.511 | Accuracy: 99.792% \n",
      "[epoch:16, iter:931] Loss: 0.511 | Accuracy: 99.798% \n",
      "[epoch:16, iter:932] Loss: 0.511 | Accuracy: 99.805% \n",
      "[epoch:16, iter:933] Loss: 0.511 | Accuracy: 99.811% \n",
      "[epoch:16, iter:934] Loss: 0.511 | Accuracy: 99.816% \n",
      "[epoch:16, iter:935] Loss: 0.511 | Accuracy: 99.821% \n",
      "[epoch:16, iter:936] Loss: 0.511 | Accuracy: 99.826% \n",
      "[epoch:16, iter:937] Loss: 0.511 | Accuracy: 99.831% \n",
      "[epoch:16, iter:938] Loss: 0.511 | Accuracy: 99.836% \n",
      "[epoch:16, iter:939] Loss: 0.510 | Accuracy: 99.840% \n",
      "[epoch:16, iter:940] Loss: 0.510 | Accuracy: 99.844% \n",
      "[epoch:16, iter:941] Loss: 0.511 | Accuracy: 99.771% \n",
      "[epoch:16, iter:942] Loss: 0.512 | Accuracy: 99.702% \n",
      "[epoch:16, iter:943] Loss: 0.512 | Accuracy: 99.709% \n",
      "[epoch:16, iter:944] Loss: 0.512 | Accuracy: 99.716% \n",
      "[epoch:16, iter:945] Loss: 0.515 | Accuracy: 99.653% \n",
      "[epoch:16, iter:946] Loss: 0.515 | Accuracy: 99.660% \n",
      "[epoch:16, iter:947] Loss: 0.515 | Accuracy: 99.668% \n",
      "[epoch:16, iter:948] Loss: 0.515 | Accuracy: 99.674% \n",
      "[epoch:16, iter:949] Loss: 0.515 | Accuracy: 99.681% \n",
      "[epoch:16, iter:950] Loss: 0.515 | Accuracy: 99.688% \n",
      "[epoch:16, iter:951] Loss: 0.518 | Accuracy: 99.571% \n",
      "[epoch:16, iter:952] Loss: 0.519 | Accuracy: 99.579% \n",
      "[epoch:16, iter:953] Loss: 0.519 | Accuracy: 99.587% \n",
      "[epoch:16, iter:954] Loss: 0.518 | Accuracy: 99.595% \n",
      "[epoch:16, iter:955] Loss: 0.519 | Accuracy: 99.602% \n",
      "[epoch:16, iter:956] Loss: 0.519 | Accuracy: 99.609% \n",
      "[epoch:16, iter:957] Loss: 0.520 | Accuracy: 99.507% \n",
      "[epoch:16, iter:958] Loss: 0.520 | Accuracy: 99.515% \n",
      "[epoch:16, iter:959] Loss: 0.520 | Accuracy: 99.523% \n",
      "[epoch:16, iter:960] Loss: 0.520 | Accuracy: 99.530% \n",
      "Waiting Test!\n",
      "EPOCH=016, Loss: 0.661, Accuracy= 96.190%\n",
      "Training complete in 0m 10s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "\n",
      "Epoch: 17\n",
      "[epoch:17, iter:961] Loss: 0.530 | Accuracy: 100.000% \n",
      "[epoch:17, iter:962] Loss: 0.520 | Accuracy: 100.000% \n",
      "[epoch:17, iter:963] Loss: 0.517 | Accuracy: 100.000% \n",
      "[epoch:17, iter:964] Loss: 0.514 | Accuracy: 100.000% \n",
      "[epoch:17, iter:965] Loss: 0.513 | Accuracy: 100.000% \n",
      "[epoch:17, iter:966] Loss: 0.513 | Accuracy: 100.000% \n",
      "[epoch:17, iter:967] Loss: 0.512 | Accuracy: 100.000% \n",
      "[epoch:17, iter:968] Loss: 0.525 | Accuracy: 99.609% \n",
      "[epoch:17, iter:969] Loss: 0.524 | Accuracy: 99.653% \n",
      "[epoch:17, iter:970] Loss: 0.523 | Accuracy: 99.688% \n",
      "[epoch:17, iter:971] Loss: 0.522 | Accuracy: 99.716% \n",
      "[epoch:17, iter:972] Loss: 0.521 | Accuracy: 99.740% \n",
      "[epoch:17, iter:973] Loss: 0.520 | Accuracy: 99.760% \n",
      "[epoch:17, iter:974] Loss: 0.519 | Accuracy: 99.777% \n",
      "[epoch:17, iter:975] Loss: 0.518 | Accuracy: 99.792% \n",
      "[epoch:17, iter:976] Loss: 0.521 | Accuracy: 99.609% \n",
      "[epoch:17, iter:977] Loss: 0.522 | Accuracy: 99.632% \n",
      "[epoch:17, iter:978] Loss: 0.521 | Accuracy: 99.653% \n",
      "[epoch:17, iter:979] Loss: 0.521 | Accuracy: 99.671% \n",
      "[epoch:17, iter:980] Loss: 0.520 | Accuracy: 99.688% \n",
      "[epoch:17, iter:981] Loss: 0.522 | Accuracy: 99.554% \n",
      "[epoch:17, iter:982] Loss: 0.525 | Accuracy: 99.432% \n",
      "[epoch:17, iter:983] Loss: 0.524 | Accuracy: 99.457% \n",
      "[epoch:17, iter:984] Loss: 0.524 | Accuracy: 99.479% \n",
      "[epoch:17, iter:985] Loss: 0.523 | Accuracy: 99.500% \n",
      "[epoch:17, iter:986] Loss: 0.524 | Accuracy: 99.399% \n",
      "[epoch:17, iter:987] Loss: 0.524 | Accuracy: 99.421% \n",
      "[epoch:17, iter:988] Loss: 0.523 | Accuracy: 99.442% \n",
      "[epoch:17, iter:989] Loss: 0.523 | Accuracy: 99.461% \n",
      "[epoch:17, iter:990] Loss: 0.524 | Accuracy: 99.375% \n",
      "[epoch:17, iter:991] Loss: 0.524 | Accuracy: 99.395% \n",
      "[epoch:17, iter:992] Loss: 0.523 | Accuracy: 99.414% \n",
      "[epoch:17, iter:993] Loss: 0.523 | Accuracy: 99.432% \n",
      "[epoch:17, iter:994] Loss: 0.522 | Accuracy: 99.449% \n",
      "[epoch:17, iter:995] Loss: 0.522 | Accuracy: 99.464% \n",
      "[epoch:17, iter:996] Loss: 0.522 | Accuracy: 99.479% \n",
      "[epoch:17, iter:997] Loss: 0.522 | Accuracy: 99.493% \n",
      "[epoch:17, iter:998] Loss: 0.522 | Accuracy: 99.424% \n",
      "[epoch:17, iter:999] Loss: 0.522 | Accuracy: 99.439% \n",
      "[epoch:17, iter:1000] Loss: 0.522 | Accuracy: 99.453% \n",
      "[epoch:17, iter:1001] Loss: 0.522 | Accuracy: 99.466% \n",
      "[epoch:17, iter:1002] Loss: 0.521 | Accuracy: 99.479% \n",
      "[epoch:17, iter:1003] Loss: 0.521 | Accuracy: 99.491% \n",
      "[epoch:17, iter:1004] Loss: 0.522 | Accuracy: 99.432% \n",
      "[epoch:17, iter:1005] Loss: 0.523 | Accuracy: 99.444% \n",
      "[epoch:17, iter:1006] Loss: 0.522 | Accuracy: 99.457% \n",
      "[epoch:17, iter:1007] Loss: 0.522 | Accuracy: 99.468% \n",
      "[epoch:17, iter:1008] Loss: 0.522 | Accuracy: 99.479% \n",
      "[epoch:17, iter:1009] Loss: 0.522 | Accuracy: 99.490% \n",
      "[epoch:17, iter:1010] Loss: 0.522 | Accuracy: 99.500% \n",
      "[epoch:17, iter:1011] Loss: 0.521 | Accuracy: 99.510% \n",
      "[epoch:17, iter:1012] Loss: 0.521 | Accuracy: 99.519% \n",
      "[epoch:17, iter:1013] Loss: 0.521 | Accuracy: 99.528% \n",
      "[epoch:17, iter:1014] Loss: 0.521 | Accuracy: 99.537% \n",
      "[epoch:17, iter:1015] Loss: 0.520 | Accuracy: 99.545% \n",
      "[epoch:17, iter:1016] Loss: 0.520 | Accuracy: 99.554% \n",
      "[epoch:17, iter:1017] Loss: 0.520 | Accuracy: 99.561% \n",
      "[epoch:17, iter:1018] Loss: 0.520 | Accuracy: 99.569% \n",
      "[epoch:17, iter:1019] Loss: 0.520 | Accuracy: 99.576% \n",
      "[epoch:17, iter:1020] Loss: 0.520 | Accuracy: 99.582% \n",
      "Waiting Test!\n",
      "EPOCH=017, Loss: 0.588, Accuracy= 97.143%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (97.142857 --> 97.142857).  Saving model ...\n",
      "\n",
      "Epoch: 18\n",
      "[epoch:18, iter:1021] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:18, iter:1022] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:18, iter:1023] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:18, iter:1024] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:18, iter:1025] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:18, iter:1026] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:18, iter:1027] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:18, iter:1028] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:18, iter:1029] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:18, iter:1030] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:18, iter:1031] Loss: 0.506 | Accuracy: 100.000% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:18, iter:1032] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:18, iter:1033] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:18, iter:1034] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:18, iter:1035] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:18, iter:1036] Loss: 0.510 | Accuracy: 99.805% \n",
      "[epoch:18, iter:1037] Loss: 0.509 | Accuracy: 99.816% \n",
      "[epoch:18, iter:1038] Loss: 0.509 | Accuracy: 99.826% \n",
      "[epoch:18, iter:1039] Loss: 0.509 | Accuracy: 99.836% \n",
      "[epoch:18, iter:1040] Loss: 0.509 | Accuracy: 99.844% \n",
      "[epoch:18, iter:1041] Loss: 0.509 | Accuracy: 99.851% \n",
      "[epoch:18, iter:1042] Loss: 0.509 | Accuracy: 99.858% \n",
      "[epoch:18, iter:1043] Loss: 0.516 | Accuracy: 99.592% \n",
      "[epoch:18, iter:1044] Loss: 0.516 | Accuracy: 99.609% \n",
      "[epoch:18, iter:1045] Loss: 0.517 | Accuracy: 99.500% \n",
      "[epoch:18, iter:1046] Loss: 0.517 | Accuracy: 99.519% \n",
      "[epoch:18, iter:1047] Loss: 0.516 | Accuracy: 99.537% \n",
      "[epoch:18, iter:1048] Loss: 0.516 | Accuracy: 99.554% \n",
      "[epoch:18, iter:1049] Loss: 0.516 | Accuracy: 99.569% \n",
      "[epoch:18, iter:1050] Loss: 0.515 | Accuracy: 99.583% \n",
      "[epoch:18, iter:1051] Loss: 0.515 | Accuracy: 99.597% \n",
      "[epoch:18, iter:1052] Loss: 0.515 | Accuracy: 99.609% \n",
      "[epoch:18, iter:1053] Loss: 0.515 | Accuracy: 99.621% \n",
      "[epoch:18, iter:1054] Loss: 0.514 | Accuracy: 99.632% \n",
      "[epoch:18, iter:1055] Loss: 0.514 | Accuracy: 99.643% \n",
      "[epoch:18, iter:1056] Loss: 0.514 | Accuracy: 99.653% \n",
      "[epoch:18, iter:1057] Loss: 0.514 | Accuracy: 99.662% \n",
      "[epoch:18, iter:1058] Loss: 0.514 | Accuracy: 99.671% \n",
      "[epoch:18, iter:1059] Loss: 0.514 | Accuracy: 99.679% \n",
      "[epoch:18, iter:1060] Loss: 0.513 | Accuracy: 99.688% \n",
      "[epoch:18, iter:1061] Loss: 0.513 | Accuracy: 99.695% \n",
      "[epoch:18, iter:1062] Loss: 0.513 | Accuracy: 99.702% \n",
      "[epoch:18, iter:1063] Loss: 0.513 | Accuracy: 99.709% \n",
      "[epoch:18, iter:1064] Loss: 0.513 | Accuracy: 99.716% \n",
      "[epoch:18, iter:1065] Loss: 0.513 | Accuracy: 99.722% \n",
      "[epoch:18, iter:1066] Loss: 0.512 | Accuracy: 99.728% \n",
      "[epoch:18, iter:1067] Loss: 0.512 | Accuracy: 99.734% \n",
      "[epoch:18, iter:1068] Loss: 0.512 | Accuracy: 99.740% \n",
      "[epoch:18, iter:1069] Loss: 0.512 | Accuracy: 99.745% \n",
      "[epoch:18, iter:1070] Loss: 0.512 | Accuracy: 99.750% \n",
      "[epoch:18, iter:1071] Loss: 0.512 | Accuracy: 99.755% \n",
      "[epoch:18, iter:1072] Loss: 0.512 | Accuracy: 99.760% \n",
      "[epoch:18, iter:1073] Loss: 0.512 | Accuracy: 99.764% \n",
      "[epoch:18, iter:1074] Loss: 0.512 | Accuracy: 99.769% \n",
      "[epoch:18, iter:1075] Loss: 0.512 | Accuracy: 99.773% \n",
      "[epoch:18, iter:1076] Loss: 0.512 | Accuracy: 99.777% \n",
      "[epoch:18, iter:1077] Loss: 0.512 | Accuracy: 99.781% \n",
      "[epoch:18, iter:1078] Loss: 0.512 | Accuracy: 99.784% \n",
      "[epoch:18, iter:1079] Loss: 0.512 | Accuracy: 99.788% \n",
      "[epoch:18, iter:1080] Loss: 0.511 | Accuracy: 99.791% \n",
      "Waiting Test!\n",
      "EPOCH=018, Loss: 0.585, Accuracy= 97.143%\n",
      "Epoch 00018: reducing learning rate of group 0 to 2.1000e-04.\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (97.142857 --> 97.142857).  Saving model ...\n",
      "\n",
      "Epoch: 19\n",
      "[epoch:19, iter:1081] Loss: 0.511 | Accuracy: 100.000% \n",
      "[epoch:19, iter:1082] Loss: 0.525 | Accuracy: 98.438% \n",
      "[epoch:19, iter:1083] Loss: 0.530 | Accuracy: 97.917% \n",
      "[epoch:19, iter:1084] Loss: 0.524 | Accuracy: 98.438% \n",
      "[epoch:19, iter:1085] Loss: 0.520 | Accuracy: 98.750% \n",
      "[epoch:19, iter:1086] Loss: 0.517 | Accuracy: 98.958% \n",
      "[epoch:19, iter:1087] Loss: 0.516 | Accuracy: 99.107% \n",
      "[epoch:19, iter:1088] Loss: 0.515 | Accuracy: 99.219% \n",
      "[epoch:19, iter:1089] Loss: 0.514 | Accuracy: 99.306% \n",
      "[epoch:19, iter:1090] Loss: 0.513 | Accuracy: 99.375% \n",
      "[epoch:19, iter:1091] Loss: 0.512 | Accuracy: 99.432% \n",
      "[epoch:19, iter:1092] Loss: 0.514 | Accuracy: 99.479% \n",
      "[epoch:19, iter:1093] Loss: 0.513 | Accuracy: 99.519% \n",
      "[epoch:19, iter:1094] Loss: 0.512 | Accuracy: 99.554% \n",
      "[epoch:19, iter:1095] Loss: 0.512 | Accuracy: 99.583% \n",
      "[epoch:19, iter:1096] Loss: 0.511 | Accuracy: 99.609% \n",
      "[epoch:19, iter:1097] Loss: 0.511 | Accuracy: 99.632% \n",
      "[epoch:19, iter:1098] Loss: 0.511 | Accuracy: 99.653% \n",
      "[epoch:19, iter:1099] Loss: 0.510 | Accuracy: 99.671% \n",
      "[epoch:19, iter:1100] Loss: 0.510 | Accuracy: 99.688% \n",
      "[epoch:19, iter:1101] Loss: 0.510 | Accuracy: 99.702% \n",
      "[epoch:19, iter:1102] Loss: 0.510 | Accuracy: 99.716% \n",
      "[epoch:19, iter:1103] Loss: 0.510 | Accuracy: 99.728% \n",
      "[epoch:19, iter:1104] Loss: 0.509 | Accuracy: 99.740% \n",
      "[epoch:19, iter:1105] Loss: 0.509 | Accuracy: 99.750% \n",
      "[epoch:19, iter:1106] Loss: 0.509 | Accuracy: 99.760% \n",
      "[epoch:19, iter:1107] Loss: 0.509 | Accuracy: 99.769% \n",
      "[epoch:19, iter:1108] Loss: 0.509 | Accuracy: 99.777% \n",
      "[epoch:19, iter:1109] Loss: 0.509 | Accuracy: 99.784% \n",
      "[epoch:19, iter:1110] Loss: 0.508 | Accuracy: 99.792% \n",
      "[epoch:19, iter:1111] Loss: 0.508 | Accuracy: 99.798% \n",
      "[epoch:19, iter:1112] Loss: 0.508 | Accuracy: 99.805% \n",
      "[epoch:19, iter:1113] Loss: 0.508 | Accuracy: 99.811% \n",
      "[epoch:19, iter:1114] Loss: 0.508 | Accuracy: 99.816% \n",
      "[epoch:19, iter:1115] Loss: 0.508 | Accuracy: 99.821% \n",
      "[epoch:19, iter:1116] Loss: 0.508 | Accuracy: 99.826% \n",
      "[epoch:19, iter:1117] Loss: 0.508 | Accuracy: 99.831% \n",
      "[epoch:19, iter:1118] Loss: 0.508 | Accuracy: 99.836% \n",
      "[epoch:19, iter:1119] Loss: 0.509 | Accuracy: 99.760% \n",
      "[epoch:19, iter:1120] Loss: 0.509 | Accuracy: 99.766% \n",
      "[epoch:19, iter:1121] Loss: 0.509 | Accuracy: 99.771% \n",
      "[epoch:19, iter:1122] Loss: 0.508 | Accuracy: 99.777% \n",
      "[epoch:19, iter:1123] Loss: 0.508 | Accuracy: 99.782% \n",
      "[epoch:19, iter:1124] Loss: 0.508 | Accuracy: 99.787% \n",
      "[epoch:19, iter:1125] Loss: 0.508 | Accuracy: 99.792% \n",
      "[epoch:19, iter:1126] Loss: 0.508 | Accuracy: 99.796% \n",
      "[epoch:19, iter:1127] Loss: 0.508 | Accuracy: 99.801% \n",
      "[epoch:19, iter:1128] Loss: 0.508 | Accuracy: 99.805% \n",
      "[epoch:19, iter:1129] Loss: 0.508 | Accuracy: 99.809% \n",
      "[epoch:19, iter:1130] Loss: 0.508 | Accuracy: 99.812% \n",
      "[epoch:19, iter:1131] Loss: 0.508 | Accuracy: 99.816% \n",
      "[epoch:19, iter:1132] Loss: 0.508 | Accuracy: 99.820% \n",
      "[epoch:19, iter:1133] Loss: 0.508 | Accuracy: 99.823% \n",
      "[epoch:19, iter:1134] Loss: 0.508 | Accuracy: 99.826% \n",
      "[epoch:19, iter:1135] Loss: 0.508 | Accuracy: 99.830% \n",
      "[epoch:19, iter:1136] Loss: 0.508 | Accuracy: 99.833% \n",
      "[epoch:19, iter:1137] Loss: 0.508 | Accuracy: 99.836% \n",
      "[epoch:19, iter:1138] Loss: 0.508 | Accuracy: 99.838% \n",
      "[epoch:19, iter:1139] Loss: 0.508 | Accuracy: 99.841% \n",
      "[epoch:19, iter:1140] Loss: 0.508 | Accuracy: 99.843% \n",
      "Waiting Test!\n",
      "EPOCH=019, Loss: 0.594, Accuracy= 97.143%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (97.142857 --> 97.142857).  Saving model ...\n",
      "\n",
      "Epoch: 20\n",
      "[epoch:20, iter:1141] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1142] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1143] Loss: 0.507 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1144] Loss: 0.507 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1145] Loss: 0.507 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1146] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1147] Loss: 0.508 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1148] Loss: 0.508 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1149] Loss: 0.507 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1150] Loss: 0.507 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1151] Loss: 0.507 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1152] Loss: 0.507 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1153] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1154] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1155] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1156] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1157] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1158] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1159] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1160] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1161] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1162] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1163] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1164] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1165] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1166] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1167] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1168] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1169] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1170] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1171] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1172] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1173] Loss: 0.506 | Accuracy: 100.000% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:20, iter:1174] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1175] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1176] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1177] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1178] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1179] Loss: 0.507 | Accuracy: 99.920% \n",
      "[epoch:20, iter:1180] Loss: 0.507 | Accuracy: 99.922% \n",
      "[epoch:20, iter:1181] Loss: 0.507 | Accuracy: 99.924% \n",
      "[epoch:20, iter:1182] Loss: 0.507 | Accuracy: 99.926% \n",
      "[epoch:20, iter:1183] Loss: 0.507 | Accuracy: 99.927% \n",
      "[epoch:20, iter:1184] Loss: 0.507 | Accuracy: 99.929% \n",
      "[epoch:20, iter:1185] Loss: 0.507 | Accuracy: 99.931% \n",
      "[epoch:20, iter:1186] Loss: 0.507 | Accuracy: 99.932% \n",
      "[epoch:20, iter:1187] Loss: 0.507 | Accuracy: 99.934% \n",
      "[epoch:20, iter:1188] Loss: 0.507 | Accuracy: 99.935% \n",
      "[epoch:20, iter:1189] Loss: 0.507 | Accuracy: 99.936% \n",
      "[epoch:20, iter:1190] Loss: 0.508 | Accuracy: 99.875% \n",
      "[epoch:20, iter:1191] Loss: 0.508 | Accuracy: 99.877% \n",
      "[epoch:20, iter:1192] Loss: 0.508 | Accuracy: 99.880% \n",
      "[epoch:20, iter:1193] Loss: 0.508 | Accuracy: 99.882% \n",
      "[epoch:20, iter:1194] Loss: 0.508 | Accuracy: 99.884% \n",
      "[epoch:20, iter:1195] Loss: 0.510 | Accuracy: 99.830% \n",
      "[epoch:20, iter:1196] Loss: 0.510 | Accuracy: 99.833% \n",
      "[epoch:20, iter:1197] Loss: 0.510 | Accuracy: 99.836% \n",
      "[epoch:20, iter:1198] Loss: 0.510 | Accuracy: 99.838% \n",
      "[epoch:20, iter:1199] Loss: 0.509 | Accuracy: 99.841% \n",
      "[epoch:20, iter:1200] Loss: 0.509 | Accuracy: 99.843% \n",
      "Waiting Test!\n",
      "EPOCH=020, Loss: 0.586, Accuracy= 97.143%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (97.142857 --> 97.142857).  Saving model ...\n",
      "\n",
      "Epoch: 21\n",
      "[epoch:21, iter:1201] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1202] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1203] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1204] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1205] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1206] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1207] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1208] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1209] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1210] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1211] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1212] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1213] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1214] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1215] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1216] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1217] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1218] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1219] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1220] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1221] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1222] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1223] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1224] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1225] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1226] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1227] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1228] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1229] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1230] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1231] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1232] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1233] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1234] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1235] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1236] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1237] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1238] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1239] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1240] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1241] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1242] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1243] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1244] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1245] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1246] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1247] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1248] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1249] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1250] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1251] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1252] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1253] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1254] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1255] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1256] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1257] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1258] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1259] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1260] Loss: 0.505 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=021, Loss: 0.571, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (97.142857 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 22\n",
      "[epoch:22, iter:1261] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1262] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1263] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1264] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1265] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1266] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1267] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1268] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1269] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1270] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1271] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1272] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1273] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1274] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1275] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1276] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1277] Loss: 0.505 | Accuracy: 99.816% \n",
      "[epoch:22, iter:1278] Loss: 0.505 | Accuracy: 99.826% \n",
      "[epoch:22, iter:1279] Loss: 0.505 | Accuracy: 99.836% \n",
      "[epoch:22, iter:1280] Loss: 0.505 | Accuracy: 99.844% \n",
      "[epoch:22, iter:1281] Loss: 0.505 | Accuracy: 99.851% \n",
      "[epoch:22, iter:1282] Loss: 0.505 | Accuracy: 99.858% \n",
      "[epoch:22, iter:1283] Loss: 0.505 | Accuracy: 99.864% \n",
      "[epoch:22, iter:1284] Loss: 0.505 | Accuracy: 99.870% \n",
      "[epoch:22, iter:1285] Loss: 0.506 | Accuracy: 99.875% \n",
      "[epoch:22, iter:1286] Loss: 0.506 | Accuracy: 99.880% \n",
      "[epoch:22, iter:1287] Loss: 0.508 | Accuracy: 99.769% \n",
      "[epoch:22, iter:1288] Loss: 0.510 | Accuracy: 99.665% \n",
      "[epoch:22, iter:1289] Loss: 0.511 | Accuracy: 99.677% \n",
      "[epoch:22, iter:1290] Loss: 0.511 | Accuracy: 99.688% \n",
      "[epoch:22, iter:1291] Loss: 0.511 | Accuracy: 99.698% \n",
      "[epoch:22, iter:1292] Loss: 0.511 | Accuracy: 99.707% \n",
      "[epoch:22, iter:1293] Loss: 0.511 | Accuracy: 99.716% \n",
      "[epoch:22, iter:1294] Loss: 0.512 | Accuracy: 99.632% \n",
      "[epoch:22, iter:1295] Loss: 0.512 | Accuracy: 99.643% \n",
      "[epoch:22, iter:1296] Loss: 0.511 | Accuracy: 99.653% \n",
      "[epoch:22, iter:1297] Loss: 0.511 | Accuracy: 99.662% \n",
      "[epoch:22, iter:1298] Loss: 0.511 | Accuracy: 99.671% \n",
      "[epoch:22, iter:1299] Loss: 0.511 | Accuracy: 99.679% \n",
      "[epoch:22, iter:1300] Loss: 0.511 | Accuracy: 99.688% \n",
      "[epoch:22, iter:1301] Loss: 0.511 | Accuracy: 99.695% \n",
      "[epoch:22, iter:1302] Loss: 0.511 | Accuracy: 99.702% \n",
      "[epoch:22, iter:1303] Loss: 0.510 | Accuracy: 99.709% \n",
      "[epoch:22, iter:1304] Loss: 0.510 | Accuracy: 99.716% \n",
      "[epoch:22, iter:1305] Loss: 0.510 | Accuracy: 99.722% \n",
      "[epoch:22, iter:1306] Loss: 0.510 | Accuracy: 99.728% \n",
      "[epoch:22, iter:1307] Loss: 0.510 | Accuracy: 99.734% \n",
      "[epoch:22, iter:1308] Loss: 0.510 | Accuracy: 99.740% \n",
      "[epoch:22, iter:1309] Loss: 0.510 | Accuracy: 99.745% \n",
      "[epoch:22, iter:1310] Loss: 0.510 | Accuracy: 99.750% \n",
      "[epoch:22, iter:1311] Loss: 0.510 | Accuracy: 99.755% \n",
      "[epoch:22, iter:1312] Loss: 0.510 | Accuracy: 99.760% \n",
      "[epoch:22, iter:1313] Loss: 0.509 | Accuracy: 99.764% \n",
      "[epoch:22, iter:1314] Loss: 0.509 | Accuracy: 99.769% \n",
      "[epoch:22, iter:1315] Loss: 0.509 | Accuracy: 99.773% \n",
      "[epoch:22, iter:1316] Loss: 0.509 | Accuracy: 99.777% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:22, iter:1317] Loss: 0.509 | Accuracy: 99.781% \n",
      "[epoch:22, iter:1318] Loss: 0.509 | Accuracy: 99.784% \n",
      "[epoch:22, iter:1319] Loss: 0.509 | Accuracy: 99.788% \n",
      "[epoch:22, iter:1320] Loss: 0.509 | Accuracy: 99.791% \n",
      "Waiting Test!\n",
      "EPOCH=022, Loss: 0.570, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 23\n",
      "[epoch:23, iter:1321] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1322] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1323] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1324] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1325] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1326] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1327] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1328] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1329] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1330] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1331] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1332] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1333] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1334] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1335] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1336] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1337] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1338] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1339] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1340] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1341] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1342] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1343] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1344] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1345] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1346] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1347] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1348] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1349] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1350] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1351] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1352] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1353] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1354] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1355] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1356] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1357] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1358] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1359] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1360] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1361] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1362] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1363] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1364] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1365] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1366] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1367] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1368] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1369] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1370] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1371] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1372] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1373] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1374] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1375] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1376] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1377] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1378] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1379] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1380] Loss: 0.504 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=023, Loss: 0.570, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 24\n",
      "[epoch:24, iter:1381] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1382] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1383] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1384] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1385] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1386] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1387] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1388] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1389] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1390] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1391] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1392] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1393] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1394] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1395] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1396] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1397] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1398] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1399] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1400] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1401] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1402] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1403] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1404] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1405] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1406] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1407] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1408] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1409] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1410] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1411] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1412] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1413] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1414] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1415] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1416] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1417] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1418] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1419] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1420] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1421] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1422] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1423] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1424] Loss: 0.505 | Accuracy: 99.929% \n",
      "[epoch:24, iter:1425] Loss: 0.505 | Accuracy: 99.931% \n",
      "[epoch:24, iter:1426] Loss: 0.506 | Accuracy: 99.932% \n",
      "[epoch:24, iter:1427] Loss: 0.506 | Accuracy: 99.934% \n",
      "[epoch:24, iter:1428] Loss: 0.506 | Accuracy: 99.935% \n",
      "[epoch:24, iter:1429] Loss: 0.506 | Accuracy: 99.936% \n",
      "[epoch:24, iter:1430] Loss: 0.506 | Accuracy: 99.938% \n",
      "[epoch:24, iter:1431] Loss: 0.506 | Accuracy: 99.939% \n",
      "[epoch:24, iter:1432] Loss: 0.506 | Accuracy: 99.940% \n",
      "[epoch:24, iter:1433] Loss: 0.506 | Accuracy: 99.941% \n",
      "[epoch:24, iter:1434] Loss: 0.506 | Accuracy: 99.942% \n",
      "[epoch:24, iter:1435] Loss: 0.506 | Accuracy: 99.943% \n",
      "[epoch:24, iter:1436] Loss: 0.508 | Accuracy: 99.888% \n",
      "[epoch:24, iter:1437] Loss: 0.509 | Accuracy: 99.836% \n",
      "[epoch:24, iter:1438] Loss: 0.510 | Accuracy: 99.838% \n",
      "[epoch:24, iter:1439] Loss: 0.510 | Accuracy: 99.841% \n",
      "[epoch:24, iter:1440] Loss: 0.510 | Accuracy: 99.843% \n",
      "Waiting Test!\n",
      "EPOCH=024, Loss: 0.577, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 25\n",
      "[epoch:25, iter:1441] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1442] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1443] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1444] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1445] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1446] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1447] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1448] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1449] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1450] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1451] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1452] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1453] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1454] Loss: 0.505 | Accuracy: 100.000% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:25, iter:1455] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1456] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1457] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1458] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1459] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1460] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1461] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1462] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1463] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1464] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1465] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1466] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1467] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1468] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1469] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1470] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1471] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1472] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1473] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1474] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1475] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1476] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1477] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1478] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1479] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1480] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1481] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1482] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1483] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1484] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1485] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1486] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1487] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1488] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1489] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1490] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1491] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1492] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1493] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1494] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1495] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1496] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1497] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1498] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1499] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:25, iter:1500] Loss: 0.504 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=025, Loss: 0.568, Accuracy= 98.095%\n",
      "Epoch 00025: reducing learning rate of group 0 to 1.4700e-04.\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 26\n",
      "[epoch:26, iter:1501] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:26, iter:1502] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:26, iter:1503] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:26, iter:1504] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:26, iter:1505] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:26, iter:1506] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:26, iter:1507] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:26, iter:1508] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:26, iter:1509] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:26, iter:1510] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:26, iter:1511] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:26, iter:1512] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:26, iter:1513] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:26, iter:1514] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:26, iter:1515] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:26, iter:1516] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:26, iter:1517] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:26, iter:1518] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:26, iter:1519] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:26, iter:1520] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:26, iter:1521] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:26, iter:1522] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:26, iter:1523] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:26, iter:1524] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:26, iter:1525] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:26, iter:1526] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:26, iter:1527] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:26, iter:1528] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:26, iter:1529] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:26, iter:1530] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:26, iter:1531] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:26, iter:1532] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:26, iter:1533] Loss: 0.504 | Accuracy: 99.905% \n",
      "[epoch:26, iter:1534] Loss: 0.504 | Accuracy: 99.908% \n",
      "[epoch:26, iter:1535] Loss: 0.504 | Accuracy: 99.911% \n",
      "[epoch:26, iter:1536] Loss: 0.504 | Accuracy: 99.913% \n",
      "[epoch:26, iter:1537] Loss: 0.504 | Accuracy: 99.916% \n",
      "[epoch:26, iter:1538] Loss: 0.504 | Accuracy: 99.918% \n",
      "[epoch:26, iter:1539] Loss: 0.504 | Accuracy: 99.920% \n",
      "[epoch:26, iter:1540] Loss: 0.504 | Accuracy: 99.922% \n",
      "[epoch:26, iter:1541] Loss: 0.504 | Accuracy: 99.924% \n",
      "[epoch:26, iter:1542] Loss: 0.504 | Accuracy: 99.926% \n",
      "[epoch:26, iter:1543] Loss: 0.504 | Accuracy: 99.927% \n",
      "[epoch:26, iter:1544] Loss: 0.504 | Accuracy: 99.929% \n",
      "[epoch:26, iter:1545] Loss: 0.504 | Accuracy: 99.931% \n",
      "[epoch:26, iter:1546] Loss: 0.504 | Accuracy: 99.932% \n",
      "[epoch:26, iter:1547] Loss: 0.504 | Accuracy: 99.934% \n",
      "[epoch:26, iter:1548] Loss: 0.504 | Accuracy: 99.935% \n",
      "[epoch:26, iter:1549] Loss: 0.504 | Accuracy: 99.936% \n",
      "[epoch:26, iter:1550] Loss: 0.504 | Accuracy: 99.938% \n",
      "[epoch:26, iter:1551] Loss: 0.504 | Accuracy: 99.939% \n",
      "[epoch:26, iter:1552] Loss: 0.504 | Accuracy: 99.940% \n",
      "[epoch:26, iter:1553] Loss: 0.504 | Accuracy: 99.941% \n",
      "[epoch:26, iter:1554] Loss: 0.504 | Accuracy: 99.942% \n",
      "[epoch:26, iter:1555] Loss: 0.504 | Accuracy: 99.943% \n",
      "[epoch:26, iter:1556] Loss: 0.504 | Accuracy: 99.944% \n",
      "[epoch:26, iter:1557] Loss: 0.504 | Accuracy: 99.945% \n",
      "[epoch:26, iter:1558] Loss: 0.504 | Accuracy: 99.946% \n",
      "[epoch:26, iter:1559] Loss: 0.504 | Accuracy: 99.947% \n",
      "[epoch:26, iter:1560] Loss: 0.504 | Accuracy: 99.948% \n",
      "Waiting Test!\n",
      "EPOCH=026, Loss: 0.570, Accuracy= 97.143%\n",
      "Training complete in 0m 10s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "\n",
      "Epoch: 27\n",
      "[epoch:27, iter:1561] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1562] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1563] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1564] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1565] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1566] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1567] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1568] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1569] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1570] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1571] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1572] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1573] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1574] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1575] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1576] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1577] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1578] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1579] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1580] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1581] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1582] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1583] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1584] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1585] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1586] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1587] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1588] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1589] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1590] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1591] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1592] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1593] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1594] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1595] Loss: 0.503 | Accuracy: 100.000% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:27, iter:1596] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1597] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1598] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1599] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1600] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1601] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1602] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1603] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1604] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1605] Loss: 0.504 | Accuracy: 99.931% \n",
      "[epoch:27, iter:1606] Loss: 0.504 | Accuracy: 99.932% \n",
      "[epoch:27, iter:1607] Loss: 0.504 | Accuracy: 99.934% \n",
      "[epoch:27, iter:1608] Loss: 0.504 | Accuracy: 99.935% \n",
      "[epoch:27, iter:1609] Loss: 0.504 | Accuracy: 99.936% \n",
      "[epoch:27, iter:1610] Loss: 0.504 | Accuracy: 99.938% \n",
      "[epoch:27, iter:1611] Loss: 0.504 | Accuracy: 99.939% \n",
      "[epoch:27, iter:1612] Loss: 0.504 | Accuracy: 99.940% \n",
      "[epoch:27, iter:1613] Loss: 0.504 | Accuracy: 99.941% \n",
      "[epoch:27, iter:1614] Loss: 0.504 | Accuracy: 99.942% \n",
      "[epoch:27, iter:1615] Loss: 0.504 | Accuracy: 99.943% \n",
      "[epoch:27, iter:1616] Loss: 0.504 | Accuracy: 99.944% \n",
      "[epoch:27, iter:1617] Loss: 0.504 | Accuracy: 99.945% \n",
      "[epoch:27, iter:1618] Loss: 0.504 | Accuracy: 99.946% \n",
      "[epoch:27, iter:1619] Loss: 0.504 | Accuracy: 99.947% \n",
      "[epoch:27, iter:1620] Loss: 0.504 | Accuracy: 99.948% \n",
      "Waiting Test!\n",
      "EPOCH=027, Loss: 0.655, Accuracy= 97.143%\n",
      "Training complete in 0m 11s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "\n",
      "Epoch: 28\n",
      "[epoch:28, iter:1621] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1622] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1623] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1624] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1625] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1626] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1627] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1628] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1629] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1630] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1631] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1632] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1633] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1634] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1635] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1636] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1637] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1638] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1639] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1640] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1641] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1642] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1643] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1644] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1645] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1646] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1647] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1648] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1649] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1650] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1651] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1652] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1653] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1654] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1655] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1656] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1657] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1658] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1659] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1660] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1661] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1662] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1663] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1664] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1665] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1666] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1667] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1668] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1669] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1670] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1671] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1672] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1673] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1674] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1675] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1676] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1677] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1678] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1679] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:28, iter:1680] Loss: 0.503 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=028, Loss: 0.569, Accuracy= 97.143%\n",
      "Training complete in 0m 10s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "\n",
      "Epoch: 29\n",
      "[epoch:29, iter:1681] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:29, iter:1682] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:29, iter:1683] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:29, iter:1684] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:29, iter:1685] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:29, iter:1686] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:29, iter:1687] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:29, iter:1688] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:29, iter:1689] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:29, iter:1690] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:29, iter:1691] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:29, iter:1692] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:29, iter:1693] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:29, iter:1694] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:29, iter:1695] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:29, iter:1696] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:29, iter:1697] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:29, iter:1698] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:29, iter:1699] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:29, iter:1700] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:29, iter:1701] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:29, iter:1702] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:29, iter:1703] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:29, iter:1704] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:29, iter:1705] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:29, iter:1706] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:29, iter:1707] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:29, iter:1708] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:29, iter:1709] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:29, iter:1710] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:29, iter:1711] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:29, iter:1712] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:29, iter:1713] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:29, iter:1714] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:29, iter:1715] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:29, iter:1716] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:29, iter:1717] Loss: 0.505 | Accuracy: 99.916% \n",
      "[epoch:29, iter:1718] Loss: 0.505 | Accuracy: 99.918% \n",
      "[epoch:29, iter:1719] Loss: 0.505 | Accuracy: 99.920% \n",
      "[epoch:29, iter:1720] Loss: 0.505 | Accuracy: 99.922% \n",
      "[epoch:29, iter:1721] Loss: 0.505 | Accuracy: 99.924% \n",
      "[epoch:29, iter:1722] Loss: 0.505 | Accuracy: 99.926% \n",
      "[epoch:29, iter:1723] Loss: 0.505 | Accuracy: 99.927% \n",
      "[epoch:29, iter:1724] Loss: 0.505 | Accuracy: 99.929% \n",
      "[epoch:29, iter:1725] Loss: 0.505 | Accuracy: 99.931% \n",
      "[epoch:29, iter:1726] Loss: 0.505 | Accuracy: 99.932% \n",
      "[epoch:29, iter:1727] Loss: 0.505 | Accuracy: 99.934% \n",
      "[epoch:29, iter:1728] Loss: 0.505 | Accuracy: 99.935% \n",
      "[epoch:29, iter:1729] Loss: 0.505 | Accuracy: 99.936% \n",
      "[epoch:29, iter:1730] Loss: 0.505 | Accuracy: 99.938% \n",
      "[epoch:29, iter:1731] Loss: 0.505 | Accuracy: 99.939% \n",
      "[epoch:29, iter:1732] Loss: 0.505 | Accuracy: 99.940% \n",
      "[epoch:29, iter:1733] Loss: 0.505 | Accuracy: 99.941% \n",
      "[epoch:29, iter:1734] Loss: 0.505 | Accuracy: 99.942% \n",
      "[epoch:29, iter:1735] Loss: 0.505 | Accuracy: 99.943% \n",
      "[epoch:29, iter:1736] Loss: 0.505 | Accuracy: 99.944% \n",
      "[epoch:29, iter:1737] Loss: 0.505 | Accuracy: 99.945% \n",
      "[epoch:29, iter:1738] Loss: 0.505 | Accuracy: 99.946% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:29, iter:1739] Loss: 0.505 | Accuracy: 99.947% \n",
      "[epoch:29, iter:1740] Loss: 0.505 | Accuracy: 99.948% \n",
      "Waiting Test!\n",
      "EPOCH=029, Loss: 0.569, Accuracy= 98.095%\n",
      "Epoch 00029: reducing learning rate of group 0 to 1.0290e-04.\n",
      "Training complete in 0m 10s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 30\n",
      "[epoch:30, iter:1741] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:30, iter:1742] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:30, iter:1743] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:30, iter:1744] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:30, iter:1745] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:30, iter:1746] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:30, iter:1747] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:30, iter:1748] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:30, iter:1749] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:30, iter:1750] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:30, iter:1751] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:30, iter:1752] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:30, iter:1753] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:30, iter:1754] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:30, iter:1755] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:30, iter:1756] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:30, iter:1757] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:30, iter:1758] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:30, iter:1759] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:30, iter:1760] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:30, iter:1761] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:30, iter:1762] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:30, iter:1763] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:30, iter:1764] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:30, iter:1765] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:30, iter:1766] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:30, iter:1767] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:30, iter:1768] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:30, iter:1769] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:30, iter:1770] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:30, iter:1771] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:30, iter:1772] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:30, iter:1773] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:30, iter:1774] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:30, iter:1775] Loss: 0.504 | Accuracy: 99.911% \n",
      "[epoch:30, iter:1776] Loss: 0.504 | Accuracy: 99.913% \n",
      "[epoch:30, iter:1777] Loss: 0.504 | Accuracy: 99.916% \n",
      "[epoch:30, iter:1778] Loss: 0.504 | Accuracy: 99.918% \n",
      "[epoch:30, iter:1779] Loss: 0.504 | Accuracy: 99.920% \n",
      "[epoch:30, iter:1780] Loss: 0.504 | Accuracy: 99.922% \n",
      "[epoch:30, iter:1781] Loss: 0.504 | Accuracy: 99.924% \n",
      "[epoch:30, iter:1782] Loss: 0.504 | Accuracy: 99.926% \n",
      "[epoch:30, iter:1783] Loss: 0.504 | Accuracy: 99.927% \n",
      "[epoch:30, iter:1784] Loss: 0.504 | Accuracy: 99.929% \n",
      "[epoch:30, iter:1785] Loss: 0.504 | Accuracy: 99.931% \n",
      "[epoch:30, iter:1786] Loss: 0.504 | Accuracy: 99.932% \n",
      "[epoch:30, iter:1787] Loss: 0.504 | Accuracy: 99.934% \n",
      "[epoch:30, iter:1788] Loss: 0.504 | Accuracy: 99.935% \n",
      "[epoch:30, iter:1789] Loss: 0.504 | Accuracy: 99.936% \n",
      "[epoch:30, iter:1790] Loss: 0.504 | Accuracy: 99.938% \n",
      "[epoch:30, iter:1791] Loss: 0.504 | Accuracy: 99.939% \n",
      "[epoch:30, iter:1792] Loss: 0.505 | Accuracy: 99.880% \n",
      "[epoch:30, iter:1793] Loss: 0.505 | Accuracy: 99.882% \n",
      "[epoch:30, iter:1794] Loss: 0.505 | Accuracy: 99.884% \n",
      "[epoch:30, iter:1795] Loss: 0.505 | Accuracy: 99.886% \n",
      "[epoch:30, iter:1796] Loss: 0.505 | Accuracy: 99.888% \n",
      "[epoch:30, iter:1797] Loss: 0.504 | Accuracy: 99.890% \n",
      "[epoch:30, iter:1798] Loss: 0.504 | Accuracy: 99.892% \n",
      "[epoch:30, iter:1799] Loss: 0.504 | Accuracy: 99.894% \n",
      "[epoch:30, iter:1800] Loss: 0.504 | Accuracy: 99.895% \n",
      "Waiting Test!\n",
      "EPOCH=030, Loss: 0.573, Accuracy= 97.143%\n",
      "Training complete in 0m 10s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "\n",
      "Epoch: 31\n",
      "[epoch:31, iter:1801] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1802] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1803] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1804] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1805] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1806] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1807] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1808] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1809] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1810] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1811] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1812] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1813] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1814] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1815] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1816] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1817] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1818] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1819] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1820] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1821] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1822] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1823] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1824] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1825] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1826] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1827] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1828] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1829] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1830] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1831] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1832] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1833] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1834] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1835] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1836] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1837] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1838] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1839] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1840] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1841] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1842] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1843] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1844] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1845] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1846] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1847] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1848] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1849] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1850] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1851] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1852] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1853] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1854] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1855] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1856] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1857] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1858] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1859] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:31, iter:1860] Loss: 0.503 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=031, Loss: 0.583, Accuracy= 97.143%\n",
      "Training complete in 0m 11s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "\n",
      "Epoch: 32\n",
      "[epoch:32, iter:1861] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:32, iter:1862] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:32, iter:1863] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:32, iter:1864] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:32, iter:1865] Loss: 0.525 | Accuracy: 99.375% \n",
      "[epoch:32, iter:1866] Loss: 0.521 | Accuracy: 99.479% \n",
      "[epoch:32, iter:1867] Loss: 0.519 | Accuracy: 99.554% \n",
      "[epoch:32, iter:1868] Loss: 0.517 | Accuracy: 99.609% \n",
      "[epoch:32, iter:1869] Loss: 0.515 | Accuracy: 99.653% \n",
      "[epoch:32, iter:1870] Loss: 0.514 | Accuracy: 99.688% \n",
      "[epoch:32, iter:1871] Loss: 0.513 | Accuracy: 99.716% \n",
      "[epoch:32, iter:1872] Loss: 0.512 | Accuracy: 99.740% \n",
      "[epoch:32, iter:1873] Loss: 0.512 | Accuracy: 99.760% \n",
      "[epoch:32, iter:1874] Loss: 0.511 | Accuracy: 99.777% \n",
      "[epoch:32, iter:1875] Loss: 0.511 | Accuracy: 99.792% \n",
      "[epoch:32, iter:1876] Loss: 0.510 | Accuracy: 99.805% \n",
      "[epoch:32, iter:1877] Loss: 0.510 | Accuracy: 99.816% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:32, iter:1878] Loss: 0.509 | Accuracy: 99.826% \n",
      "[epoch:32, iter:1879] Loss: 0.509 | Accuracy: 99.836% \n",
      "[epoch:32, iter:1880] Loss: 0.509 | Accuracy: 99.844% \n",
      "[epoch:32, iter:1881] Loss: 0.508 | Accuracy: 99.851% \n",
      "[epoch:32, iter:1882] Loss: 0.508 | Accuracy: 99.858% \n",
      "[epoch:32, iter:1883] Loss: 0.508 | Accuracy: 99.864% \n",
      "[epoch:32, iter:1884] Loss: 0.508 | Accuracy: 99.870% \n",
      "[epoch:32, iter:1885] Loss: 0.508 | Accuracy: 99.875% \n",
      "[epoch:32, iter:1886] Loss: 0.507 | Accuracy: 99.880% \n",
      "[epoch:32, iter:1887] Loss: 0.507 | Accuracy: 99.884% \n",
      "[epoch:32, iter:1888] Loss: 0.507 | Accuracy: 99.888% \n",
      "[epoch:32, iter:1889] Loss: 0.507 | Accuracy: 99.892% \n",
      "[epoch:32, iter:1890] Loss: 0.507 | Accuracy: 99.896% \n",
      "[epoch:32, iter:1891] Loss: 0.507 | Accuracy: 99.899% \n",
      "[epoch:32, iter:1892] Loss: 0.507 | Accuracy: 99.902% \n",
      "[epoch:32, iter:1893] Loss: 0.506 | Accuracy: 99.905% \n",
      "[epoch:32, iter:1894] Loss: 0.506 | Accuracy: 99.908% \n",
      "[epoch:32, iter:1895] Loss: 0.506 | Accuracy: 99.911% \n",
      "[epoch:32, iter:1896] Loss: 0.506 | Accuracy: 99.913% \n",
      "[epoch:32, iter:1897] Loss: 0.506 | Accuracy: 99.916% \n",
      "[epoch:32, iter:1898] Loss: 0.506 | Accuracy: 99.918% \n",
      "[epoch:32, iter:1899] Loss: 0.506 | Accuracy: 99.920% \n",
      "[epoch:32, iter:1900] Loss: 0.506 | Accuracy: 99.922% \n",
      "[epoch:32, iter:1901] Loss: 0.506 | Accuracy: 99.924% \n",
      "[epoch:32, iter:1902] Loss: 0.506 | Accuracy: 99.926% \n",
      "[epoch:32, iter:1903] Loss: 0.506 | Accuracy: 99.927% \n",
      "[epoch:32, iter:1904] Loss: 0.506 | Accuracy: 99.929% \n",
      "[epoch:32, iter:1905] Loss: 0.506 | Accuracy: 99.931% \n",
      "[epoch:32, iter:1906] Loss: 0.506 | Accuracy: 99.932% \n",
      "[epoch:32, iter:1907] Loss: 0.505 | Accuracy: 99.934% \n",
      "[epoch:32, iter:1908] Loss: 0.505 | Accuracy: 99.935% \n",
      "[epoch:32, iter:1909] Loss: 0.505 | Accuracy: 99.936% \n",
      "[epoch:32, iter:1910] Loss: 0.505 | Accuracy: 99.938% \n",
      "[epoch:32, iter:1911] Loss: 0.505 | Accuracy: 99.939% \n",
      "[epoch:32, iter:1912] Loss: 0.505 | Accuracy: 99.940% \n",
      "[epoch:32, iter:1913] Loss: 0.505 | Accuracy: 99.941% \n",
      "[epoch:32, iter:1914] Loss: 0.505 | Accuracy: 99.942% \n",
      "[epoch:32, iter:1915] Loss: 0.505 | Accuracy: 99.943% \n",
      "[epoch:32, iter:1916] Loss: 0.505 | Accuracy: 99.944% \n",
      "[epoch:32, iter:1917] Loss: 0.505 | Accuracy: 99.945% \n",
      "[epoch:32, iter:1918] Loss: 0.505 | Accuracy: 99.946% \n",
      "[epoch:32, iter:1919] Loss: 0.505 | Accuracy: 99.947% \n",
      "[epoch:32, iter:1920] Loss: 0.505 | Accuracy: 99.948% \n",
      "Waiting Test!\n",
      "EPOCH=032, Loss: 0.649, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 33\n",
      "[epoch:33, iter:1921] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1922] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1923] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1924] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1925] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1926] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1927] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1928] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1929] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1930] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1931] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1932] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1933] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1934] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1935] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1936] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1937] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1938] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1939] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1940] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1941] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1942] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1943] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1944] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1945] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1946] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1947] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1948] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1949] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1950] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1951] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1952] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1953] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1954] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1955] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1956] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1957] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1958] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1959] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1960] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1961] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1962] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1963] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1964] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1965] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1966] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1967] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1968] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1969] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1970] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1971] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1972] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1973] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1974] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1975] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1976] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1977] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1978] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1979] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:33, iter:1980] Loss: 0.503 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=033, Loss: 0.571, Accuracy= 98.095%\n",
      "Epoch 00033: reducing learning rate of group 0 to 7.2030e-05.\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 34\n",
      "[epoch:34, iter:1981] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:1982] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:1983] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:1984] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:1985] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:1986] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:1987] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:1988] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:1989] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:1990] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:1991] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:1992] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:1993] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:1994] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:1995] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:1996] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:1997] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:1998] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:1999] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2000] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2001] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2002] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2003] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2004] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2005] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2006] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2007] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2008] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2009] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2010] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2011] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2012] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2013] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2014] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2015] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2016] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2017] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2018] Loss: 0.503 | Accuracy: 100.000% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:34, iter:2019] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2020] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2021] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2022] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2023] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2024] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2025] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2026] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2027] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2028] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2029] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2030] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2031] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2032] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2033] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2034] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2035] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2036] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2037] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2038] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2039] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2040] Loss: 0.503 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=034, Loss: 0.567, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 35\n",
      "[epoch:35, iter:2041] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:35, iter:2042] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:35, iter:2043] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:35, iter:2044] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:35, iter:2045] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:35, iter:2046] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:35, iter:2047] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:35, iter:2048] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:35, iter:2049] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:35, iter:2050] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:35, iter:2051] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:35, iter:2052] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:35, iter:2053] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:35, iter:2054] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:35, iter:2055] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:35, iter:2056] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:35, iter:2057] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:35, iter:2058] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:35, iter:2059] Loss: 0.505 | Accuracy: 99.836% \n",
      "[epoch:35, iter:2060] Loss: 0.505 | Accuracy: 99.844% \n",
      "[epoch:35, iter:2061] Loss: 0.505 | Accuracy: 99.851% \n",
      "[epoch:35, iter:2062] Loss: 0.505 | Accuracy: 99.858% \n",
      "[epoch:35, iter:2063] Loss: 0.505 | Accuracy: 99.864% \n",
      "[epoch:35, iter:2064] Loss: 0.505 | Accuracy: 99.870% \n",
      "[epoch:35, iter:2065] Loss: 0.505 | Accuracy: 99.875% \n",
      "[epoch:35, iter:2066] Loss: 0.505 | Accuracy: 99.880% \n",
      "[epoch:35, iter:2067] Loss: 0.505 | Accuracy: 99.884% \n",
      "[epoch:35, iter:2068] Loss: 0.505 | Accuracy: 99.888% \n",
      "[epoch:35, iter:2069] Loss: 0.504 | Accuracy: 99.892% \n",
      "[epoch:35, iter:2070] Loss: 0.504 | Accuracy: 99.896% \n",
      "[epoch:35, iter:2071] Loss: 0.504 | Accuracy: 99.899% \n",
      "[epoch:35, iter:2072] Loss: 0.504 | Accuracy: 99.902% \n",
      "[epoch:35, iter:2073] Loss: 0.504 | Accuracy: 99.905% \n",
      "[epoch:35, iter:2074] Loss: 0.504 | Accuracy: 99.908% \n",
      "[epoch:35, iter:2075] Loss: 0.504 | Accuracy: 99.911% \n",
      "[epoch:35, iter:2076] Loss: 0.504 | Accuracy: 99.913% \n",
      "[epoch:35, iter:2077] Loss: 0.504 | Accuracy: 99.916% \n",
      "[epoch:35, iter:2078] Loss: 0.504 | Accuracy: 99.918% \n",
      "[epoch:35, iter:2079] Loss: 0.504 | Accuracy: 99.920% \n",
      "[epoch:35, iter:2080] Loss: 0.504 | Accuracy: 99.922% \n",
      "[epoch:35, iter:2081] Loss: 0.504 | Accuracy: 99.924% \n",
      "[epoch:35, iter:2082] Loss: 0.504 | Accuracy: 99.926% \n",
      "[epoch:35, iter:2083] Loss: 0.504 | Accuracy: 99.927% \n",
      "[epoch:35, iter:2084] Loss: 0.504 | Accuracy: 99.929% \n",
      "[epoch:35, iter:2085] Loss: 0.504 | Accuracy: 99.931% \n",
      "[epoch:35, iter:2086] Loss: 0.504 | Accuracy: 99.932% \n",
      "[epoch:35, iter:2087] Loss: 0.504 | Accuracy: 99.934% \n",
      "[epoch:35, iter:2088] Loss: 0.504 | Accuracy: 99.935% \n",
      "[epoch:35, iter:2089] Loss: 0.504 | Accuracy: 99.936% \n",
      "[epoch:35, iter:2090] Loss: 0.504 | Accuracy: 99.938% \n",
      "[epoch:35, iter:2091] Loss: 0.504 | Accuracy: 99.939% \n",
      "[epoch:35, iter:2092] Loss: 0.504 | Accuracy: 99.940% \n",
      "[epoch:35, iter:2093] Loss: 0.504 | Accuracy: 99.941% \n",
      "[epoch:35, iter:2094] Loss: 0.504 | Accuracy: 99.942% \n",
      "[epoch:35, iter:2095] Loss: 0.504 | Accuracy: 99.943% \n",
      "[epoch:35, iter:2096] Loss: 0.504 | Accuracy: 99.944% \n",
      "[epoch:35, iter:2097] Loss: 0.504 | Accuracy: 99.945% \n",
      "[epoch:35, iter:2098] Loss: 0.504 | Accuracy: 99.946% \n",
      "[epoch:35, iter:2099] Loss: 0.504 | Accuracy: 99.947% \n",
      "[epoch:35, iter:2100] Loss: 0.504 | Accuracy: 99.948% \n",
      "Waiting Test!\n",
      "EPOCH=035, Loss: 0.566, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 36\n",
      "[epoch:36, iter:2101] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2102] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2103] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2104] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2105] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2106] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2107] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2108] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2109] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2110] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2111] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2112] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2113] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2114] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2115] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2116] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2117] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2118] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2119] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2120] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2121] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2122] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2123] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2124] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2125] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2126] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2127] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2128] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2129] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2130] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2131] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2132] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2133] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2134] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2135] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2136] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2137] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2138] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2139] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2140] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2141] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2142] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2143] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2144] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2145] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2146] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2147] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2148] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2149] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2150] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2151] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2152] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2153] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2154] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2155] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2156] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2157] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2158] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2159] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2160] Loss: 0.503 | Accuracy: 100.000% \n",
      "Waiting Test!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH=036, Loss: 0.565, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 37\n",
      "[epoch:37, iter:2161] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2162] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2163] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2164] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2165] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2166] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2167] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2168] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2169] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2170] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2171] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2172] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2173] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2174] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2175] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2176] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2177] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2178] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2179] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2180] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2181] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2182] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2183] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2184] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2185] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2186] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2187] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2188] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2189] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2190] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2191] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2192] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2193] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2194] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2195] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2196] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2197] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2198] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2199] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2200] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2201] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2202] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2203] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2204] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2205] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2206] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2207] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2208] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2209] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2210] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2211] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2212] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2213] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2214] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2215] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2216] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2217] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2218] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2219] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2220] Loss: 0.503 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=037, Loss: 0.565, Accuracy= 98.095%\n",
      "Epoch 00037: reducing learning rate of group 0 to 5.0421e-05.\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 38\n",
      "[epoch:38, iter:2221] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2222] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2223] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2224] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2225] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2226] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2227] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2228] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2229] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2230] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2231] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2232] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2233] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2234] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2235] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2236] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2237] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2238] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2239] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2240] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2241] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2242] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2243] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2244] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2245] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2246] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2247] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2248] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2249] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2250] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2251] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2252] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2253] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2254] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2255] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2256] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2257] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2258] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2259] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2260] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2261] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2262] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2263] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2264] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2265] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2266] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2267] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2268] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2269] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2270] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2271] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2272] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2273] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2274] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2275] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2276] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2277] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2278] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2279] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2280] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=038, Loss: 0.566, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 39\n",
      "[epoch:39, iter:2281] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2282] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2283] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2284] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2285] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2286] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2287] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2288] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2289] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2290] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2291] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2292] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2293] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2294] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2295] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2296] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2297] Loss: 0.503 | Accuracy: 100.000% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:39, iter:2298] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2299] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2300] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2301] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2302] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2303] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2304] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2305] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2306] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2307] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2308] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2309] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2310] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2311] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2312] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2313] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2314] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2315] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2316] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2317] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2318] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2319] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2320] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2321] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2322] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2323] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2324] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2325] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2326] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2327] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2328] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2329] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2330] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2331] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2332] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2333] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2334] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2335] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2336] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2337] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2338] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2339] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2340] Loss: 0.503 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=039, Loss: 0.566, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 40\n",
      "[epoch:40, iter:2341] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2342] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2343] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2344] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2345] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2346] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2347] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2348] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2349] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2350] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2351] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2352] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2353] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2354] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2355] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2356] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2357] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2358] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2359] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2360] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2361] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2362] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2363] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2364] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2365] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2366] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2367] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2368] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2369] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2370] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2371] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2372] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2373] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2374] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2375] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2376] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2377] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2378] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2379] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2380] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2381] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2382] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2383] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2384] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2385] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2386] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2387] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2388] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2389] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2390] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2391] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2392] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2393] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2394] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2395] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2396] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2397] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2398] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2399] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2400] Loss: 0.503 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=040, Loss: 0.566, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 41\n",
      "[epoch:41, iter:2401] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2402] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2403] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2404] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2405] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2406] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2407] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2408] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2409] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2410] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2411] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2412] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2413] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2414] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2415] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2416] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2417] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2418] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2419] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2420] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2421] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2422] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2423] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2424] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2425] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2426] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2427] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2428] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2429] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2430] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2431] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2432] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2433] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2434] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2435] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2436] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2437] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2438] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2439] Loss: 0.502 | Accuracy: 100.000% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:41, iter:2440] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2441] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2442] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2443] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2444] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2445] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2446] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2447] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2448] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2449] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2450] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2451] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2452] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2453] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2454] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2455] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2456] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2457] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2458] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2459] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:41, iter:2460] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=041, Loss: 0.566, Accuracy= 98.095%\n",
      "Epoch 00041: reducing learning rate of group 0 to 3.5295e-05.\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 42\n",
      "[epoch:42, iter:2461] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2462] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2463] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2464] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2465] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2466] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2467] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2468] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2469] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2470] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2471] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2472] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2473] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2474] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2475] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2476] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2477] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2478] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2479] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2480] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2481] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2482] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2483] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2484] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2485] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2486] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2487] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2488] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2489] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2490] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2491] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2492] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2493] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2494] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2495] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2496] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2497] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2498] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2499] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2500] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2501] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2502] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2503] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2504] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2505] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2506] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2507] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2508] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2509] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2510] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2511] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2512] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2513] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2514] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2515] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2516] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2517] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2518] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2519] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:42, iter:2520] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=042, Loss: 0.565, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 43\n",
      "[epoch:43, iter:2521] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2522] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2523] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2524] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2525] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2526] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2527] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2528] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2529] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2530] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2531] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2532] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2533] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2534] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2535] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2536] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2537] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2538] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2539] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2540] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2541] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2542] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2543] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2544] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2545] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2546] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2547] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2548] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2549] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2550] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2551] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2552] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2553] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2554] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2555] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2556] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2557] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2558] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2559] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2560] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2561] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2562] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2563] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2564] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2565] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2566] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2567] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2568] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2569] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2570] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2571] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2572] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2573] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2574] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2575] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2576] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2577] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2578] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2579] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:43, iter:2580] Loss: 0.503 | Accuracy: 100.000% \n",
      "Waiting Test!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH=043, Loss: 0.566, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 44\n",
      "[epoch:44, iter:2581] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2582] Loss: 0.507 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2583] Loss: 0.507 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2584] Loss: 0.506 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2585] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2586] Loss: 0.505 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2587] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2588] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2589] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2590] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2591] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2592] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2593] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2594] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2595] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2596] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2597] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2598] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2599] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2600] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2601] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2602] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2603] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2604] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2605] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2606] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2607] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2608] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2609] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2610] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2611] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2612] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2613] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2614] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2615] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2616] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2617] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2618] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2619] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2620] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2621] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2622] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2623] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2624] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2625] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2626] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2627] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2628] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2629] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2630] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2631] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2632] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2633] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2634] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2635] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2636] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2637] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2638] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2639] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:44, iter:2640] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=044, Loss: 0.565, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 45\n",
      "[epoch:45, iter:2641] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2642] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2643] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2644] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2645] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2646] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2647] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2648] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2649] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2650] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2651] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2652] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2653] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2654] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2655] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2656] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2657] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2658] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2659] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2660] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2661] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2662] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2663] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2664] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2665] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2666] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2667] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2668] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2669] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2670] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2671] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2672] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2673] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2674] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2675] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2676] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2677] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2678] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2679] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2680] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2681] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2682] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2683] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2684] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2685] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2686] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2687] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2688] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2689] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2690] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2691] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2692] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2693] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2694] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2695] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2696] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2697] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2698] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2699] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:45, iter:2700] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=045, Loss: 0.566, Accuracy= 98.095%\n",
      "Epoch 00045: reducing learning rate of group 0 to 2.4706e-05.\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 46\n",
      "[epoch:46, iter:2701] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2702] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2703] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2704] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2705] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2706] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2707] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2708] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2709] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2710] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2711] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2712] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2713] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2714] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2715] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2716] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2717] Loss: 0.502 | Accuracy: 100.000% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:46, iter:2718] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2719] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2720] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2721] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2722] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2723] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2724] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2725] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2726] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2727] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2728] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2729] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2730] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2731] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2732] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2733] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2734] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2735] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2736] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2737] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2738] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2739] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2740] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2741] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2742] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2743] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2744] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2745] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2746] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2747] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2748] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2749] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2750] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2751] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2752] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2753] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:46, iter:2754] Loss: 0.503 | Accuracy: 99.942% \n",
      "[epoch:46, iter:2755] Loss: 0.503 | Accuracy: 99.943% \n",
      "[epoch:46, iter:2756] Loss: 0.503 | Accuracy: 99.944% \n",
      "[epoch:46, iter:2757] Loss: 0.503 | Accuracy: 99.945% \n",
      "[epoch:46, iter:2758] Loss: 0.503 | Accuracy: 99.946% \n",
      "[epoch:46, iter:2759] Loss: 0.503 | Accuracy: 99.947% \n",
      "[epoch:46, iter:2760] Loss: 0.503 | Accuracy: 99.948% \n",
      "Waiting Test!\n",
      "EPOCH=046, Loss: 0.566, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 47\n",
      "[epoch:47, iter:2761] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:47, iter:2762] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:47, iter:2763] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:47, iter:2764] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:47, iter:2765] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:47, iter:2766] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:47, iter:2767] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:47, iter:2768] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:47, iter:2769] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:47, iter:2770] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:47, iter:2771] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:47, iter:2772] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:47, iter:2773] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:47, iter:2774] Loss: 0.505 | Accuracy: 99.777% \n",
      "[epoch:47, iter:2775] Loss: 0.504 | Accuracy: 99.792% \n",
      "[epoch:47, iter:2776] Loss: 0.504 | Accuracy: 99.805% \n",
      "[epoch:47, iter:2777] Loss: 0.504 | Accuracy: 99.816% \n",
      "[epoch:47, iter:2778] Loss: 0.504 | Accuracy: 99.826% \n",
      "[epoch:47, iter:2779] Loss: 0.504 | Accuracy: 99.836% \n",
      "[epoch:47, iter:2780] Loss: 0.504 | Accuracy: 99.844% \n",
      "[epoch:47, iter:2781] Loss: 0.504 | Accuracy: 99.851% \n",
      "[epoch:47, iter:2782] Loss: 0.504 | Accuracy: 99.858% \n",
      "[epoch:47, iter:2783] Loss: 0.504 | Accuracy: 99.864% \n",
      "[epoch:47, iter:2784] Loss: 0.504 | Accuracy: 99.870% \n",
      "[epoch:47, iter:2785] Loss: 0.504 | Accuracy: 99.875% \n",
      "[epoch:47, iter:2786] Loss: 0.504 | Accuracy: 99.880% \n",
      "[epoch:47, iter:2787] Loss: 0.504 | Accuracy: 99.884% \n",
      "[epoch:47, iter:2788] Loss: 0.504 | Accuracy: 99.888% \n",
      "[epoch:47, iter:2789] Loss: 0.504 | Accuracy: 99.892% \n",
      "[epoch:47, iter:2790] Loss: 0.504 | Accuracy: 99.896% \n",
      "[epoch:47, iter:2791] Loss: 0.504 | Accuracy: 99.899% \n",
      "[epoch:47, iter:2792] Loss: 0.504 | Accuracy: 99.902% \n",
      "[epoch:47, iter:2793] Loss: 0.503 | Accuracy: 99.905% \n",
      "[epoch:47, iter:2794] Loss: 0.503 | Accuracy: 99.908% \n",
      "[epoch:47, iter:2795] Loss: 0.503 | Accuracy: 99.911% \n",
      "[epoch:47, iter:2796] Loss: 0.503 | Accuracy: 99.913% \n",
      "[epoch:47, iter:2797] Loss: 0.503 | Accuracy: 99.916% \n",
      "[epoch:47, iter:2798] Loss: 0.503 | Accuracy: 99.918% \n",
      "[epoch:47, iter:2799] Loss: 0.503 | Accuracy: 99.920% \n",
      "[epoch:47, iter:2800] Loss: 0.503 | Accuracy: 99.922% \n",
      "[epoch:47, iter:2801] Loss: 0.503 | Accuracy: 99.924% \n",
      "[epoch:47, iter:2802] Loss: 0.503 | Accuracy: 99.926% \n",
      "[epoch:47, iter:2803] Loss: 0.503 | Accuracy: 99.927% \n",
      "[epoch:47, iter:2804] Loss: 0.503 | Accuracy: 99.929% \n",
      "[epoch:47, iter:2805] Loss: 0.503 | Accuracy: 99.931% \n",
      "[epoch:47, iter:2806] Loss: 0.503 | Accuracy: 99.932% \n",
      "[epoch:47, iter:2807] Loss: 0.503 | Accuracy: 99.934% \n",
      "[epoch:47, iter:2808] Loss: 0.503 | Accuracy: 99.935% \n",
      "[epoch:47, iter:2809] Loss: 0.503 | Accuracy: 99.936% \n",
      "[epoch:47, iter:2810] Loss: 0.503 | Accuracy: 99.938% \n",
      "[epoch:47, iter:2811] Loss: 0.503 | Accuracy: 99.939% \n",
      "[epoch:47, iter:2812] Loss: 0.503 | Accuracy: 99.940% \n",
      "[epoch:47, iter:2813] Loss: 0.503 | Accuracy: 99.941% \n",
      "[epoch:47, iter:2814] Loss: 0.503 | Accuracy: 99.942% \n",
      "[epoch:47, iter:2815] Loss: 0.503 | Accuracy: 99.943% \n",
      "[epoch:47, iter:2816] Loss: 0.503 | Accuracy: 99.944% \n",
      "[epoch:47, iter:2817] Loss: 0.503 | Accuracy: 99.945% \n",
      "[epoch:47, iter:2818] Loss: 0.503 | Accuracy: 99.946% \n",
      "[epoch:47, iter:2819] Loss: 0.503 | Accuracy: 99.947% \n",
      "[epoch:47, iter:2820] Loss: 0.503 | Accuracy: 99.948% \n",
      "Waiting Test!\n",
      "EPOCH=047, Loss: 0.569, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 48\n",
      "[epoch:48, iter:2821] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2822] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2823] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2824] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2825] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2826] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2827] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2828] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2829] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2830] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2831] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2832] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2833] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2834] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2835] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2836] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2837] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2838] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2839] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2840] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2841] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2842] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2843] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2844] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2845] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2846] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2847] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2848] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2849] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2850] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2851] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2852] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2853] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2854] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2855] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2856] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2857] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2858] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2859] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2860] Loss: 0.502 | Accuracy: 100.000% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:48, iter:2861] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2862] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2863] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2864] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2865] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2866] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2867] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2868] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2869] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2870] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2871] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2872] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2873] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2874] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2875] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2876] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2877] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2878] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2879] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:48, iter:2880] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=048, Loss: 0.569, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 49\n",
      "[epoch:49, iter:2881] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2882] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2883] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2884] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2885] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2886] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2887] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2888] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2889] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2890] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2891] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2892] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2893] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2894] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2895] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2896] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2897] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2898] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2899] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2900] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2901] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2902] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2903] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2904] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2905] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2906] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2907] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2908] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2909] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2910] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2911] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2912] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2913] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2914] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2915] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2916] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2917] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2918] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2919] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2920] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2921] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2922] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2923] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2924] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2925] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2926] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2927] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2928] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2929] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2930] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2931] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2932] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2933] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2934] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2935] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2936] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2937] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2938] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2939] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:49, iter:2940] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=049, Loss: 0.568, Accuracy= 98.095%\n",
      "Epoch 00049: reducing learning rate of group 0 to 1.7294e-05.\n",
      "Training complete in 0m 10s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 50\n",
      "[epoch:50, iter:2941] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2942] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2943] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2944] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2945] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2946] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2947] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2948] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2949] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2950] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2951] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2952] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2953] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2954] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2955] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2956] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2957] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2958] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2959] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2960] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2961] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2962] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2963] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2964] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2965] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2966] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2967] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2968] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2969] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2970] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2971] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2972] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2973] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2974] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2975] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2976] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2977] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2978] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2979] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2980] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2981] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2982] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2983] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2984] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2985] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:50, iter:2986] Loss: 0.503 | Accuracy: 99.932% \n",
      "[epoch:50, iter:2987] Loss: 0.503 | Accuracy: 99.934% \n",
      "[epoch:50, iter:2988] Loss: 0.503 | Accuracy: 99.935% \n",
      "[epoch:50, iter:2989] Loss: 0.503 | Accuracy: 99.936% \n",
      "[epoch:50, iter:2990] Loss: 0.503 | Accuracy: 99.938% \n",
      "[epoch:50, iter:2991] Loss: 0.503 | Accuracy: 99.939% \n",
      "[epoch:50, iter:2992] Loss: 0.503 | Accuracy: 99.940% \n",
      "[epoch:50, iter:2993] Loss: 0.503 | Accuracy: 99.941% \n",
      "[epoch:50, iter:2994] Loss: 0.503 | Accuracy: 99.942% \n",
      "[epoch:50, iter:2995] Loss: 0.503 | Accuracy: 99.943% \n",
      "[epoch:50, iter:2996] Loss: 0.503 | Accuracy: 99.944% \n",
      "[epoch:50, iter:2997] Loss: 0.503 | Accuracy: 99.945% \n",
      "[epoch:50, iter:2998] Loss: 0.503 | Accuracy: 99.946% \n",
      "[epoch:50, iter:2999] Loss: 0.503 | Accuracy: 99.947% \n",
      "[epoch:50, iter:3000] Loss: 0.503 | Accuracy: 99.948% \n",
      "Waiting Test!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH=050, Loss: 0.568, Accuracy= 98.095%\n",
      "Training complete in 0m 10s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 51\n",
      "[epoch:51, iter:3001] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3002] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3003] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3004] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3005] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3006] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3007] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3008] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3009] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3010] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3011] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3012] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3013] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3014] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3015] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3016] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3017] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3018] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3019] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3020] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3021] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3022] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3023] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3024] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3025] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3026] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3027] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3028] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3029] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3030] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3031] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3032] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3033] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3034] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3035] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3036] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3037] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3038] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3039] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3040] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3041] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3042] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3043] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3044] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3045] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3046] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3047] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3048] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3049] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3050] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3051] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3052] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3053] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3054] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3055] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3056] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3057] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3058] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3059] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3060] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=051, Loss: 0.568, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 52\n",
      "[epoch:52, iter:3061] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3062] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3063] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3064] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3065] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3066] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3067] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3068] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3069] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3070] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3071] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3072] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3073] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3074] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3075] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3076] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3077] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3078] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3079] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3080] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3081] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3082] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3083] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3084] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3085] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3086] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3087] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3088] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3089] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3090] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3091] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3092] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3093] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3094] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3095] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3096] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3097] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3098] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3099] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3100] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3101] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3102] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3103] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3104] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3105] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3106] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3107] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3108] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3109] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3110] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3111] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3112] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3113] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3114] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3115] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3116] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3117] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3118] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3119] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:52, iter:3120] Loss: 0.503 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=052, Loss: 0.647, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 53\n",
      "[epoch:53, iter:3121] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3122] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3123] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3124] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3125] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3126] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3127] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3128] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3129] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3130] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3131] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3132] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3133] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3134] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3135] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3136] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3137] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3138] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3139] Loss: 0.502 | Accuracy: 100.000% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:53, iter:3140] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3141] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3142] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3143] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3144] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3145] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3146] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3147] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3148] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3149] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3150] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3151] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3152] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3153] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3154] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3155] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3156] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3157] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3158] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3159] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3160] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3161] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3162] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3163] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3164] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3165] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3166] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3167] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3168] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3169] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3170] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3171] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3172] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3173] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3174] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3175] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3176] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3177] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3178] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3179] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:53, iter:3180] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=053, Loss: 0.567, Accuracy= 98.095%\n",
      "Epoch 00053: reducing learning rate of group 0 to 1.2106e-05.\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 54\n",
      "[epoch:54, iter:3181] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3182] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3183] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3184] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3185] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3186] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3187] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3188] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3189] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3190] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3191] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3192] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3193] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3194] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3195] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3196] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3197] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3198] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3199] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3200] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3201] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3202] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3203] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3204] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3205] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3206] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3207] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3208] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3209] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3210] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3211] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3212] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3213] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3214] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3215] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3216] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3217] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3218] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3219] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3220] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3221] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3222] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3223] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3224] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3225] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3226] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3227] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3228] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3229] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3230] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3231] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3232] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3233] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3234] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3235] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3236] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3237] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3238] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3239] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:54, iter:3240] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=054, Loss: 0.567, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 55\n",
      "[epoch:55, iter:3241] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3242] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3243] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3244] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3245] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3246] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3247] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3248] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3249] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3250] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3251] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3252] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3253] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3254] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3255] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3256] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3257] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3258] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3259] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3260] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3261] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3262] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3263] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3264] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3265] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3266] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3267] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3268] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3269] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3270] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3271] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3272] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3273] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3274] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3275] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3276] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3277] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3278] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3279] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3280] Loss: 0.502 | Accuracy: 100.000% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:55, iter:3281] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3282] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3283] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3284] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3285] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3286] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3287] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3288] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3289] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3290] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3291] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3292] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3293] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3294] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3295] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3296] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3297] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3298] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3299] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:55, iter:3300] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=055, Loss: 0.646, Accuracy= 98.095%\n",
      "Training complete in 0m 10s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 56\n",
      "[epoch:56, iter:3301] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3302] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3303] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3304] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3305] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3306] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3307] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3308] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3309] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3310] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3311] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3312] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3313] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3314] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3315] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3316] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3317] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3318] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3319] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3320] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3321] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3322] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3323] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3324] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3325] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3326] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3327] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3328] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3329] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3330] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3331] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3332] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3333] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3334] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3335] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3336] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3337] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3338] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3339] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3340] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3341] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3342] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3343] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3344] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3345] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3346] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3347] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3348] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3349] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3350] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3351] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3352] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3353] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3354] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3355] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3356] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3357] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3358] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3359] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:56, iter:3360] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=056, Loss: 0.566, Accuracy= 98.095%\n",
      "Training complete in 0m 10s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 57\n",
      "[epoch:57, iter:3361] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3362] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3363] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3364] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3365] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3366] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3367] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3368] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3369] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3370] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3371] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3372] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3373] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3374] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3375] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3376] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3377] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3378] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3379] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3380] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3381] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3382] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3383] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3384] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3385] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3386] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3387] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3388] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3389] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3390] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3391] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3392] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3393] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3394] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3395] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3396] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3397] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3398] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3399] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3400] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3401] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3402] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3403] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3404] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3405] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3406] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3407] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3408] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3409] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3410] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3411] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3412] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3413] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3414] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3415] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3416] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3417] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3418] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3419] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:57, iter:3420] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH=057, Loss: 0.566, Accuracy= 98.095%\n",
      "Epoch 00057: reducing learning rate of group 0 to 8.4743e-06.\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 58\n",
      "[epoch:58, iter:3421] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:58, iter:3422] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:58, iter:3423] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:58, iter:3424] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:58, iter:3425] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:58, iter:3426] Loss: 0.507 | Accuracy: 99.479% \n",
      "[epoch:58, iter:3427] Loss: 0.506 | Accuracy: 99.554% \n",
      "[epoch:58, iter:3428] Loss: 0.506 | Accuracy: 99.609% \n",
      "[epoch:58, iter:3429] Loss: 0.506 | Accuracy: 99.653% \n",
      "[epoch:58, iter:3430] Loss: 0.505 | Accuracy: 99.688% \n",
      "[epoch:58, iter:3431] Loss: 0.505 | Accuracy: 99.716% \n",
      "[epoch:58, iter:3432] Loss: 0.505 | Accuracy: 99.740% \n",
      "[epoch:58, iter:3433] Loss: 0.505 | Accuracy: 99.760% \n",
      "[epoch:58, iter:3434] Loss: 0.504 | Accuracy: 99.777% \n",
      "[epoch:58, iter:3435] Loss: 0.504 | Accuracy: 99.792% \n",
      "[epoch:58, iter:3436] Loss: 0.504 | Accuracy: 99.805% \n",
      "[epoch:58, iter:3437] Loss: 0.504 | Accuracy: 99.816% \n",
      "[epoch:58, iter:3438] Loss: 0.504 | Accuracy: 99.826% \n",
      "[epoch:58, iter:3439] Loss: 0.504 | Accuracy: 99.836% \n",
      "[epoch:58, iter:3440] Loss: 0.504 | Accuracy: 99.844% \n",
      "[epoch:58, iter:3441] Loss: 0.504 | Accuracy: 99.851% \n",
      "[epoch:58, iter:3442] Loss: 0.504 | Accuracy: 99.858% \n",
      "[epoch:58, iter:3443] Loss: 0.503 | Accuracy: 99.864% \n",
      "[epoch:58, iter:3444] Loss: 0.503 | Accuracy: 99.870% \n",
      "[epoch:58, iter:3445] Loss: 0.503 | Accuracy: 99.875% \n",
      "[epoch:58, iter:3446] Loss: 0.503 | Accuracy: 99.880% \n",
      "[epoch:58, iter:3447] Loss: 0.503 | Accuracy: 99.884% \n",
      "[epoch:58, iter:3448] Loss: 0.503 | Accuracy: 99.888% \n",
      "[epoch:58, iter:3449] Loss: 0.503 | Accuracy: 99.892% \n",
      "[epoch:58, iter:3450] Loss: 0.503 | Accuracy: 99.896% \n",
      "[epoch:58, iter:3451] Loss: 0.503 | Accuracy: 99.899% \n",
      "[epoch:58, iter:3452] Loss: 0.503 | Accuracy: 99.902% \n",
      "[epoch:58, iter:3453] Loss: 0.503 | Accuracy: 99.905% \n",
      "[epoch:58, iter:3454] Loss: 0.503 | Accuracy: 99.908% \n",
      "[epoch:58, iter:3455] Loss: 0.503 | Accuracy: 99.911% \n",
      "[epoch:58, iter:3456] Loss: 0.503 | Accuracy: 99.913% \n",
      "[epoch:58, iter:3457] Loss: 0.503 | Accuracy: 99.916% \n",
      "[epoch:58, iter:3458] Loss: 0.503 | Accuracy: 99.918% \n",
      "[epoch:58, iter:3459] Loss: 0.503 | Accuracy: 99.920% \n",
      "[epoch:58, iter:3460] Loss: 0.503 | Accuracy: 99.922% \n",
      "[epoch:58, iter:3461] Loss: 0.503 | Accuracy: 99.924% \n",
      "[epoch:58, iter:3462] Loss: 0.503 | Accuracy: 99.926% \n",
      "[epoch:58, iter:3463] Loss: 0.503 | Accuracy: 99.927% \n",
      "[epoch:58, iter:3464] Loss: 0.503 | Accuracy: 99.929% \n",
      "[epoch:58, iter:3465] Loss: 0.503 | Accuracy: 99.931% \n",
      "[epoch:58, iter:3466] Loss: 0.503 | Accuracy: 99.932% \n",
      "[epoch:58, iter:3467] Loss: 0.503 | Accuracy: 99.934% \n",
      "[epoch:58, iter:3468] Loss: 0.503 | Accuracy: 99.935% \n",
      "[epoch:58, iter:3469] Loss: 0.503 | Accuracy: 99.936% \n",
      "[epoch:58, iter:3470] Loss: 0.503 | Accuracy: 99.938% \n",
      "[epoch:58, iter:3471] Loss: 0.503 | Accuracy: 99.939% \n",
      "[epoch:58, iter:3472] Loss: 0.503 | Accuracy: 99.940% \n",
      "[epoch:58, iter:3473] Loss: 0.503 | Accuracy: 99.941% \n",
      "[epoch:58, iter:3474] Loss: 0.503 | Accuracy: 99.942% \n",
      "[epoch:58, iter:3475] Loss: 0.503 | Accuracy: 99.943% \n",
      "[epoch:58, iter:3476] Loss: 0.503 | Accuracy: 99.944% \n",
      "[epoch:58, iter:3477] Loss: 0.503 | Accuracy: 99.945% \n",
      "[epoch:58, iter:3478] Loss: 0.503 | Accuracy: 99.946% \n",
      "[epoch:58, iter:3479] Loss: 0.503 | Accuracy: 99.947% \n",
      "[epoch:58, iter:3480] Loss: 0.503 | Accuracy: 99.948% \n",
      "Waiting Test!\n",
      "EPOCH=058, Loss: 0.566, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 59\n",
      "[epoch:59, iter:3481] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3482] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3483] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3484] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3485] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3486] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3487] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3488] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3489] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3490] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3491] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3492] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3493] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3494] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3495] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3496] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3497] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3498] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3499] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3500] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3501] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3502] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3503] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3504] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3505] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3506] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3507] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3508] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3509] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3510] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3511] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3512] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3513] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3514] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3515] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3516] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3517] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3518] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3519] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3520] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3521] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3522] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3523] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3524] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3525] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3526] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3527] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3528] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3529] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3530] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3531] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3532] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3533] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3534] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3535] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3536] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3537] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3538] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3539] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:59, iter:3540] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=059, Loss: 0.565, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 60\n",
      "[epoch:60, iter:3541] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3542] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3543] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3544] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3545] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3546] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3547] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3548] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3549] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3550] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3551] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3552] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3553] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3554] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3555] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3556] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3557] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3558] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3559] Loss: 0.502 | Accuracy: 100.000% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:60, iter:3560] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3561] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3562] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3563] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3564] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3565] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3566] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3567] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3568] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3569] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3570] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3571] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3572] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3573] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3574] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3575] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3576] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3577] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3578] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3579] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3580] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3581] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3582] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3583] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3584] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3585] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3586] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3587] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3588] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3589] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3590] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3591] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3592] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3593] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3594] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3595] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3596] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3597] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3598] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3599] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:60, iter:3600] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=060, Loss: 0.571, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 61\n",
      "[epoch:61, iter:3601] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3602] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3603] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3604] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3605] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3606] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3607] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3608] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3609] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3610] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3611] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3612] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3613] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3614] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3615] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3616] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3617] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3618] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3619] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3620] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3621] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3622] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3623] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3624] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3625] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3626] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3627] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3628] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3629] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3630] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3631] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3632] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3633] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3634] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3635] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3636] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3637] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3638] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3639] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3640] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3641] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3642] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3643] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3644] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3645] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3646] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3647] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3648] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3649] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3650] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3651] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3652] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3653] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3654] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3655] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3656] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3657] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3658] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3659] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:61, iter:3660] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=061, Loss: 0.572, Accuracy= 98.095%\n",
      "Epoch 00061: reducing learning rate of group 0 to 5.9320e-06.\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 62\n",
      "[epoch:62, iter:3661] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3662] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3663] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3664] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3665] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3666] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3667] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3668] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3669] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3670] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3671] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3672] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3673] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3674] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3675] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3676] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3677] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3678] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3679] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3680] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3681] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3682] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3683] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3684] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3685] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3686] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3687] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3688] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3689] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3690] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3691] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3692] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3693] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3694] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3695] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3696] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3697] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3698] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3699] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3700] Loss: 0.502 | Accuracy: 100.000% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:62, iter:3701] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3702] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3703] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3704] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3705] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3706] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3707] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3708] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3709] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3710] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3711] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3712] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3713] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3714] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3715] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3716] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3717] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3718] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3719] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:62, iter:3720] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=062, Loss: 0.572, Accuracy= 98.095%\n",
      "Training complete in 0m 10s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 63\n",
      "[epoch:63, iter:3721] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3722] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3723] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3724] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3725] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3726] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3727] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3728] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3729] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3730] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3731] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3732] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3733] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3734] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3735] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3736] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3737] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3738] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3739] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3740] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3741] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3742] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3743] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3744] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3745] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3746] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3747] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3748] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3749] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3750] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3751] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3752] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3753] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3754] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3755] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3756] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3757] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3758] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3759] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3760] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3761] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3762] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3763] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3764] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3765] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3766] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3767] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3768] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3769] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3770] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3771] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3772] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3773] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3774] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3775] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3776] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3777] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3778] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3779] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:63, iter:3780] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=063, Loss: 0.567, Accuracy= 98.095%\n",
      "Training complete in 0m 10s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 64\n",
      "[epoch:64, iter:3781] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3782] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3783] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3784] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3785] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3786] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3787] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3788] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3789] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3790] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3791] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3792] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3793] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3794] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3795] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3796] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3797] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3798] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3799] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3800] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3801] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3802] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3803] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3804] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3805] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3806] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3807] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3808] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3809] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3810] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3811] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3812] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3813] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3814] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3815] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3816] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3817] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3818] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3819] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3820] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3821] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3822] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3823] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3824] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3825] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3826] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3827] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3828] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3829] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3830] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3831] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3832] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3833] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3834] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3835] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3836] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3837] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3838] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3839] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:64, iter:3840] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH=064, Loss: 0.644, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 65\n",
      "[epoch:65, iter:3841] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3842] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3843] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3844] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3845] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3846] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3847] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3848] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3849] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3850] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3851] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3852] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3853] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3854] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3855] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3856] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3857] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3858] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3859] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3860] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3861] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3862] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3863] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3864] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3865] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3866] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3867] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3868] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3869] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3870] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3871] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3872] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3873] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3874] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3875] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3876] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3877] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3878] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3879] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3880] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3881] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3882] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3883] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3884] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3885] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3886] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3887] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3888] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3889] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3890] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3891] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3892] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3893] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3894] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3895] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3896] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3897] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3898] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3899] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:65, iter:3900] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=065, Loss: 0.644, Accuracy= 98.095%\n",
      "Epoch 00065: reducing learning rate of group 0 to 4.1524e-06.\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 66\n",
      "[epoch:66, iter:3901] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3902] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3903] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3904] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3905] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3906] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3907] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3908] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3909] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3910] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3911] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3912] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3913] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3914] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3915] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3916] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3917] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3918] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3919] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3920] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3921] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3922] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3923] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3924] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3925] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3926] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3927] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3928] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3929] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3930] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3931] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3932] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3933] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3934] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3935] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3936] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3937] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3938] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3939] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3940] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3941] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3942] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3943] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3944] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3945] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3946] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3947] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3948] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3949] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3950] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3951] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3952] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3953] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3954] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3955] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3956] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3957] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3958] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3959] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:66, iter:3960] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=066, Loss: 0.566, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 67\n",
      "[epoch:67, iter:3961] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:67, iter:3962] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:67, iter:3963] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:67, iter:3964] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:67, iter:3965] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:67, iter:3966] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:67, iter:3967] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:67, iter:3968] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:67, iter:3969] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:67, iter:3970] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:67, iter:3971] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:67, iter:3972] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:67, iter:3973] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:67, iter:3974] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:67, iter:3975] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:67, iter:3976] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:67, iter:3977] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:67, iter:3978] Loss: 0.502 | Accuracy: 100.000% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:67, iter:3979] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:67, iter:3980] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:67, iter:3981] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:67, iter:3982] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:67, iter:3983] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:67, iter:3984] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:67, iter:3985] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:67, iter:3986] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:67, iter:3987] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:67, iter:3988] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:67, iter:3989] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:67, iter:3990] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:67, iter:3991] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:67, iter:3992] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:67, iter:3993] Loss: 0.504 | Accuracy: 99.905% \n",
      "[epoch:67, iter:3994] Loss: 0.504 | Accuracy: 99.908% \n",
      "[epoch:67, iter:3995] Loss: 0.504 | Accuracy: 99.911% \n",
      "[epoch:67, iter:3996] Loss: 0.504 | Accuracy: 99.913% \n",
      "[epoch:67, iter:3997] Loss: 0.504 | Accuracy: 99.916% \n",
      "[epoch:67, iter:3998] Loss: 0.504 | Accuracy: 99.918% \n",
      "[epoch:67, iter:3999] Loss: 0.504 | Accuracy: 99.920% \n",
      "[epoch:67, iter:4000] Loss: 0.504 | Accuracy: 99.922% \n",
      "[epoch:67, iter:4001] Loss: 0.504 | Accuracy: 99.924% \n",
      "[epoch:67, iter:4002] Loss: 0.504 | Accuracy: 99.926% \n",
      "[epoch:67, iter:4003] Loss: 0.504 | Accuracy: 99.927% \n",
      "[epoch:67, iter:4004] Loss: 0.503 | Accuracy: 99.929% \n",
      "[epoch:67, iter:4005] Loss: 0.503 | Accuracy: 99.931% \n",
      "[epoch:67, iter:4006] Loss: 0.503 | Accuracy: 99.932% \n",
      "[epoch:67, iter:4007] Loss: 0.503 | Accuracy: 99.934% \n",
      "[epoch:67, iter:4008] Loss: 0.503 | Accuracy: 99.935% \n",
      "[epoch:67, iter:4009] Loss: 0.503 | Accuracy: 99.936% \n",
      "[epoch:67, iter:4010] Loss: 0.503 | Accuracy: 99.938% \n",
      "[epoch:67, iter:4011] Loss: 0.503 | Accuracy: 99.939% \n",
      "[epoch:67, iter:4012] Loss: 0.503 | Accuracy: 99.940% \n",
      "[epoch:67, iter:4013] Loss: 0.503 | Accuracy: 99.941% \n",
      "[epoch:67, iter:4014] Loss: 0.503 | Accuracy: 99.942% \n",
      "[epoch:67, iter:4015] Loss: 0.503 | Accuracy: 99.943% \n",
      "[epoch:67, iter:4016] Loss: 0.503 | Accuracy: 99.944% \n",
      "[epoch:67, iter:4017] Loss: 0.503 | Accuracy: 99.945% \n",
      "[epoch:67, iter:4018] Loss: 0.503 | Accuracy: 99.946% \n",
      "[epoch:67, iter:4019] Loss: 0.503 | Accuracy: 99.947% \n",
      "[epoch:67, iter:4020] Loss: 0.503 | Accuracy: 99.948% \n",
      "Waiting Test!\n",
      "EPOCH=067, Loss: 0.566, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 68\n",
      "[epoch:68, iter:4021] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4022] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4023] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4024] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4025] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4026] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4027] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4028] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4029] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4030] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4031] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4032] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4033] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4034] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4035] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4036] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4037] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4038] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4039] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4040] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4041] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4042] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4043] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4044] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4045] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4046] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4047] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4048] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4049] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4050] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4051] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4052] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4053] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4054] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4055] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4056] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4057] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4058] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4059] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4060] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4061] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4062] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4063] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4064] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4065] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4066] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4067] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4068] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4069] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4070] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4071] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4072] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:68, iter:4073] Loss: 0.503 | Accuracy: 99.941% \n",
      "[epoch:68, iter:4074] Loss: 0.503 | Accuracy: 99.942% \n",
      "[epoch:68, iter:4075] Loss: 0.503 | Accuracy: 99.943% \n",
      "[epoch:68, iter:4076] Loss: 0.503 | Accuracy: 99.944% \n",
      "[epoch:68, iter:4077] Loss: 0.503 | Accuracy: 99.945% \n",
      "[epoch:68, iter:4078] Loss: 0.503 | Accuracy: 99.946% \n",
      "[epoch:68, iter:4079] Loss: 0.503 | Accuracy: 99.947% \n",
      "[epoch:68, iter:4080] Loss: 0.503 | Accuracy: 99.948% \n",
      "Waiting Test!\n",
      "EPOCH=068, Loss: 0.566, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 69\n",
      "[epoch:69, iter:4081] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4082] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4083] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4084] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4085] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4086] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4087] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4088] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4089] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4090] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4091] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4092] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4093] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4094] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4095] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4096] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4097] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4098] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4099] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4100] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4101] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4102] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4103] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4104] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4105] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4106] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4107] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4108] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4109] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4110] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4111] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4112] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4113] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4114] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4115] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4116] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4117] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4118] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4119] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4120] Loss: 0.502 | Accuracy: 100.000% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:69, iter:4121] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4122] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4123] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4124] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4125] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4126] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4127] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4128] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4129] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4130] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4131] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4132] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4133] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4134] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4135] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4136] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4137] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4138] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4139] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:69, iter:4140] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=069, Loss: 0.566, Accuracy= 98.095%\n",
      "Epoch 00069: reducing learning rate of group 0 to 2.9067e-06.\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 70\n",
      "[epoch:70, iter:4141] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4142] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4143] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4144] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4145] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4146] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4147] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4148] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4149] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4150] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4151] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4152] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4153] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4154] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4155] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4156] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4157] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4158] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4159] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4160] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4161] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4162] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4163] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4164] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4165] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4166] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4167] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4168] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4169] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4170] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4171] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4172] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4173] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4174] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4175] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4176] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4177] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4178] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4179] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4180] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4181] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4182] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4183] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4184] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4185] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4186] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4187] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4188] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4189] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4190] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4191] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4192] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4193] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4194] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4195] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4196] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4197] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4198] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4199] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:70, iter:4200] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=070, Loss: 0.566, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 71\n",
      "[epoch:71, iter:4201] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4202] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4203] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4204] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4205] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4206] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4207] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4208] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4209] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4210] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4211] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4212] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4213] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4214] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4215] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4216] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4217] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4218] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4219] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4220] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4221] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4222] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4223] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4224] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4225] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4226] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4227] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4228] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4229] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4230] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4231] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4232] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4233] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4234] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4235] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4236] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4237] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4238] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4239] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4240] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4241] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4242] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4243] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4244] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4245] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4246] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4247] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4248] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4249] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4250] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4251] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4252] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4253] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4254] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4255] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4256] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4257] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4258] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4259] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:71, iter:4260] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH=071, Loss: 0.566, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 72\n",
      "[epoch:72, iter:4261] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4262] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4263] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4264] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4265] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4266] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4267] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4268] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4269] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4270] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4271] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4272] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4273] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4274] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4275] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4276] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4277] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4278] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4279] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4280] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4281] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4282] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4283] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4284] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4285] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4286] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4287] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4288] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4289] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4290] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4291] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4292] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4293] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4294] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4295] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4296] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4297] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4298] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4299] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4300] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4301] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4302] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4303] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4304] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4305] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4306] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4307] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4308] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4309] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4310] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4311] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4312] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4313] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4314] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4315] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4316] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4317] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4318] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4319] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:72, iter:4320] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=072, Loss: 0.567, Accuracy= 98.095%\n",
      "Training complete in 0m 10s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 73\n",
      "[epoch:73, iter:4321] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4322] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4323] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4324] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4325] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4326] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4327] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4328] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4329] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4330] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4331] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4332] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4333] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4334] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4335] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4336] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4337] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4338] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4339] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4340] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4341] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4342] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4343] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4344] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4345] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4346] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4347] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4348] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4349] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4350] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4351] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4352] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4353] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4354] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4355] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4356] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4357] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4358] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4359] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4360] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4361] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4362] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4363] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4364] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4365] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4366] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4367] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4368] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4369] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4370] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4371] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4372] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4373] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4374] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4375] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4376] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4377] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4378] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4379] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:73, iter:4380] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=073, Loss: 0.567, Accuracy= 98.095%\n",
      "Epoch 00073: reducing learning rate of group 0 to 2.0347e-06.\n",
      "Training complete in 0m 10s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 74\n",
      "[epoch:74, iter:4381] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4382] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4383] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4384] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4385] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4386] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4387] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4388] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4389] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4390] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4391] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4392] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4393] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4394] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4395] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4396] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4397] Loss: 0.502 | Accuracy: 100.000% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:74, iter:4398] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4399] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4400] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4401] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4402] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4403] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4404] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4405] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4406] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4407] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4408] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4409] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4410] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4411] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4412] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4413] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4414] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4415] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4416] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4417] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4418] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4419] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4420] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4421] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4422] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4423] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4424] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4425] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4426] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4427] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4428] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4429] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4430] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4431] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4432] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4433] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4434] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4435] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4436] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4437] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4438] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4439] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:74, iter:4440] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=074, Loss: 0.566, Accuracy= 98.095%\n",
      "Training complete in 0m 10s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 75\n",
      "[epoch:75, iter:4441] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4442] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4443] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4444] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4445] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4446] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4447] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4448] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4449] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4450] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4451] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4452] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4453] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4454] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4455] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4456] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4457] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4458] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4459] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4460] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4461] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4462] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4463] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4464] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4465] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4466] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4467] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4468] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4469] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4470] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4471] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4472] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4473] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4474] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4475] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4476] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4477] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4478] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4479] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4480] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4481] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4482] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4483] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4484] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4485] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4486] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4487] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4488] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4489] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4490] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4491] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4492] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4493] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4494] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4495] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4496] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4497] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4498] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4499] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:75, iter:4500] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=075, Loss: 0.571, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 76\n",
      "[epoch:76, iter:4501] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4502] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4503] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4504] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4505] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4506] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4507] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4508] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4509] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4510] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4511] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4512] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4513] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4514] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4515] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4516] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4517] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4518] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4519] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4520] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4521] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4522] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4523] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4524] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4525] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4526] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4527] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4528] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4529] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4530] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4531] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4532] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4533] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4534] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4535] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4536] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4537] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4538] Loss: 0.502 | Accuracy: 100.000% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:76, iter:4539] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4540] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4541] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4542] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4543] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4544] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4545] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4546] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4547] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4548] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4549] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4550] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4551] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4552] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4553] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4554] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4555] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4556] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4557] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4558] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4559] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:76, iter:4560] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=076, Loss: 0.644, Accuracy= 98.095%\n",
      "Training complete in 0m 10s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 77\n",
      "[epoch:77, iter:4561] Loss: 0.501 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4562] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4563] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4564] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4565] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4566] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4567] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4568] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4569] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4570] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4571] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4572] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4573] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4574] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4575] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4576] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4577] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4578] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4579] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4580] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4581] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4582] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4583] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4584] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4585] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4586] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4587] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4588] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4589] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4590] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4591] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4592] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4593] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4594] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4595] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4596] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4597] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4598] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4599] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4600] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4601] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4602] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4603] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4604] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4605] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4606] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4607] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4608] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4609] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4610] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4611] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4612] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4613] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4614] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4615] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4616] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4617] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4618] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4619] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:77, iter:4620] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=077, Loss: 0.566, Accuracy= 98.095%\n",
      "Epoch 00077: reducing learning rate of group 0 to 1.4243e-06.\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 78\n",
      "[epoch:78, iter:4621] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4622] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4623] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4624] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4625] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4626] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4627] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4628] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4629] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4630] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4631] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4632] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4633] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4634] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4635] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4636] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4637] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4638] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4639] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4640] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4641] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4642] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4643] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4644] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4645] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4646] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4647] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4648] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4649] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4650] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4651] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4652] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4653] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4654] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4655] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4656] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4657] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4658] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4659] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4660] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4661] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4662] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4663] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4664] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4665] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4666] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4667] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4668] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4669] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4670] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4671] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4672] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4673] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4674] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4675] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4676] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4677] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4678] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:78, iter:4679] Loss: 0.502 | Accuracy: 100.000% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:78, iter:4680] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=078, Loss: 0.565, Accuracy= 98.095%\n",
      "Training complete in 0m 10s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 79\n",
      "[epoch:79, iter:4681] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4682] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4683] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4684] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4685] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4686] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4687] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4688] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4689] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4690] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4691] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4692] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4693] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4694] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4695] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4696] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4697] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4698] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4699] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4700] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4701] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4702] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4703] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4704] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4705] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4706] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4707] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4708] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4709] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4710] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4711] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4712] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4713] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4714] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4715] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4716] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4717] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4718] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4719] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4720] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4721] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4722] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4723] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4724] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4725] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4726] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4727] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4728] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4729] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4730] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4731] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4732] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4733] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4734] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4735] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4736] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4737] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4738] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4739] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:79, iter:4740] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=079, Loss: 0.570, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 80\n",
      "[epoch:80, iter:4741] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4742] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4743] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4744] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4745] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4746] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4747] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4748] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4749] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4750] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4751] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4752] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4753] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4754] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4755] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4756] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4757] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4758] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4759] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4760] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4761] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4762] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4763] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4764] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4765] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4766] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4767] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4768] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4769] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4770] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4771] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4772] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4773] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4774] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4775] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4776] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4777] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4778] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4779] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4780] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4781] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4782] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4783] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4784] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4785] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4786] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4787] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4788] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4789] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4790] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4791] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4792] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4793] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4794] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4795] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4796] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4797] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4798] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4799] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:80, iter:4800] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=080, Loss: 0.566, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 81\n",
      "[epoch:81, iter:4801] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4802] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4803] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4804] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4805] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4806] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4807] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4808] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4809] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4810] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4811] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4812] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4813] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4814] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4815] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4816] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4817] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4818] Loss: 0.502 | Accuracy: 100.000% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:81, iter:4819] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4820] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4821] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4822] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4823] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4824] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4825] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4826] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4827] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4828] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4829] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4830] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4831] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4832] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4833] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4834] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4835] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4836] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4837] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4838] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4839] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4840] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4841] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4842] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4843] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4844] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4845] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4846] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4847] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4848] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4849] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4850] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4851] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4852] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4853] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4854] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4855] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4856] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4857] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4858] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4859] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:81, iter:4860] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=081, Loss: 0.566, Accuracy= 98.095%\n",
      "Epoch 00081: reducing learning rate of group 0 to 9.9699e-07.\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 82\n",
      "[epoch:82, iter:4861] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4862] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4863] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4864] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4865] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4866] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4867] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4868] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4869] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4870] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4871] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4872] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4873] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4874] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4875] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4876] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4877] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4878] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4879] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4880] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4881] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4882] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4883] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4884] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4885] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4886] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4887] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4888] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4889] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4890] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4891] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4892] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4893] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4894] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4895] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4896] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4897] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4898] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4899] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4900] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4901] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4902] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4903] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4904] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4905] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4906] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4907] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4908] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4909] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4910] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4911] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4912] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4913] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4914] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4915] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4916] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4917] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4918] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4919] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:82, iter:4920] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=082, Loss: 0.646, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 83\n",
      "[epoch:83, iter:4921] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4922] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4923] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4924] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4925] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4926] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4927] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4928] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4929] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4930] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4931] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4932] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4933] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4934] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4935] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4936] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4937] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4938] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4939] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4940] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4941] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4942] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4943] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4944] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4945] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4946] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4947] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4948] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4949] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4950] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4951] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4952] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4953] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4954] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4955] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4956] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4957] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4958] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4959] Loss: 0.502 | Accuracy: 100.000% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:83, iter:4960] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4961] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4962] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4963] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4964] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4965] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4966] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4967] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4968] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4969] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4970] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4971] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4972] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4973] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4974] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4975] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4976] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4977] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4978] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4979] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:83, iter:4980] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=083, Loss: 0.565, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 84\n",
      "[epoch:84, iter:4981] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:84, iter:4982] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:84, iter:4983] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:4984] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:4985] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:4986] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:4987] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:4988] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:4989] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:4990] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:4991] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:4992] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:4993] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:4994] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:4995] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:4996] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:4997] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:4998] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:4999] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5000] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5001] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5002] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5003] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5004] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5005] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5006] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5007] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5008] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5009] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5010] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5011] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5012] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5013] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5014] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5015] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5016] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5017] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5018] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5019] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5020] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5021] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5022] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5023] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5024] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5025] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5026] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5027] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5028] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5029] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5030] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5031] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5032] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5033] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5034] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5035] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5036] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5037] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5038] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5039] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:84, iter:5040] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=084, Loss: 0.565, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 85\n",
      "[epoch:85, iter:5041] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5042] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5043] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5044] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5045] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5046] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5047] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5048] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5049] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5050] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5051] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5052] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5053] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5054] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5055] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5056] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5057] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5058] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5059] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5060] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5061] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5062] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5063] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5064] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5065] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5066] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5067] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5068] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5069] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5070] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5071] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5072] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5073] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5074] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5075] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5076] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5077] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5078] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5079] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5080] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5081] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5082] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5083] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5084] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5085] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5086] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5087] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5088] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5089] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5090] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5091] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5092] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5093] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5094] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5095] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5096] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5097] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5098] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5099] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:85, iter:5100] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH=085, Loss: 0.566, Accuracy= 98.095%\n",
      "Epoch 00085: reducing learning rate of group 0 to 6.9789e-07.\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 86\n",
      "[epoch:86, iter:5101] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5102] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5103] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5104] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5105] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5106] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5107] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5108] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5109] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5110] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5111] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5112] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5113] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5114] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5115] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5116] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5117] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5118] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5119] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5120] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5121] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5122] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5123] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5124] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5125] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5126] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5127] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5128] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5129] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5130] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5131] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5132] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5133] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5134] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5135] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5136] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5137] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5138] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5139] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5140] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5141] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5142] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5143] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5144] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5145] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5146] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5147] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5148] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5149] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5150] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5151] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5152] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5153] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5154] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5155] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5156] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5157] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5158] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5159] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:86, iter:5160] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=086, Loss: 0.566, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 87\n",
      "[epoch:87, iter:5161] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5162] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5163] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5164] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5165] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5166] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5167] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5168] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5169] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5170] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5171] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5172] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5173] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5174] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5175] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5176] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5177] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5178] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5179] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5180] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5181] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5182] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5183] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5184] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5185] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5186] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5187] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5188] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5189] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5190] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5191] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5192] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5193] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5194] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5195] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5196] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5197] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5198] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5199] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5200] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5201] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5202] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5203] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5204] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5205] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5206] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5207] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5208] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5209] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5210] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5211] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5212] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5213] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5214] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5215] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5216] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5217] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5218] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5219] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:87, iter:5220] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=087, Loss: 0.566, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 88\n",
      "[epoch:88, iter:5221] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5222] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5223] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5224] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5225] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5226] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5227] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5228] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5229] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5230] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5231] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5232] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5233] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5234] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5235] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5236] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5237] Loss: 0.502 | Accuracy: 100.000% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:88, iter:5238] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5239] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5240] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5241] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5242] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5243] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5244] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5245] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5246] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5247] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5248] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5249] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5250] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5251] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5252] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5253] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5254] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5255] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5256] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5257] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5258] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5259] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5260] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5261] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5262] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5263] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5264] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5265] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5266] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5267] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5268] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5269] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5270] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5271] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5272] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5273] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5274] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5275] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5276] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5277] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5278] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5279] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:88, iter:5280] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=088, Loss: 0.566, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 89\n",
      "[epoch:89, iter:5281] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5282] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5283] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5284] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5285] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5286] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5287] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5288] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5289] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5290] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5291] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5292] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5293] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5294] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5295] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5296] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5297] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5298] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5299] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5300] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5301] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5302] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5303] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5304] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5305] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5306] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5307] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5308] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5309] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5310] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5311] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5312] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5313] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5314] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5315] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5316] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5317] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5318] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5319] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5320] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5321] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5322] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5323] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5324] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5325] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5326] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5327] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5328] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5329] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5330] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5331] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5332] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5333] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5334] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5335] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5336] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5337] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5338] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5339] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:89, iter:5340] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=089, Loss: 0.566, Accuracy= 98.095%\n",
      "Epoch 00089: reducing learning rate of group 0 to 4.8852e-07.\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 90\n",
      "[epoch:90, iter:5341] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5342] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5343] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5344] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5345] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5346] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5347] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5348] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5349] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5350] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5351] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5352] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5353] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5354] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5355] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5356] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5357] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5358] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5359] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5360] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5361] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5362] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5363] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5364] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5365] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5366] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5367] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5368] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5369] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5370] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5371] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5372] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5373] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5374] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5375] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5376] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5377] Loss: 0.502 | Accuracy: 100.000% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:90, iter:5378] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5379] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5380] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5381] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5382] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5383] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5384] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5385] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5386] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5387] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5388] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5389] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5390] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5391] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5392] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5393] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5394] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5395] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5396] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5397] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5398] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5399] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:90, iter:5400] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=090, Loss: 0.566, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 91\n",
      "[epoch:91, iter:5401] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5402] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5403] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5404] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5405] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5406] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5407] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5408] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5409] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5410] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5411] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5412] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5413] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5414] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5415] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5416] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5417] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5418] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5419] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5420] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5421] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5422] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5423] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5424] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5425] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5426] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5427] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5428] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5429] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5430] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5431] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5432] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5433] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5434] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5435] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5436] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5437] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5438] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5439] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5440] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5441] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5442] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5443] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5444] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5445] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5446] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5447] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5448] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5449] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5450] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5451] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5452] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5453] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5454] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5455] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5456] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5457] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5458] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5459] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:91, iter:5460] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=091, Loss: 0.566, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 92\n",
      "[epoch:92, iter:5461] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5462] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5463] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5464] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5465] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5466] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5467] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5468] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5469] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5470] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5471] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5472] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5473] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5474] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5475] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5476] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5477] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5478] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5479] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5480] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5481] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5482] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5483] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5484] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5485] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5486] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5487] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5488] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5489] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5490] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5491] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5492] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5493] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5494] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5495] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5496] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5497] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5498] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5499] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5500] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5501] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5502] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5503] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5504] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5505] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5506] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5507] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5508] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5509] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5510] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5511] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5512] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5513] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5514] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5515] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5516] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5517] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5518] Loss: 0.502 | Accuracy: 100.000% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:92, iter:5519] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:92, iter:5520] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=092, Loss: 0.571, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 93\n",
      "[epoch:93, iter:5521] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5522] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5523] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5524] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5525] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5526] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5527] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5528] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5529] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5530] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5531] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5532] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5533] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5534] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5535] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5536] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5537] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5538] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5539] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5540] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5541] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5542] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5543] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5544] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5545] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5546] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5547] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5548] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5549] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5550] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5551] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5552] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5553] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5554] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5555] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5556] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5557] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5558] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5559] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5560] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5561] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5562] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5563] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5564] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5565] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5566] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5567] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5568] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5569] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5570] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5571] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5572] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5573] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5574] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5575] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5576] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5577] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5578] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5579] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:93, iter:5580] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=093, Loss: 0.566, Accuracy= 98.095%\n",
      "Epoch 00093: reducing learning rate of group 0 to 3.4197e-07.\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 94\n",
      "[epoch:94, iter:5581] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5582] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5583] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5584] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5585] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5586] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5587] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5588] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5589] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5590] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5591] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5592] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5593] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5594] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5595] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5596] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5597] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5598] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5599] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5600] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5601] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5602] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5603] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5604] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5605] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5606] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5607] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5608] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5609] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5610] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5611] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5612] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5613] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5614] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5615] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5616] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5617] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5618] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5619] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5620] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5621] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5622] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5623] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5624] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5625] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5626] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5627] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5628] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5629] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5630] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5631] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5632] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5633] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5634] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5635] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5636] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5637] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5638] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5639] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:94, iter:5640] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=094, Loss: 0.644, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 95\n",
      "[epoch:95, iter:5641] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5642] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5643] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5644] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5645] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5646] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5647] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5648] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5649] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5650] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5651] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5652] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5653] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5654] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5655] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5656] Loss: 0.502 | Accuracy: 100.000% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:95, iter:5657] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5658] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5659] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5660] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5661] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5662] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5663] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5664] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5665] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5666] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5667] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5668] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5669] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5670] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5671] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5672] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5673] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5674] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5675] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5676] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5677] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5678] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5679] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5680] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5681] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5682] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5683] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5684] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5685] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5686] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5687] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5688] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5689] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5690] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5691] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5692] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5693] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5694] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5695] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5696] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5697] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5698] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5699] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:95, iter:5700] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=095, Loss: 0.566, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 96\n",
      "[epoch:96, iter:5701] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5702] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5703] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5704] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5705] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5706] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5707] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5708] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5709] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5710] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5711] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5712] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5713] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5714] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5715] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5716] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5717] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5718] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5719] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5720] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5721] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5722] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5723] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5724] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5725] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5726] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5727] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5728] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5729] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5730] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5731] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5732] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5733] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5734] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5735] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5736] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5737] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5738] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5739] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5740] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5741] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5742] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5743] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5744] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5745] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5746] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5747] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5748] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5749] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5750] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5751] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5752] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5753] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5754] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5755] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5756] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5757] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5758] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5759] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:96, iter:5760] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=096, Loss: 0.566, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 97\n",
      "[epoch:97, iter:5761] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5762] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5763] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5764] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5765] Loss: 0.504 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5766] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5767] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5768] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5769] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5770] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5771] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5772] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5773] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5774] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5775] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5776] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5777] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5778] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5779] Loss: 0.503 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5780] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5781] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5782] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5783] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5784] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5785] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5786] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5787] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5788] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5789] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5790] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5791] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5792] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5793] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5794] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5795] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5796] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5797] Loss: 0.502 | Accuracy: 100.000% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:97, iter:5798] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5799] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5800] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5801] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5802] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5803] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5804] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5805] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5806] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5807] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5808] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5809] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5810] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5811] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5812] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5813] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5814] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5815] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5816] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5817] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5818] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5819] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:97, iter:5820] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=097, Loss: 0.566, Accuracy= 98.095%\n",
      "Epoch 00097: reducing learning rate of group 0 to 2.3938e-07.\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 98\n",
      "[epoch:98, iter:5821] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5822] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5823] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5824] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5825] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5826] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5827] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5828] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5829] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5830] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5831] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5832] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5833] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5834] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5835] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5836] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5837] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5838] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5839] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5840] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5841] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5842] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5843] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5844] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5845] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5846] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5847] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5848] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5849] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5850] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5851] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5852] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5853] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5854] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5855] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5856] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5857] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5858] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5859] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5860] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5861] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5862] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5863] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5864] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5865] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5866] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5867] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5868] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5869] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5870] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5871] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5872] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5873] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5874] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5875] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5876] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5877] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5878] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5879] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:98, iter:5880] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=098, Loss: 0.567, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 99\n",
      "[epoch:99, iter:5881] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5882] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5883] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5884] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5885] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5886] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5887] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5888] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5889] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5890] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5891] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5892] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5893] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5894] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5895] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5896] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5897] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5898] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5899] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5900] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5901] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5902] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5903] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5904] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5905] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5906] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5907] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5908] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5909] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5910] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5911] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5912] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5913] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5914] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5915] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5916] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5917] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5918] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5919] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5920] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5921] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5922] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5923] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5924] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5925] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5926] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5927] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5928] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5929] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5930] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5931] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5932] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5933] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5934] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5935] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5936] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5937] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5938] Loss: 0.502 | Accuracy: 100.000% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:99, iter:5939] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:99, iter:5940] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=099, Loss: 0.566, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "\n",
      "Epoch: 100\n",
      "[epoch:100, iter:5941] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5942] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5943] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5944] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5945] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5946] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5947] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5948] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5949] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5950] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5951] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5952] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5953] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5954] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5955] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5956] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5957] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5958] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5959] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5960] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5961] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5962] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5963] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5964] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5965] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5966] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5967] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5968] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5969] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5970] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5971] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5972] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5973] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5974] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5975] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5976] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5977] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5978] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5979] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5980] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5981] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5982] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5983] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5984] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5985] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5986] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5987] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5988] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5989] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5990] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5991] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5992] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5993] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5994] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5995] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5996] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5997] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5998] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:5999] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:100, iter:6000] Loss: 0.502 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=100, Loss: 0.646, Accuracy= 98.095%\n",
      "Training complete in 0m 11s\n",
      "Validation accuracy increased (98.095238 --> 98.095238).  Saving model ...\n",
      "Training Finished, TotalEPOCH=0\n",
      "The whole training process complete in 18m 42s\n"
     ]
    }
   ],
   "source": [
    "losses_train, accs_train, losses_val, accs_val = train_net(pre_epoch=0,\n",
    "                                                           EPOCH = 100,\n",
    "                                                           early_patience = 30,\n",
    "                                                           training_loader=training_loader,\n",
    "                                                           validation_loader = validation_loader,\n",
    "                                                           net=net,\n",
    "                                                           optimizer=optimizer,\n",
    "                                                           scheduler=scheduler,\n",
    "                                                           criteria=criteria,\n",
    "                                                           device=device\n",
    "                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bea51d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1122.2175842081197\n"
     ]
    }
   ],
   "source": [
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8fad5aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accs_train, label='Train_accuracy')\n",
    "plt.plot(accs_val, label='Validation_accuracy')\n",
    "plt.grid()\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "676bc729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses_train, label='Train_loss')\n",
    "plt.plot(losses_val, label='Validation_loss')\n",
    "plt.grid()\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a198b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "class MyTestSet(Dataset):\n",
    "    def __init__(self, img):\n",
    "        self.img = np.load(img)\n",
    "        self.transforms = transforms.Compose([transforms.ToTensor(), ])\n",
    "    def __getitem__(self, index):\n",
    "        img = self.img[index, :, :, :]\n",
    "        img = np.squeeze(img)\n",
    "        img = Image.fromarray(np.uint8(img))\n",
    "        img = self.transforms(img)\n",
    "        return img\n",
    "    def __len__(self):\n",
    "        return self.img.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4dd79b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = MyTestSet(\"./pretrained/test_pre.npy\")\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a44fa5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): EfficientNet(\n",
       "    (_conv_stem): Conv2dStaticSamePadding(\n",
       "      3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "      (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "    )\n",
       "    (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_blocks): ModuleList(\n",
       "      (0): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          40, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          10, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (1): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (2): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (3): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (4): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (5): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (6): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (7): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (8): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False\n",
       "          (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (9): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (10): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (11): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (12): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (13): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (14): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (15): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (16): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (17): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (18): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (19): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (20): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (21): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (22): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (23): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (24): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (25): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          2304, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          96, 2304, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "    )\n",
       "    (_conv_head): Conv2dStaticSamePadding(\n",
       "      384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (static_padding): Identity()\n",
       "    )\n",
       "    (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "    (_dropout): Dropout(p=0.3, inplace=False)\n",
       "    (_fc): Linear(in_features=1536, out_features=10, bias=True)\n",
       "    (_swish): MemoryEfficientSwish()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "mod =EfficientNet.from_pretrained('efficientnet-b3', num_classes=classes)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    mod = nn.DataParallel(mod)\n",
    "\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.device_count()\n",
    "torch.cuda.current_device()\n",
    "torch.cuda.get_device_name()\n",
    "\n",
    "mod.to(device)\n",
    "mod = mod.to(device)\n",
    "mod.load_state_dict(torch.load((\"./pretrained/checkpoint_model_pre.pth\")))\n",
    "mod.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec05be57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "celltype   \n",
       "alpha          41\n",
       "beta           23\n",
       "duct           13\n",
       "acinar         11\n",
       "delta           9\n",
       "pp              5\n",
       "mesenchymal     4\n",
       "endothelial     1\n",
       "unclear         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = []\n",
    "for i, data in enumerate(test_loader):\n",
    "    query = data\n",
    "    query = query.to(device)\n",
    "    pred= mod(query)\n",
    "    _, predicted = torch.max(pred.data, 1)\n",
    "    out.append(predicted)\n",
    "\n",
    "pred = torch.cat(out, dim=0)\n",
    "pr = pred.cpu().numpy()\n",
    "\n",
    "real_label = pd.read_csv(\"./pretrained/testy_pre.csv\", index_col=0)\n",
    "real_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da4262bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alpha          40\n",
       "beta           31\n",
       "acinar         12\n",
       "duct           12\n",
       "delta           7\n",
       "mesenchymal     5\n",
       "endothelial     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(\"./pretrained/label_encoder_pre.obj\",'rb')\n",
    "le = pickle.load(file)\n",
    "file.close()\n",
    "pred_label = le.inverse_transform(pr)\n",
    "pred_label = pd.DataFrame(pred_label)\n",
    "pred_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f017e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuray: 0.880, ARI = 0.851\n"
     ]
    }
   ],
   "source": [
    "ls = list(set(pd.unique(pred_label[0]).tolist()) | set(pd.unique(real_label[\"celltype\"]).tolist()))\n",
    "acc = accuracy_score(pred_label,real_label)\n",
    "\n",
    "le2 = preprocessing.LabelEncoder()\n",
    "le2.fit(ls)\n",
    "pred_label_2 = le2.transform(pred_label[0])\n",
    "real_label_2 = le2.transform(real_label[\"celltype\"])\n",
    "ari = adjusted_rand_score(real_label_2, pred_label_2)\n",
    "\n",
    "print(\"Accuray: %.03f, ARI = %.03f\" % (acc, ari))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
